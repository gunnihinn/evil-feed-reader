<?xml version="1.0" encoding="UTF-8"?><rss version="2.0"
	xmlns:content="http://purl.org/rss/1.0/modules/content/"
	xmlns:wfw="http://wellformedweb.org/CommentAPI/"
	xmlns:dc="http://purl.org/dc/elements/1.1/"
	xmlns:atom="http://www.w3.org/2005/Atom"
	xmlns:sy="http://purl.org/rss/1.0/modules/syndication/"
	xmlns:slash="http://purl.org/rss/1.0/modules/slash/"
	>

<channel>
	<title>IT Hare on Soft.ware</title>
	<atom:link href="http://ithare.com/feed/" rel="self" type="application/rss+xml" />
	<link>http://ithare.com</link>
	<description>analytics for those Senior Software Developers, Team Leads, Architects, and Project Managers who&#039;re Able to Think</description>
	<lastBuildDate>Thu, 10 Aug 2017 04:48:14 +0000</lastBuildDate>
	<language>en-US</language>
	<sy:updatePeriod>hourly</sy:updatePeriod>
	<sy:updateFrequency>1</sy:updateFrequency>
	<generator>https://wordpress.org/?v=4.8.1</generator>
	<item>
		<title>The Importance of Back-of-Envelope Estimates</title>
		<link>http://ithare.com/the-importance-of-back-of-envelope-estimates/</link>
		<comments>http://ithare.com/the-importance-of-back-of-envelope-estimates/#respond</comments>
		<pubDate>Tue, 08 Aug 2017 14:06:25 +0000</pubDate>
		<dc:creator><![CDATA["No Bugs" Hare]]></dc:creator>
				<category><![CDATA[Design Decisions]]></category>
		<category><![CDATA[Requirement Analysis]]></category>
		<category><![CDATA[System Architecture]]></category>
		<category><![CDATA[Cache]]></category>
		<category><![CDATA[crazy stuff]]></category>
		<category><![CDATA[Latency]]></category>
		<category><![CDATA[UDP]]></category>

		<guid isPermaLink="false">http://ithare.com/?p=9069&#038;rabbit_rss_ver=23</guid>
		<description><![CDATA[

<div class="rabbit-img"><a href="/wp-content/uploads/BB_part131_Overload137_feb2017_v2.png"><img class="wp-image-10026 size-medium" src="/wp-content/uploads/BB_part131_Overload137_feb2017_v2-640x427.png" alt="Back of the Envelope Calculations: Fermi Problem" width="640" height="427" /></a></div>
<p>With all the techniques we use during development (ranging from ‘just keyboard and vim’ to ‘RAD IDE which claims to make writing code unnecessary’), there is one thing which is unfortunately meticulously neglected across the software development industry (and moreover, there are arguments pushed forward that it is a Bad Thing even to <em>try</em> using it). I’m speaking about order-of-magnitude estimates made on the back of an envelope. While it is impossible to provide any strict proof that such estimates are useful, we’ll see some anecdotal kinda-evidence that such estimates do help us to avoid spending months (and even years) on development which is apparently unnecessary or outright infeasible.</p>
<p>BTW, the subject of back-of-the-envelope estimates in IT is not something new (it was discussed at least in <a href="http://ithare.com/the-importance-of-back-of-envelope-estimates/?rabbit_open_refs=1#rabbitref-McConnell">[McConnell]</a> and <a href="http://ithare.com/the-importance-of-back-of-envelope-estimates/?rabbit_open_refs=1#rabbitref-Atwood">[Atwood]</a>, and recently mentioned in <a href="http://ithare.com/the-importance-of-back-of-envelope-estimates/?rabbit_open_refs=1#rabbitref-Acton">[Acton]</a>); indeed, I myself am guilty of using it in <a href="http://ithare.com/the-importance-of-back-of-envelope-estimates/?rabbit_open_refs=1#rabbitref-NoBugs12">[NoBugs12]</a> and <a href="http://ithare.com/the-importance-of-back-of-envelope-estimates/?rabbit_open_refs=1#rabbitref-NoBugs13">[NoBugs13]</a>☺. However, with such estimates being so important and so frequently neglected, I am sure it is necessary to emphasize their importance once again (and again, and again ;-)).</p>
<p>&nbsp;</p>
<h2>Definition and examples from physics</h2>
<p>First of all, let’s define what we’re talking about. Without going into lengthy discussion, let’s just quote Wikipedia:</p>
<p style="text-align: left;"><blockquote><big><b>In the hard sciences, back-of-the-envelope calculation is often associated with physicist Enrico Fermi, who was well known for emphasizing ways that complex scientific equations could be approximated within an order of magnitude using simple calculations.</b></big></blockquote></p>
<p>Besides noting that with Enrico Fermi being one of the brightest minds of the XX century, we’re certainly in a good company ;-), we should emphasize this ‘within an order of magnitude’ qualifier. In other words, we’re not even trying to get results which can be seen as a replacement for benchmarking. On the other hand, if our simplified calculations can give us an order of magnitude that is appropriate for approximating the exact value we need, we don’t have to spend time performing an actual experiment.</p>
<p>Two most famous examples of back-of-the-envelope calculations in physics are the following (with lots and lots of others not recorded as they’re not seen as anything special):</p>
<ul>
<li>Fermi estimating the yield of an atomic bomb by dropping bits of paper and measuring the distance they were blown by the blast wave (he estimated 10K tons of TNT, the actual result was 18.6K tons). See also his famous ‘Fermi problem’ of ‘how many piano tuners are there in Chicago?’☺.</li>
<li>Arnold Wilkins spending a few hours proving that radio-based ‘death rays’ (claimed to be invented by several influential people, including Guglielmo Marconi and Nicola Tesla) are outright impossible, but using radio waves to detect moving objects is perfectly feasible. This, in turn, led to the development of the radar.</li>
</ul>
<h2>Estimating CPU and RAM usage</h2>
<p>Well, as most of us are not physicists, and are more like software developers and/or admins, let’s take a look at some real-world examples from IT. While (of course), any such examples at best count as anecdotal evidence, they still illustrate the tremendous practical value which can come out of them.</p>
<p>My first family of examples are about estimating CPU and RAM usage. Actually, examples of such calculations are so routine that they come and go without being noticed. Still, I managed to remember four recent ones which I encountered within the last two months.</p>
<p>The first example was about CPU. In an otherwise very good and insightful presentation (which I won’t name exactly since it was very good and insightful), an example was provided where a certain suboptimality had led to memory reads of 1Megabyte per 10,000 frames of the video game – instead of the 1 Kbyte which was really necessary. As it was noted (and perfectly correctly too), this corresponds to 99.9% of CPU memory bandwidth being wasted. What wasn’t mentioned, however, is that:</p>
<ul>
<li>1Megabyte of waste per 10,000 frames corresponds to a mere 100 bytes/frame</li>
<li>at a typical 60 frames/second, this corresponds to a mere 6K bytes/second of memory bandwidth being wasted</li>
<li>with modern x64 CPU bandwidth being of the order of 20+ GByte/second, we’re talking about the waste of about 3e-7 of the total memory bandwidth.</li>
</ul>
<p><img width="170" height="170" src="/wp-content/uploads/BB_emotion_0034b.png" />BTW, let’s note that I am not arguing with the main point of the presentation – that you can easily waste a lot of memory bandwidth; it is just in this specific example, trying to optimize out a 3e-7 performance hit is very rarely worth the trouble.</p>
<p>The second example was also about CPU. In a high-performance event-driven machine handling TCP/UDP packets coming over the Ethernet, the question has arisen whether it is ok to use virtual functions to implement event dispatch. A very quick calculation on the back of the envelope has shown that:</p>
<ul>
<li>The minimal size of an Ethernet packet which such a system can possibly receive is Ethernet_Frame_Gap + Ethernet_Preamble + Minimal_Ethernet_Packet_Size, or 12+8+64 bytes = 84 bytes.</li>
<li>For a 100MBit/s link (which is the limit the system has for other reasons), in the very, very best case, it can get 100Mbit/8 ~= 1.2e7 bytes/second, or (given the 84 bytes/packet) 150K packets/second.</li>
<li>As it is noted in <a href="http://ithare.com/the-importance-of-back-of-envelope-estimates/?rabbit_open_refs=1#rabbitref-NoBugs16">[NoBugs16]</a>, the cost of a virtual function call is usually within 50 CPU cycles</li>
<li>On the other hand, at 3GHz and with 150K packets/second, we’re talking about 20,000 CPU cycles available for handling each packet.</li>
<li>The waste of at most 50 CPU cycles – compared to 20K CPU cycles – is about 0.2%. Compared to the trouble of avoiding virtual dispatch, the saving seems too small to bother with.</li>
</ul>
<p>On the other hand, the picture would be <em>very</em> different if we were talking about virtualizing some operation which is done 100 times per packet (or about handling the 10GBit/s link, but the latter is quite difficult regardless of the virtual function calls). The whole point is about the numbers in specific scenarios – and certainly <em>not</em> about blanket statements such as ‘virtual functions costs are {negligible|very high} regardless of the context’.</p>
<p>The third example of back-of-the-envelope estimates which I encountered in recent months was about the cost of exceptions vs the cost of the return-and-check of the error code. The cost of modern implementations of exception handling in C++ are ‘zero-cost when no exception happens’ – but they cost thousands of CPU cycles when they do happen. On the other hand, an old-fashioned return of the error code from the function being checked by the caller will cost some single-digit CPU cycles on each function call even if nothing wrong happens. When we combine these two numbers together, we realize that performance-wise exceptions will beat return-and-checks as soon as there is 10K function calls per one exception; on the other hand, having one exception per 100 function calls is probably detrimental to performance. Anything between 100 and 10K function calls is too close to call – but on the other hand, the performance difference probably won’t be too drastic regardless of the approach chosen. NB: I am intentionally ignoring the other advantages of exceptions at the moment; for the purposes of this article, the whole discussion is about performance, and only about performance.</p>
<p>The fourth example (and final among those which I’ve run into during the last month or two) was about RAM. In the context of app-level caching of USERS from a database, I was asked “Hey, if we try to cache a million users, will they fit in memory?” My very simple analysis went along the following lines:</p>
<ul>
<li>If we are talking about a ‘user’ which is just a current state of the user (and not the history of those things which user has ever done), we’re usually talking about user id, name, hashed password, e-mail address, maybe physical address, and some attributes such as current credit. If we add all these items together, we’ll be talking about some hundreds of bytes. Accounting for all the inefficiencies and overheads, let’s say the upper bound is around 1K bytes/user.</li>
<li>With this in mind, a million users will take around 1 GByte.</li>
<li><img width="170" height="170" src="/wp-content/uploads/BB_emotion_0012b.png" />As this whole discussion was in the context of servers, and as modern ‘workhorse’ 2S/1U servers are able to host up to 512G RAM easily (and modern 4S/4U servers able to host 4+ terabytes<a href="#rabbitfootnote-1"><sup>1</sup></a>), it means that even 100M users aren’t likely to cause too much trouble. In addition, noting that this is not really the number of all users in the DB, but just those users which need to be cached (which roughly corresponds to ‘users currently on site’) – well, it means that there aren’t that many systems out there (if any) which would have any trouble caching users in the app-level cache.</li>
</ul>
<p>Overall, as we can see, there are quite a few situations when back-of-the-envelope (a.k.a. order of magnitude) analysis can provide very valuable information even before we start implementing our system. Sure, such calculations are not a substitute for benchmarking, but they can save us lots and lots of trouble either (a) trying to implement things which won’t be able to cope with the load, or (b) trying to do premature optimizations which aim to eliminate problems which will never really bite us.</p>
<hr class="rabbit-footnote-separator" /><a name="rabbitfootnote-1"></a><div class="rabbit-footnote"><sup>1</sup> 4S = 4-Socket; 4U = 4 Rack Units. Popular examples include HP DL580 (my personal favourite for years ;-)), and Dell R930</div>
<p>&nbsp;</p>
<h2>Estimating MTBF</h2>
<p>While estimating CPU and RAM usage is very important, they’re certainly <em>not</em> the only cases when calculations on the back of the envelope come in handy.</p>
<p>Quite recently, I was involved in quite an interesting analysis related to making systems redundant. Lots of people out there tend to postulate that ‘Hey, to be reliable your system needs to be redundant, period!’; however, under a more thorough analysis this claim fails pretty badly in quite a significant number of real-world scenarios.</p>
<p>First of all, let’s note that when talking about reliability, it is only MTBF (= Mean Time Between Failures) which matters; in other words,</p>
<p style="text-align: left;"><blockquote><big><b>if comparing two systems – one being redundant but failing every month, and another being non-redundant but failing every year – I will clearly pick the second one every day of the week.<a href="#rabbitfootnote-2"><sup>2</sup></a></b></big></blockquote></p>
<p>Ok, sure we should note that there are other factors which may need to be considered within the context of reliability (in particular, the way in which the system fails; there is quite a significant difference between losing all the business data, having a ‘split-brain’, or just needing a restart). On the other hand, all these things we’re really interested in are inherently observable ones; as redundancy is not an observable property, it is merely an implementation detail to implement those observable MTBFs etc.</p>
<p>Now, let’s consider an OLTP database running on a larger 4S/4U box; as noted in <a href="http://ithare.com/the-importance-of-back-of-envelope-estimates/?rabbit_open_refs=1#rabbitref-NoBugs16a">[NoBugs16a]</a>. Such a box (with proper optimizations) can be able to run up to dozens of billions transactions/year, and this is quite a substantial number for quite a few systems out there.</p>
<p><img width="170" height="170" src="/wp-content/uploads/BB_emotion_0024b.png" />With 4S/4U boxes having typical MTBFs of 3–5 years, the next question we should ask ourselves, is “Hey, will we really be able to write software which crashes much more rarely than that?” If not (and for any business software, the chance of failures being much more frequent than once every 3–5 years is overwhelmingly high), then the whole point of being redundant pretty much goes away; in other words, it can easily be the case that spending time making the system redundant is not efficient, and that spending the same time on things such as code reviews can lead to better overall reliability.</p>
<hr class="rabbit-footnote-separator" /><a name="rabbitfootnote-2"></a><div class="rabbit-footnote"><sup>2</sup> And this happens in real-world too, see also below</div>
<p>&nbsp;</p>
<h2>On MTBFs of redundant systems</h2>
<p>As a side note – actually, when calculating MTBFs of a redundant system with 2 nodes, the numbers are not as good as they might seem on first glance. Let’s consider a redundant system Z consisting of 2 redundant components X and Y. Now we need to introduce MDT (= Mean Down Time), which is the mean time between the node going down; MDT is usually measured in hours and usually ranges from 8 hours to several days. (Note that MTTR (= Mean Time To Repair), while closely related to MDT, doesn’t normally include such things as ‘How to get the replacement part to your datacenter’ – and so is not directly usable for our MTBF analysis.)</p>
<p>Let’s note that the maths below, while perfectly common and accepted (see, for example, Chapter 8 in <a href="http://ithare.com/the-importance-of-back-of-envelope-estimates/?rabbit_open_refs=1#rabbitref-Smith">[Smith]</a>) is using quite a few implicit assumptions, which are beyond the scope of our exercise. In particular, it assumes that (a) MDTs are negligible compared to MTBFs, and (b) that failure probabilities (inverse of MTBFs) can be added together (i.e. that failure probabilities are small enough to say that non-linear effects when adding probabilities, are negligible).</p>
<p>Note that all these assumptions, while potentially confusing, do stand in most real-world situations. What we’ll be concentrating on is a different implicit assumption – the one which doesn’t usually stand☹.</p>
<p><strong>//WARNING: INVALID IMPLICIT ASSUMPTION AHEAD</strong></p>
<p>At this point, it is common to say (erroneously! See below) that redundant system Z will fail if and only if one of the following scenarios happen: (a) after component X fails, component Y will fail within MDTx (i.e. while component X is still being repaired); or (b) after component Y fails, component X will fail within MDTy (i.e. while component Y is still being repaired). The probability of such a failure of component Y within the MDTx, assuming that MTBFs are large, and MDTs are relatively small compared to MTBFs, is</p>
<p>Pyx = 1/MTBFy * MDTx</p>
<p><em>NB: relying on assumption (a) above</em></p>
<p>It means that MTBFz can be calculated as</p>
<p>MTBFz<sub>incorrect</sub><br />
= 1 / ( 1 / MTBFx * Pyx + 1 / MTBFy * Pyx )<br />
= 1 / ( 1 / MTBFx * 1/MTBFy * MDTx + 1 / MTBFy * 1/MTBFx * MDTy )<br />
= MTBFx * MTBFy / (MDTx + MDTy)</p>
<p><em>NB: relying on assumption (b) above</em></p>
<p><strong>//END OF INVALID IMPLICIT ASSUMPTION</strong></p>
<p>It looks all grand and dandy (and with typical MTBFs of 3–5 years and MDTs being maximum 3–5 days, we’d have an MTBFz<sub>incorrect</sub> of thousands of years – wow!) – until we notice that there is one thing which is utterly unaccounted for in the formula above: it is the MTBF of the redundancy system itself. Let’s name it MTBFr.</p>
<p>Practically, MTBFr needs to cover all the components which form the redundancy system itself. Just one example: if our system uses a ‘heartbeat’ Ethernet cable between two nodes to detect failure of the other node, then failure of this cable is likely to lead to all kinds of trouble (including extremely disastrous ‘split-brain’ failures), and so it needs to be accounted for in MTBFr. In a similar manner, network cards (and their respective drivers(!)) serving this ‘heartbeat’ cable, also need to be included into MTBFr. Moreover, if this cable and NICs are made redundant (which would be quite unusual, but is certainly doable), they will still have their respective MTBFr, and moreover there will be some kind of software (or, Linus forbid, drivers) handling this redundancy, which will also have its own MTBFr. And so on, and so forth.</p>
<p>With MTBFr in mind (and realizing that whenever redundancy system itself fails – the whole thing will fail too) – MTBFzcorrect can be written as</p>
<p>MTBFz<sub>correct</sub> = 1 / (1/ MTBFz<sub>incorrect</sub> + 1/ MTBFr). (*)</p>
<p>How large your MTBFr is depends, but I can assure you that for the vast majority of real-world cases, it will be much smaller than those hyper-optimistic ‘thousands of years’.</p>
<p><img width="170" height="170" src="/wp-content/uploads/BB_emotion_0027b.png" /><blockquote><big><b>Moreover, according to the formula (*) above, if MTBFr is smaller than MTBFx and MTBFy, adding redundancy makes things <em>worse</em> than it was without any redundancy.</b></big></blockquote></p>
<p>And in practice (and especially whenever redundancy is implemented in software), MTBFr can be easily much smaller than MTBFx. For example, if MTBFr is 1 month (BTW, it is not a joke, I’ve seen quite a few redundancy systems which exhibited less-than-a-week MTBFs under serious loads) while having MTBFx at 3–5 years – the formula (*) will show that MTBFz<sub>correct</sub> is about 0.9999 of MTBFr (i.e. much smaller than original non-redundant MTBFx).</p>
<h2>Redundancy estimates – sanity checks</h2>
<p>As a nice side effect, our formula of MTBFz<sub>correct</sub> also explains an apparent discrepancy of theoretically predicted MTBFs (those calculated in a manner similar to the calculation of MTBFz<sub>incorrect</sub>), and realistic numbers – especially if redundancy is implemented in software. Just two real-world stories in this regard.</p>
<p><img width="170" height="170" src="/wp-content/uploads/BB_emotion_0013b.png" />Once upon a time (around 1997 or so), Stratus (one of the leaders of really serious redundant systems aimed at military, nuclear stations etc. – and generally performing as promised) decided to produce a software-based RADIO cluster. Essentially, the RADIO cluster was just two Windows boxes with a fault-tolerant logic implemented in software; using MTBFz<sub>incorrect</sub>-like calculations, its MTBF was in hundreds of years. It was a rather impressive system (well, <em>all</em> the Stratuses are quite impressive) – that is, until RADIO crashed with a dreaded Blue Screen Of Death (coming from redundancy driver) just half an hour into testing ☹; and it wasn’t a fluke: under any kind of decent load, RADIO kept crashing several times a day. So much for very-nicely-looking MTBFs calculated along the lines of MTBFz<sub>incorrect</sub>. RADIO was discontinued really soon, and to the best of my knowledge, Stratus has given up on software-based redundancy at least for a long while. BTW, for hardware-based Stratuses MTBF is indeed in hundreds of years.</p>
<p>In a completely separate story, at some point a rather seriously loaded system was undergoing pre-IPO technical audit. Out of the whole audit, two points are of interest to our discussion:</p>
<ul>
<li>At some point, the auditor asked about system downtime, and after hearing the answer, he was really surprised; the wording went along the lines of ‘how do you guys manage to achieve unplanned downtimes which are 5x–10x lower than others in the industry?!’ Ok, the full log files were provided, essentially proving that the downtimes-being-<em>much</em>-lower-than-industry-average were real.</li>
<li>At another point (coming much later in the discussion), the auditor noticed that main DB server of the system runs without redundancy. From this point on, the dialog went along the following lines:
<ul>
<li>Auditor: Why don’t you use clusters?</li>
<li>Team: Why should we?</li>
<li>Auditor: Because it isn’t reliable without redundancy.</li>
<li>Team: Actually, the reason why we have unplanned downtimes which are that much lower than industry average is because we do NOT use clusters – and the rest of the industry does.</li>
<li>The curtain falls.</li>
</ul>
</li>
</ul>
<p>At that point, the team wasn’t able to articulate the formulae and back-of-the-envelope estimates discussed above to explain the whole thing; however, as of now, feel free to use it as an argument with all kinds of the auditors (and management) insisting on redundancy of all the mission-critical boxes. Note, though, that this logic stands only if <em>both</em> of the following two observations stand for your system:</p>
<ul>
<li>The cost of failure can be calculated; in other words, it is not about loss of life, and even not about loss of the whole business.</li>
<li>the number of boxes involved is very low (like in ‘just one, maybe two’). As the formulae above will show, the cost of redundancy (even if it has an MTBFr as poor as 1 failure per month) is low enough compared to the chance of any one of a thousand of servers failing.</li>
</ul>
<h2>Estimating network traffic and RTT</h2>
<p>Last but not least, back-of-the-envelope estimates often come handy in the context of network programming.</p>
<p>One rather typical case for traffic calculations occurs when we want to push small pieces of information to the clients all the time; this happens all the time in the context of a game (and IMNSHO, games include stock exchanges, etc.).</p>
<p>Let’s consider an example where we need to calculate traffic for an RPG game server which handles 10K players, with each of the players receiving updates about 10 other players and 50 objects (those which are nearby, so the player can see them), with each of players and objects described with three coordinates and a quaternion (the latter to describe rotation), and the updates are sent 60 times per second (at the frame rate of the game client). In this case, if we’re encoding each coordinate and each angle as an 8-byte double, we’ll find that:</p>
<ul>
<li>Each update will take ((10+50)*7*8) bytes of payload, plus at least 14+28 bytes of Ethernet + IP + UDP headers, totalling to ~3K per update</li>
<li>Each player will need to receive 3Kbytes / update * 60 updates/second = 180 kBytes/second</li>
<li>With 10K players/server, it means that per-server traffic will be like 1,8 GByte/second, or 14.5 GBit/second</li>
<li>Even with typical pricing these days being of the order of $3K / month for 10 Gbit/s, it is going to cost quite a lot.</li>
</ul>
<p>On the other hand, if we:</p>
<ul>
<li>reduce the update frequency (for most RPG out there, 20 updates / second will be perfectly unnoticeable, and 10 updates / second will still probably be fine)</li>
<li>switch to rounded fixed-point representation for coordinates (which can be as little as 10–12 bits per coordinate; 10 bits is enough to represent 10 cm precision in a 100m radius around our character). It will mean that each coordinate will use 10 bits instead of former 64(!).</li>
<li>switch to Euler-angle-based fixed-point representation for rotations (with precision of each angle being 10 bits, or 0.3 degree)</li>
</ul>
<p>we can easily reduce our traffic to:</p>
<ul>
<li>((10+50)*6*1.25)+42 ~= 500 bytes / update</li>
<li>500 bytes / update * 10 updates / second = 5 kBytes / second per player</li>
<li>5kBytes/second/player * 10K players/server = 50 Mbytes / second, or 400 Mbit/second</li>
</ul>
<p><img width="170" height="170" src="/wp-content/uploads/BB_emotion_0029b.png" />While it is still quite a substantial number, it is roughly 36x smaller than before, so at least our traffic costs went down quite a bit☺. Moreover, while this is very difficult to account for in advance, rounded fixed-point numbers are usually compressed significantly better than full-scaled doubles, which will usually allow further reduction of the traffic.</p>
<p>Another case for back-of-the-envelope estimates in the context of network programming is related to round-trip times (routinely abbreviated as RTT). An example which I want to describe in this regard is a rather long real-world story.</p>
<p>Once upon a time, there was a Really Big Company. And developers there were tasked with developing a system so that companies around the globe (in particular, from the US and Europe) can collaborate. And the guys were tasked with doing it over CORBA as a Big Fat Business Requirement (please don’t tell me that CORBA is actually an implementation detail so it doesn’t belong in Business Requirements; of course it is, but this kind of stuff does happen, <em>especially</em> in Really Big Companies).</p>
<p>And CORBA of that time (which didn’t support the concept of passing objects by value rather than by reference) had an ideology that you create a remote object, and then you call a remote method to add an item to a certain list in the remote object, and then you call a remote method to set a field in the item of the remote object you just created, and so on. And for several of the forms within the program – well, the number of fields combined over various items has reached thousands(!); with CORBA, this meant that when a user presses the ‘submit’ button, there will be thousands of those remote calls.</p>
<p>The guys from the Really Big Company have built the system along the lines above, and they even tested it in LAN. However, when they tried to deploy it over the Atlantic (which was their primary use case), submitting certain forms started to take up to 20 minutes(!), which was obviously unacceptable. Sure, the system was fixed (by removing those roundtrips, which required rewriting like a half of the system and took half a year or so).</p>
<p>What matters, from our current perspective, is that if the guys had performed a back-of-the-envelope estimate in advance, they would see that:</p>
<ul>
<li>5,000 fields for all the items in a form, combined with CORBA’s ‘1 remote call per field’ approach, means 5,000 remote calls</li>
<li>Each remote call incurs at least one round-trip</li>
<li>Over the trans-Atlantic cable, each remote call takes at the very least 80 ms (the absolute theoretical limit imposed by the speed of light in fibre is 56ms for NY-to-London); taking into account that the program was intended to be used worldwide, we should expect a round-trip time of 200ms at the very least.</li>
<li>Hence, in the worst-case, 5,000 remote calls would lead to 5,000 round-trips of 200ms each, which translates into a 1000-second delay, or over 15 minutes.</li>
</ul>
<p>Sure, in practice it was even worse than that – but even 15 minutes would be bad enough ☹ to see that the whole model is not really feasible. Realizing this in advance would save those guys (and that Really Big Company) quite a bit of wasted effort – and quite a bit of embarrassment too.</p>
<h2>The importance of sanity checks</h2>
<p style="text-align: left;"><blockquote><p>I am terribly sorry, but here your calculations are wrong by EIGHT orders of magnitude, so I cannot give you a credit for this lab.</p>&#8212; overheard during my uni physics courses &#8212;</blockquote></p>
<p>One all-important precaution which needs to be done whenever you’re trying to use back-of-the-envelope estimates (or actually, any kind of calculations, but this is a subject for a separate discussion) is making sanity checks. When you have your estimate, you at least need to try to think whether it makes sense given your experience; however, if you’re going to use the estimate to make any serious decisions, you <em>should</em> try to get some other way to double-check your estimate. BTW, in quite a few real-world scenarios, a back-of-the-envelope estimate can be double-checked by another – <em>independent(!)</em> – back-of-the-envelope estimate.</p>
<h2>Benchmarks vs back-of-the-envelope estimates</h2>
<p>When trying to convince various people to do some back-of-the-envelope estimates, I’ve often run into arguments such as ‘Hey, don’t even try this, the only way to get anything meaningful is to try it and benchmark it properly in the context of your specific task’.</p>
<p>I’m not going to argue with this statement, it is indeed a good advice – that is, <em>if</em> trying and benchmarking is feasible. However, especially at the earlier stages in development, trying certain things can be extremely expensive; this is when back-of-the-envelope estimates come in really handy.</p>
<blockquote><big><b>Back-of-the-Envelope Estimates are not a replacement for benchmarks; instead, they’re prerequisites to implementing systems which can be used for benchmarking.</b></big></blockquote>
<h2>Conclusions</h2>
<p>Summarizing all the anecdotal kinda-evidence above, I am comfortable to state the following.</p>
<p><img width="170" height="170" src="/wp-content/uploads/BB_emotion_0007b.png" />On the one hand, back-of-the-envelope calculations are all-important at least at architectural stages of the project. In particular, they often enable avoiding implementing things which cannot possibly fly for various reasons – and on the other hand, allow avoidance of premature optimizations which will never be important enough for the task in hand.</p>
<p>On the other hand, back-of-the-envelope calculations are just one of the instruments available, and, unfortunately, they’re not the most reliable one ☹.</p>
<p>Make sure to double-check back-of-the-envelope estimates, and to test them, and to benchmark things – as long as it is feasible, that is.</p>
<hr><h3>References</h3><p></p>
<p><a name="rabbitref-Acton"></a>[Acton] Mike Acton, <a href="https://www.youtube.com/watch?v=rX0ItVEVjHc">&#8220;‘Data-Oriented Design and C++’, CppCon 2014&#8221;</a><br />
<a name="rabbitref-Atwood"></a>[Atwood] Jeff Atwood, <a href="https://blog.codinghorror.com/how-good-an-estimator-are-you/">&#8220;How Good an Estimator Are You?&#8221;</a><br />
<a name="rabbitref-Loganberry04"></a>[Loganberry04] David ‘Loganberry’, <a href="http://bitsnbobstones.watershipdown.org/lapine/overview.html">&#8220;Frithaes! - an Introduction to Colloquial Lapine!&#8221;</a><br />
<a name="rabbitref-McConnell"></a>[McConnell] Steve McConnell, <a href="https://www.amazon.com/exec/obidos/ASIN/0735605351/codihorr-20">&#8220;Software Estimation: Demystifying the Black Art (Developer Best Practices).&#8221;</a><br />
<a name="rabbitref-NoBugs12"></a>[NoBugs12] ‘No Bugs’ Hare, <a href="https://accu.org/index.php/journals/1880">&#8220;Overload #112, 2012&#8221;</a><br />
<a name="rabbitref-NoBugs13"></a>[NoBugs13] ‘No Bugs’ Hare, <a href="https://accu.org/index.php/journals/1844">&#8220;Overload #116, 2013&#8221;</a><br />
<a name="rabbitref-NoBugs16"></a>[NoBugs16] ‘No Bugs' Hare, <a href="http://ithare.com/infographics-operation-costs-in-cpu-clock-cycles/">&#8220;Infographics: Operation Costs in CPU Clock Cycles&#8221;</a><br />
<a name="rabbitref-NoBugs16a"></a>[NoBugs16a] ‘No Bugs’ Hare, <a href="http://ithare.com/gradual-oltp-db-development-from-zero-to-10-billion-transactions-per-year-and-beyond/">&#8220;Gradual OLTP DB Development - from Zero to 10 Billion Transactions per Year and Beyond&#8221;</a><br />
<a name="rabbitref-Smith"></a>[Smith] Dr David J. Smith, &#8220;Reliability, Maintainability and Risk.&#8221;, ISBN 978-0080969022</p>
<p>&nbsp;</p>
<p></p><h3>Disclaimer</h3><p>as usual, the opinions within this article are those of ‘No Bugs’ Hare, and do not necessarily coincide with the opinions of the translators and <em>Overload</em> editors; also, please keep in mind that translation difficulties from Lapine (like those described in <a href="http://ithare.com/the-importance-of-back-of-envelope-estimates/?rabbit_open_refs=1#rabbitref-Loganberry04">[Loganberry04]</a>) might have prevented an exact translation. In addition, the translator and <em>Overload</em> expressly disclaim all responsibility from any action or inaction resulting from reading this article.</p><h3>Acknowledgement</h3><p>Cartoons by Sergey Gordeev<sup><a style="border:none;" href="/real-people-behind-the-hare#sergey-gordeev"><img width="16" height="16" src="/wp-content/uploads/irl-link.png" alt="IRL" style="position:relative; bottom:3px;"></a></sup> from <a href="http://gagltd.eu/">Gordeev Animation Graphics</a>, Prague.</p><h3>P.S.</h3><p>Don&#39;t like this post?&nbsp;<b><a href="http://ithare.com/the-importance-of-back-of-envelope-estimates/#rabbit-comment">Criticize&#8623;</a></b></p><h3>P.P.S.</h3><p>We've tried to optimize our feed for viewing in your RSS viewer. However, our pages are quite complicated, so if you see any glitches when viewing this page in your RSS viewer, please refer to our <a href="http://ithare.com/the-importance-of-back-of-envelope-estimates/">original page</a>.</p>
]]></description>
		<wfw:commentRss>http://ithare.com/the-importance-of-back-of-envelope-estimates/feed/</wfw:commentRss>
		<slash:comments>0</slash:comments>
		</item>
		<item>
		<title>(Not Really So) New Niche for C++: Browser!?</title>
		<link>http://ithare.com/not-really-so-new-niche-for-c-browser/</link>
		<comments>http://ithare.com/not-really-so-new-niche-for-c-browser/#respond</comments>
		<pubDate>Tue, 01 Aug 2017 12:49:02 +0000</pubDate>
		<dc:creator><![CDATA["No Bugs" Hare]]></dc:creator>
				<category><![CDATA[Programming]]></category>
		<category><![CDATA[Programming Languages]]></category>
		<category><![CDATA[C/C++]]></category>
		<category><![CDATA[Client]]></category>
		<category><![CDATA[web development]]></category>

		<guid isPermaLink="false">http://ithare.com/?p=9435&#038;rabbit_rss_ver=23</guid>
		<description><![CDATA[

<p><em>[In chess annotation,] ‘!?’… usually indicates that the move leads to exciting or wild play but that the objective evaluation of the move is unclear</em></p>
<p style="text-align: right;"><em>~ Wikipedia</em></p>
<div class="rabbit-img"><a href="/wp-content/uploads/BB_part141_Overload138_apr2017_v1-3.png"><img class="wp-image-10002 size-medium" src="/wp-content/uploads/BB_part141_Overload138_apr2017_v1-3-640x427.png" alt="C++ in Browser" width="640" height="427" /></a></div>
<p>For quite a long while, C++ had been losing popularity; for example, as reported in <a href="http://ithare.com/not-really-so-new-niche-for-c-browser/?rabbit_open_refs=1#rabbitref-Widman16">[Widman16]</a>, in 2016 it got 7% less of the listings on Dice.com compared with a year earlier; and according to <a href="http://ithare.com/not-really-so-new-niche-for-c-browser/?rabbit_open_refs=1#rabbitref-TIOBE17">[TIOBE17]</a>, from the C++ Golden Age in 2004 till 2017, the C++ share fell from ~17% to a measly 6%.</p>
<p>As all of us (as in, ‘hardcore C++ fans’) know , this has nothing to do with the deficiencies of C++; rather it is related to an observation that the time of downloadable clients (which was one of the main C++ strongholds) has changed into the time of browser-based clients – and all the attempts to get C++ onto browsers were sooo ugly (ActiveX, anyone?) that this didn’t really leave a chance to use C++ there.</p>
<p>Well, it <em>seems</em> that this tendency is already in the process of being reverted:</p>
<p style="text-align: left;"><blockquote><big><b>C++ can already run on all four major browsers – and moreover, it has several all-important advantages over JavaScript, too.</b></big></blockquote></p>
<p>And this – not too surprisingly – is what this article is all about.</p>
<p><em>A word of warning: please do NOT expect any revelations here; this article is admittedly long overdue – and quite a few people know MUCH more than I can fit here (and MUCH more than know myself).</em> Still, given the lack of such overviews intended for those of us who haven’t tried it yet, I am sure that such an article has its merits. In the article, I will try to provide a very high-level overview of <em>Emscripten</em>, of the technologies involved, of the performance which can be expected, of the APIs which can be used – and what we can gain from using it.</p>
<h2>JavaScript to the rescue!</h2>
<p>Attempts to get C++ on browsers were continuing all the time (such as (P)NaCl), but all of them were platform- (and/or browser-)specific, and (as a result) were very problematic for browser deployments. However, help for the C++ side of things has come from exactly the same rival which has been stealing the browser show for all these years – from JavaScript. It wasn’t easy, and took several all-important (and IMO ingenious) pieces of the puzzle to make it useful.</p>
<h3>Piece I – asm.js</h3>
<p>In 2013, so-called <em>asm.js</em> was released. Essentially,<em> asm.js</em> is just a very small subset of JavaScript, intended to simulate good old assembler. If we take a look at a real-world <em>asm.js</em> program (not hand-written, but compiled from C++), we’ll see something along the lines of Listing 1 <a href="http://ithare.com/not-really-so-new-niche-for-c-browser/?rabbit_open_refs=1#rabbitref-Resig13">[Resig13]</a>:</p>
<pre class="brush: jscript; title: ; notranslate">function Vb(d) {
  d = d | 0;
  var e = 0, f = 0, h = 0, j = 0, k = 0, l = 0, m = 0, n = 0, o = 0, p = 0, q = 0, r = 0, s = 0;
  e = i;
  i = i + 12 | 0;
  f = e | 0;
  h = d + 12 | 0;
  j = c[h&gt;&gt;2] | 0;
  if ((j | 0) &gt; 0) {
    c[h&gt;&gt;2] = 0;
  k = 0
  } else {
    k = j
  }
  j = d + 24 | 0;
  if ((c[j&gt;&gt;2] | 0) &gt; 0) {
    c[j&gt;&gt;2] = 0
  }
...
}</pre>
<p>As we can see, it is nothing like your usual high-level JavaScript, which deals with DOM and high-level <strong>onclick</strong> handlers. Instead (except from the if statements and function declarations) it directly translates into what we’d usually expect from an assembler language.</p>
<p>On taking a closer look, we can observe the following elements of more-or-less typical assembler in the code above:</p>
<ul>
<li>registers (implemented as JavaScript <strong>var</strong>s)</li>
<li>ALU operations (via JavaScript doubles, but converting them into <strong>uint32_t</strong> all the time via <strong>| 0</strong>)</li>
<li>Ability to access memory (as one huge array; in the example above – <strong>c[]</strong>)</li>
<li>Control operations (<strong>if and function</strong>)</li>
</ul>
<p>Well, that’s pretty much <em>all</em> we need to get the full-scale assembler rolling.☹</p>
<p>For our current purposes, we don’t really want to go any deeper, but hopefully I’ve managed to describe the idea behind <em>asm.js</em>: essentially, it is pretty much a simulator of a <em>strange CPU</em> with a <em>strange instruction</em> set. In other words, <em>asm.js</em> did NOT try to simulate any existing instruction sets (and doing so would make it fatally inefficient).</p>
<p style="text-align: left;"><em>Instead, asm.js has invented <strong>its own instruction set</strong>, which can be still seen as an instruction set of a CPU, <strong>at least from the point of view of a C++ compiler</strong>.</em></p>
<h3>Piece II – LLVM/Emscripten</h3>
<p>The above observation has made it possible to write a back-end for the LLVM compiler, and this back-end has allowed the generation of <em>asm.js</em> out of our usual C++ (some restrictions apply, batteries not included). Moreover, such a compiler is not only possible, but it exists and is working: it is <em>Emscripten</em>.<a href="#rabbitfootnote-1"><sup>1</sup></a></p>
<p>Actually, the <em>asm.js</em> in the example above has been generated by <em>Emscripten</em>. Using <em>Emscripten</em> is indeed rather simple:<a href="#rabbitfootnote-2"><sup>2</sup></a> we just take our existing standard-compliant and not-using-platform-specific-stuff C++ code (hey, you DO write your code as cross-platform and standard-compliant, don’t you?), and compile it into <em>asm.js</em>. As long as our code is just ‘moving bits around’, it works near-perfectly (and what will happen when we need to interact with the rest of the world, we’ll discuss in the ‘APIs’ section below), producing <em>asm.js</em> code which looks similar to the example above.</p>
<hr class="rabbit-footnote-separator" /><a name="rabbitfootnote-1"></a><div class="rabbit-footnote"><sup>1</sup> There are alternative compilers (formerly Mandreel, now cheerp) which compile C++ not into <em>asm.js</em>, but into other subtypes of compliant JavaScript; we’ll see in a jiff why compiling into <em>asm.js</em> is so important.</div><a name="rabbitfootnote-2"></a><div class="rabbit-footnote"><sup>2</sup> After the usual jumping through the hoops to get stuff installed</div>
<p>&nbsp;</p>
<h3>Piece III – optimizations for asm.js</h3>
<p>When looking at all the stuff above, a very natural scepticism goes along the lines of “Ok, this compiled piece of [CENSORED] stuff MAY work correctly, but how slow it is going to be???” And here is the point where the third piece of the C++-to-<em>asm.js</em> puzzle comes in. I’m speaking about <em>asm.js</em>-specific optimizations.</p>
<p>The thing is that with <em>asm.js</em> being <em>this</em> simple and restricted, it becomes possible to optimize it during a JIT compile. That’s it – we <em>can</em> have our cake (write in C++) and eat it (run it in <em>asm.js</em> with a reasonable speed) too!</p>
<p>As of now, all the four major browsers (in alphabetical order: Chrome, Edge, Firefox, and Safari <a href="#rabbitfootnote-3"><sup>3</sup></a>) – at least <em>try</em> to optimize for <em>asm.js</em>. Results vary, but currently, most of the time, we’re speaking about a less than 2× performance degradation of <em>asm.js</em> compared to native C++(say, compiled with Clang) <a href="http://ithare.com/not-really-so-new-niche-for-c-browser/?rabbit_open_refs=1#rabbitref-Zakai14">[Zakai14]</a>. While comparisons with native C++ are difficult to find (which BTW does make me to raise an eyebrow), the few resources available seem to support this claim (see, for example, <a href="http://ithare.com/not-really-so-new-niche-for-c-browser/?rabbit_open_refs=1#rabbitref-AreWeFastYet17">[AreWeFastYet17]</a>). BTW, Firefox results listed by the link are of special interest – in fact, <em>it manages to keep the performance of asm.js within a mere 20% of the ‘native’ performance</em> – and while we cannot <em>rely</em> on such performance (hey, we don’t want to be <em>restricted</em> only to Firefox users), it still serves as an indication of what it is possible to achieve (well, if enough effort is spent on it).</p>
<p>BTW, one important property of <em>asm.js</em> is that</p>
<p style="text-align: left;"><blockquote><big><b>As asm.js is a strict subset of JavaScript – it will run even if there is no special support for asm.js in browser.</b></big></blockquote></p>
<p>Sure, without special support <em>asm.js</em> will be pretty slow – but if we’re speaking about ‘glue code’, it still <em>may</em> fly even with <em>asm.js</em> support being unavailable/disabled.</p>
<hr class="rabbit-footnote-separator" /><a name="rabbitfootnote-3"></a><div class="rabbit-footnote"><sup>3</sup> Well, actually – WebKit</div>
<p>&nbsp;</p>
<h2>Restrictions</h2>
<p>While <em>Emscripten</em> provides a full-scale and very usable environment, there are certain limitations due to the need to run from within browser. When you’re ready to go ahead with <em>Emscripten</em>, make sure to read <a href="http://ithare.com/not-really-so-new-niche-for-c-browser/?rabbit_open_refs=1#rabbitref-Emscripten.Porting">[Emscripten.Porting]</a>; the following is only a very short summary of the <em>Emscripten</em> restrictions and capabilities.</p>
<h2>APIs</h2>
<p>The most annoying restriction of <em>Emscripten</em> is (arguably) related to the provided APIs. First of all, we can use pretty much all the C++ standard libraries which don’t need to interact with the system – and that’s including STL (phew). <strong>boost::</strong> libraries are not explicitly supported, but there are reports that some of them can be compiled too (not without some associated headaches); most of the header-<strong>only boost::</strong> libraries are <em>expected</em> to work with <em>Emscripten</em> ‘out of the box’ (no warranties of any kind, batteries not included).</p>
<p>As noted above, libraries which interact with the rest of the world are a different story. Contrastingly, in general, all the stuff which we’d need to use on the client is present in the APIs; in particular, the following APIs are supported:</p>
<ul>
<li>Network support (<strong>libc</strong>-style, non-blocking only(!))</li>
<li>File system access</li>
<li>Graphics (OpenGL ES – though it is better to restrict yourself to WebGL-friendly subset, as I’ve heard that emulation of the rest kinda suxx)</li>
<li>Audio, keyboard, mouse, joystick (SDL)</li>
<li>Integration with HTML5 (DOM, some of the events – including device orientation, touch, gamepad, etc.)</li>
</ul>
<h3>Threads and main loop</h3>
<p>Due to the <em>Emscripten</em> runtime being run on a top of the JS engine, threading in <em>Emscripten</em> is quite limited from the point of view of a C++ developer.</p>
<p>First of all:</p>
<p style="text-align: left;"><blockquote><big><b>Unless we’re speaking about ‘Workers’, everything within our app happens within a single ‘browser main loop’</b></big></blockquote></p>
<p>In practice, this means a few things:</p>
<ul>
<li>Our app MUST adhere to the ‘event processing’ model (i.e. if our code blocks for a while, it means that the whole page is blocked).
<ul>
<li>APIs are built in a way to help us with this; in particular, network access being non-blocking only, is a Good Thing™ from this perspective.</li>
</ul>
</li>
</ul>
<ul>
<li>If we have our own infinite loop (event processing loop, game loop, simulation loop, etc.), we’ll need to break it and re-implement it on top of the browser main loop. It is NOT as <em>bad</em> as it sounds – see <a href="http://ithare.com/not-really-so-new-niche-for-c-browser/?rabbit_open_refs=1#rabbitref-Emscripten.BrowserMainLoop">[Emscripten.BrowserMainLoop]</a> for details</li>
<li>Handling replies to asynchronous calls (such as replies to our requests which are coming from the server-side) can be a headache. For an overview of non-blocking handling techniques in C++ (though <em>not</em> taking <em>Emscripten-</em>specifics into account), see <a href="http://ithare.com/not-really-so-new-niche-for-c-browser/?rabbit_open_refs=1#rabbitref-NoBugs16">[NoBugs16]</a> and <a href="http://ithare.com/not-really-so-new-niche-for-c-browser/?rabbit_open_refs=1#rabbitref-NoBugs17">[NoBugs17]</a>.</li>
</ul>
<p>Personally, I do NOT think that this is really restrictive; in other words, I am arguing to write the code in such an event-driven manner (which I like to name ‘(Re)Actor-style’) in any case, even when there is no <em>Emscripten</em> in sight. Very briefly – considering I have been arguing that having thread sync at app-level is evil for years now (see <a href="http://ithare.com/not-really-so-new-niche-for-c-browser/?rabbit_open_refs=1#rabbitref-NoBugs10">[NoBugs10]</a> and <a href="http://ithare.com/not-really-so-new-niche-for-c-browser/?rabbit_open_refs=1#rabbitref-NoBugs15">[NoBugs15]</a>) – going for a bunch of event-driven (Re)Actors exchanging messages is a Good Thing™.</p>
<h2>Using multiple cores</h2>
<p>While I am all for event-driven single-threaded processing, I am the first one to admit that there are situations when one single thread (and as a result, a single CPU core) is not sufficient to do whatever we need to do. Which means that we do need a way to use multiple cores.</p>
<p>However, being able to use multiple cores, DOES NOT necessarily imply the need to go into traditional mutex- and atomics-ridden untestable nightmare. Rather, we can have more than one separate event processor a.k.a. (Re)Actors (in <em>Emscripten-</em>speak, additional (Re)Actors – that is, beyond the original one running within the ‘browser main loop’ – are called ‘workers’) and exchange messages with them. It provides several benefits compared to classical mutex-based shared-state synchronization models:</p>
<ul>
<li>There is no need to think about thread sync when programming.
<ul>
<li>While it comes at the price of headaches related to handling non-blocking calls, I am arguing that – in those scenarios when we need to handle intervening events anyway – non-blocking single-threaded handling is the least evil; for more discussion, see <a href="http://ithare.com/not-really-so-new-niche-for-c-browser/?rabbit_open_refs=1#rabbitref-NoBugs17">[NoBugs17]</a>.</li>
</ul>
</li>
</ul>
<ul>
<li>Each of the (Re)Actors is deterministic. This, in turn, enables several all-important improvements (from testability and replay-based testing, to production post-mortem analysis), see <a href="http://ithare.com/not-really-so-new-niche-for-c-browser/?rabbit_open_refs=1#rabbitref-NoBugs17">[NoBugs17]</a> for a detailed discussion.</li>
<li>This approach is Shared-Nothing and, as a result, it scales near-perfectly (though see the note below). This phenomenon (and problems with scaling shared states) is well-known; very briefly, each and every shared state (in other words, every mutex) carries a risk of becoming a very serious contention, causing severe degradation of scalability; moreover, in quite a few cases you may find that 90% of all your processing happens under one of the mutexes, which means that regardless of the number of cores, you cannot possibly scale more than to 1.1 core.
<ul>
<li>As discussed in <a href="http://ithare.com/not-really-so-new-niche-for-c-browser/?rabbit_open_refs=1#rabbitref-NoBugs17">[NoBugs17]</a>, the only case which I know when pure (Re)Actors-exchanging-messages are not scaling well is when we have a big unbreakable state with lots of calculations performed over it at the same time. This <em>can</em> be solved (and was solved for an AAA game Client too) without departing too much from the event-processing (Re)Actor-based ideology (using what I call (Re)Actor-with-Extractors). However, at the moment, (Re)Actor-with-Extractors is not supported by <em>Emscripten</em>, so there <em>may</em> be some issues on this way.</li>
</ul>
</li>
</ul>
<ul>
<li>(Re)Actor-based systems tend to exhibit very good performance. Discussion of performance advantages of event-driven systems over thread-synced ones is well beyond the scope of this article, but very briefly, it boils down to the costs of thread context switches (which can take anywhere between 10K and 1M CPU cycles(!)), and event-driven systems tend to have <em>much</em> fewer of these switches. From a completely different point of view, there is a reason why event-driven non-blocking systems (such as nginx) tend to beat blocking systems (such as Apache) performance-wise.</li>
</ul>
<h2>Pthread support</h2>
<p>In theory, <em>Emscripten</em> has support for pthreads. However, the support is experimental – and moreover, it is <em>Firefox-only</em>. This, of course, makes its use for serious projects a non-starter; however, my rant about pthreads goes deeper than that:</p>
<p style="text-align: left;"><em>Even in the long run, I would prefer support for (Re)Actor-with-Extractors to support for pthreads.</em></p>
<p>Sure, having full-scale pthreads, we can implement (Re)Actor-with-Extractors ourselves; however:</p>
<ul>
<li>I have no idea how difficult it will be to push pthreads into <em>all</em> the browsers (from what I’ve seen, it can easily become an insurmountable task). (Re)Actor-with-Extractors should be easier to implement (while providing all the safety guarantees – and testability too).
<ul>
<li>In addition, at least in some cases, (Re)Actor-with-Extractors <em>may</em> happen to be more efficient (it depends on specifics of pthreads implementation under each of the browsers, but in general, it might easily happen)</li>
</ul>
</li>
</ul>
<ul>
<li>Enabling pthreads would bring us back into dark ages of massive usage of mutexes – and as you may have noticed, I am a very strong opponent of mutex-based thread sync at application level. I prefer to keep my code clean in this regard.</li>
</ul>
<h2>64-bit int and 32-bit float issues</h2>
<p>As of now, the only numeric data type in JavaScript is 64-bit float; in addition, some operations (mostly bitwise ones) return 32-bit integer (which always fits into 64-bit float). As a result, any operations which are neither 64-bit float nor 32-bit integer are not 100%-efficient in <em>asm.js</em>. In particular:</p>
<ul>
<li>32-bit floats need to be processed as 64-bit floats, which is rather slow compared to native 32-bit floats</li>
<li>64-bit integers need to be simulated from 2 of 32-bit integers, which is pretty slow too.</li>
</ul>
<p>There are some proposals to deal with it (see, for example, <a href="http://ithare.com/not-really-so-new-niche-for-c-browser/?rabbit_open_refs=1#rabbitref-Zakai14">[Zakai14]</a>) but as far as I know, these slowdowns still apply, so if you’re after best-possible performance, you need to keep them in mind.</p>
<h2>Practical uses</h2>
<p>As noted above, I haven’t used <em>Emscripten</em> for a serious project (yet). However, quite a few projects were reported as compiled and working, including:</p>
<ul>
<li>Game Engines(!)
<ul>
<li>UE3 (reported to be ported in 4 days)</li>
<li>UE4</li>
<li>Unity<br />
Unity is quite an interesting beast when it comes to its use of <em>Emscripten</em>; as it uses C# at the app-level, it first re-compiles C# parts into C++ using IL2CPP compiler, and then uses <em>Emscripten</em> to compile it into <em>asm.js</em>. You won’t believe it – but it does work.☹</li>
</ul>
</li>
</ul>
<ul>
<li>Games
<ul>
<li>Quake 3</li>
<li>Doom</li>
<li>OpenDune</li>
</ul>
</li>
</ul>
<ul>
<li>Libraries/Frameworks
<ul>
<li>OpenSSL</li>
<li>SQLite</li>
<li>Pepper (via pepper.js)</li>
<li>Quite a few of Qt demos</li>
</ul>
</li>
</ul>
<p>For a much more comprehensive list of ports and demos, please refer to <a href="http://ithare.com/not-really-so-new-niche-for-c-browser/?rabbit_open_refs=1#rabbitref-Emscripten.PortingExamples">[Emscripten.PortingExamples]</a>.</p>
<h2>Competition: NaCl/PNaCl</h2>
<p>An alternative way of running C++ code on browsers, is NaCl/PNaCl by Google. It serves pretty much the same noble purpose of running C++ on the browser, however, it has the BIG problem of being restricted to Chrome. As (a) no other browser has followed suit, and (b) as Chrome market share, while it grew to about 60%, has slowed down its growth in 2016, I do NOT think that NaCl/PNaCl is a viable option (except for some very narrowly defined scenarios) – especially when comparing it to <em>Emscripten+asm.js</em>.</p>
<p>Moreover, I’ve got a <em>feeling</em> (no warranties of any kind) that Google itself has realized futility of (P)NaCl and has slowed down development as a result; overall, my <em>wild guess</em> is that in a few years from now, (P)NaCl will be quietly abandoned in favor of <em>asm.js</em> (and Google is already working on support for <em>asm.js</em> optimizations) or in favor of WebAssembly (see below).</p>
<p>As a result, while the only thing which is certain is that nothing is certain yet, if faced with the task of developing/porting a new C++ Client for browser, I would clearly prefer <em>Emscripten+asm.js</em>.</p>
<p>Oh, BTW – if you already have a (P)NaCl client, there is a library pepper.js, which aims to provide a migration path from (P)NaCl to <em>Emscripten</em>; while I didn’t try it myself – well, it <em>seems</em> to be worth trying.</p>
<h2>Ongoing development: WebAssembly a.k.a. wasm</h2>
<p>As a next step in this development (and to compensate for certain problems such as <em>asm.js</em> parsing times on mobile devices), an alternative representation – known as WebAssembly or <em>wasm</em> – is being actively worked on.</p>
<p>The idea is to use (give or take) the same C++ source code as already can be used to compile into <em>asm.js</em>, and to compile it to a very different assembler (<em>wasm</em>). Then <em>wasm</em> will be loaded into the browser, where it will be JIT-compiled and then executed.</p>
<p>There <em>seems</em> to be quite significant momentum behind <em>wasm</em> – but as of now, it is too early to tell anything specific. What matters though is that</p>
<p style="text-align: left;"><em>As app-level developers, we do NOT really care much whether it is asm.js or wasm which wins in the end. Rather, we can use asm.js right now, and hope that we won’t need to change our programs <strong>too much</strong> when re-compiling them into wasm <strong>(when/if it is widely available)</strong></em></p>
<p>Whether these hopes will stand in reality, we’ll see, but as of now, it is IMNSHO by far the best option we have to try pushing our C++ Clients into browsers.</p>
<h2>Practical uses: porting downloadable clients to the web</h2>
<p>Well, it is all this stuff is certainly technically exciting, but what can we get from it in practice? Most importantly,</p>
<p style="text-align: left;"><blockquote><big><b>we can port our (well-written-enough) C++ Clients to the web.</b></big></blockquote></p>
<p>Until two or so years ago, there was no way to port an existing downloadable Client into a web app. In other words, whatever we were doing with our C++, we weren’t able to avoid download and at least some warnings about how malicious our code can be from the browser – and this was the point where our potential users were dropping out the most.</p>
<p>So, for a long while, when deciding how to develop our Client,</p>
<p style="text-align: left;"><em>we were facing a tough choice: either to develop it in JS-only (losing all the bells, whistles, and performance of C++ development) – or to have it in C++ but at the cost of dropping those users who don’t want to download.</em></p>
<p>With <em>Emscripten</em> and <em>asm.js</em>, these problems are gone. We <em>can</em> have our C++ cake and eat it on browsers too.</p>
<p>In addition, such an option opens a door for some things that are not really widely used yet – such as creating live demo versions which can be viewed in-browser without the need to download and install them; it looks very promising for reducing drop-out rates of potential customers (as showing a live demo tends to work <em>orders of magnitude</em> better then showing a screenshot, and if we can get live demo without download, we have a clear winner).</p>
<p>Of course, to achieve this holy grail of multi-platform clients with one of the platforms being ‘web browser’, we’ll need to re-learn how to write cross-platform programs (and apparently, with all the vendor efforts to lock us in, it is not an easy feat), but as soon as we do it (and some of us were doing it all the way regardless of <em>Emscripten</em>), we will be able to have one single C++ code base over all of the following: desktops, phones/tablets, and web (with AAA gamedevs being able to add consoles to the mix too).</p>
<hr><h3>References</h3><p></p>
<p><a name="rabbitref-AreWeFastYet17"></a>[AreWeFastYet17] <a href="https://arewefastyet.com/#machine=28&amp;view=single&amp;suite=asmjs-apps">&#8220;AreWeFastYet&#8221;</a></p>
<p><a name="rabbitref-Emscripten.BrowserMainLoop"></a>[Emscripten.BrowserMainLoop] <a href="https://kripken.github.io/emscripten-site/docs/porting/emscripten-runtime-environment.html#browser-main-loop">&#8220;Emscripten Contributors, Emscripten Runtime Environment#Browser main loop&#8221;</a><br />
<a name="rabbitref-Emscripten.Porting"></a>[Emscripten.Porting] <a href="https://kripken.github.io/emscripten-site/docs/porting/index.html">&#8220;Emscripten Contributors, Porting&#8221;</a><br />
<a name="rabbitref-Emscripten.PortingExamples"></a>[Emscripten.PortingExamples] <a href="https://github.com/kripken/emscripten/wiki/Porting-Examples-and-Demos">&#8220;Emscripten Contributors, Porting Examples and Demos&#8221;</a><br />
<a name="rabbitref-Loganberry04"></a>[Loganberry04] David ‘Loganberry’, <a href="http://bitsnbobstones.watershipdown.org/lapine/overview.html">&#8220;Frithaes! – an Introduction to Colloquial Lapine!&#8221;</a><br />
<a name="rabbitref-NoBugs10"></a>[NoBugs10] ‘No Bugs’ Hare, &#8220;Single-Threading: Back to the Future? Overload #97/#98&#8221;<br />
<a name="rabbitref-NoBugs15"></a>[NoBugs15] ‘No Bugs’ Hare, &#8220;Multi-threading at Business-logic Level is Considered Harmful&#8221;, <a href="http://accu.org/var/uploads/journals/Overload128.pdf">Overload #128</a><br />
<a name="rabbitref-NoBugs16"></a>[NoBugs16] ‘No Bugs’ Hare, <a href="http://ithare.com/asynchronous-processing-for-finite-state-machines-actors-from-plain-events-to-futures-with-oo-and-lambda-call-pyramids-in-between/">&#8220;Asynchronous Processing for Finite State Machines/Actors: from plain event processing to Futures (with OO and Lambda Call Pyramids in between)&#8221;</a><br />
<a name="rabbitref-NoBugs17"></a>[NoBugs17]  ‘No Bugs’ Hare, &#8220;Vol.II, chapter on (Re)Actors&#8221;, current beta available at Leanpub and Indiegogo<br />
<a name="rabbitref-Resig13"></a>[Resig13] John Resig, <a href="http://ejohn.org/blog/asmjs-javascript-compile-target/">&#8220;Asm.js: The JavaScript Compile Target&#8221;</a><br />
<a name="rabbitref-TIOBE17"></a>[TIOBE17] <a href="http://www.tiobe.com/tiobe-index/">&#8220;TIOBE Index (February 2017)&#8221;</a><br />
<a name="rabbitref-Widman16"></a>[Widman16] Jake Widman, <a href="https://blog.newrelic.com/2016/08/18/popular-programming-languages-2016-go/">&#8220;The Most Popular Programming Languages of 2016&#8221;</a><br />
<a name="rabbitref-Zakai14"></a>[Zakai14] Alon Zakai, <a href="http://kripken.github.io/mloc_emscripten_talk/sloop.html#/">&#8220;NATIVE SPEED ON THE WEB. JAVASCRIPT &amp; ASM.JS&#8221;</a></p>
<p></p><h3>Disclaimer</h3><p>as usual, the opinions within this article are those of ‘No Bugs’ Hare, and do not necessarily coincide with the opinions of the translators and <em>Overload</em> editors; also, please keep in mind that translation difficulties from Lapine (like those described in <a href="http://ithare.com/not-really-so-new-niche-for-c-browser/?rabbit_open_refs=1#rabbitref-Loganberry04">[Loganberry04]</a>) might have prevented an exact translation. In addition, the translator and <em>Overload</em> expressly disclaim all responsibility from any action or inaction resulting from reading this article.</p><h3>Acknowledgement</h3><p>Cartoons by Sergey Gordeev<sup><a style="border:none;" href="/real-people-behind-the-hare#sergey-gordeev"><img width="16" height="16" src="/wp-content/uploads/irl-link.png" alt="IRL" style="position:relative; bottom:3px;"></a></sup> from <a href="http://gagltd.eu/">Gordeev Animation Graphics</a>, Prague.</p><h3>P.S.</h3><p>Don&#39;t like this post?&nbsp;<b><a href="http://ithare.com/not-really-so-new-niche-for-c-browser/#rabbit-comment">Criticize&#8623;</a></b></p><h3>P.P.S.</h3><p>We've tried to optimize our feed for viewing in your RSS viewer. However, our pages are quite complicated, so if you see any glitches when viewing this page in your RSS viewer, please refer to our <a href="http://ithare.com/not-really-so-new-niche-for-c-browser/">original page</a>.</p>
]]></description>
		<wfw:commentRss>http://ithare.com/not-really-so-new-niche-for-c-browser/feed/</wfw:commentRss>
		<slash:comments>0</slash:comments>
		</item>
		<item>
		<title>Access Control for Admin Tools</title>
		<link>http://ithare.com/access-control-for-admin-tools/</link>
		<comments>http://ithare.com/access-control-for-admin-tools/#respond</comments>
		<pubDate>Tue, 25 Jul 2017 15:16:51 +0000</pubDate>
		<dc:creator><![CDATA["No Bugs" Hare]]></dc:creator>
				<category><![CDATA[D&D of MOGs: Vol. VII-IX (1st beta)]]></category>
		<category><![CDATA[Development & Deployment of Multiplayer Online Games]]></category>
		<category><![CDATA[Manager]]></category>
		<category><![CDATA[multiplayer]]></category>
		<category><![CDATA[Server]]></category>

		<guid isPermaLink="false">http://ithare.com/?p=9983&#038;rabbit_rss_ver=23</guid>
		<description><![CDATA[
<div class="rabbit-img"><a href="/wp-content/uploads/BB_part160_BookChapter26c_v1.png"><img class="wp-image-9990 size-medium" src="/wp-content/uploads/BB_part160_BookChapter26c_v1-640x427.png" alt="Access Control - The Hard (Boot) Way" width="640" height="427" /></a></div>
<div class="rabbit-img-right"><a href="/contents-of-development-and-deployment-of-massively-multiplayer-games-from-social-games-to-mmofps-with-stock-exchanges-in-between/#vol7"><img src="/wp-content/uploads/bbbook_cover_vol07_-330.png" alt="#DDMoG, Vol. VII" width="220" height="220" /></a></div><p>[[<em>This is Chapter 26(b) from “beta” Volume VII of the upcoming book "Development&Deployment of Multiplayer Online Games", which is currently being beta-tested. Beta-testing is intended to improve the quality of the book, and provides free e-copy of the "release" book to those who help with improving; for further details see "<a href="/book-beta-testing-development-and-deployment-of-massively-multiplayer-games-from-social-games-to-mmofps-with-stock-exchanges-in-between/">Book Beta Testing</a>". All the content published during Beta Testing, is subject to change before the book is published. </em><p><em>To navigate through the "1st beta" of the book, you may want to use <a href="/contents-of-development-and-deployment-of-massively-multiplayer-games-from-social-games-to-mmofps-with-stock-exchanges-in-between/#toc">Development&amp;Deployment of MOG: Table of Contents</a>.</em>]]
<p>Last but certainly not least when speaking about Admin Tools, we need to have some kind of access control. The reason for it is simple –</p>
<blockquote><big><b>As soon as your company has more than a dozen of people working with the tools, risks of just <em>one </em>of them causing trouble, become way too high to be ignored.</b></big></blockquote>
<p>BTW, it stands even when all your CSRs are completely honest: even a perfectly honest CSR can press a wrong button in that-form-which-was-intended-ONLY-for-admins – and bring your system to knees without really understanding what is going on.</p>
<p>On the other hand, for the bottom line of your company (and our current purposes) it doesn’t really matter why the system has stopped – because of malicious intent, or because of using the wrong tool for the job. What matters – is that</p>
<blockquote><big><b>You DO need access control for your CSRs.</b></big></blockquote>
<p><img width="170" height="170" src="/wp-content/uploads/BB_emotion_0025b.png" />There are many ways to implement access control; some of them don’t work at all,<a href="#rabbitfootnote-1"><sup>1</sup></a> some do work but are cumbersome, and some do work while being very simple. We’ll concentrate on one of the latter approaches – which was seen to work really good in a real-world game company with over a thousand employees-who-need-access-admin-tools.</p>
<hr class="rabbit-footnote-separator" /><a name="rabbitfootnote-1"></a><div class="rabbit-footnote"><sup>1</sup> those who tried to implement Bell-LaPadula access model in a real world, will certainly agree with this statement &lt;sigh /&gt;</div>
<p>&nbsp;</p>
<h2>Prerequisites</h2>
<p>To deal with our task, we’ll assume that:</p>
<ul>
<li>Each person who needs accessing admin tools, has an account.
<ul>
<li>How to authenticate these admin accounts – depends, though <em>at least </em>for highly-privileged accounts some kind of two-factor authentication (2FA) is desirable.</li>
<li>Another question is whether admin accounts should be just ordinary player accounts with an ‘admin’ flag – or a completely separate DB table. I’ve seen both these approaches working reasonably well, though probably, if starting a new system, I’d vote for having a separate table for admin accounts. Actually, the whole question here is about “are there more similarities or differences between player accounts and admin accounts?” – and more often in the long run we’ll see that there are more differences than similarities.</li>
</ul>
</li>
<li>Each of the actions we’re doing, has an “Action Verb” associated with it, and the code calls a special function which indicates whether currently-logged-in user has right to perform “Action Verb”. For example – a report showing player data, MUST call something like <em>userHasAccess(current_session,”ViewPlayer”) </em>– and abort if the result is <em>false</em>. In a similar manner, a Control admin tool stopping the system, MUST check that <em>userHasAccess(current_session,”StopSystem”) </em>– and so on.</li>
</ul>
<h2>Mapping</h2>
<p>As soon as we got our accounts and our “Action Verbs” (hardcoded, as defined above), all we need to do – is to provide some kind of mapping between them.</p>
<p>In theory – we could even hardcode this mapping into our code; OTOH, on the practice, such hardcoding is <em>highly undesirable</em>. Instead –</p>
<blockquote><big><b>We certainly want this relation between accounts and “Action Verbs” to be modifiable by non-programmers via Admin Tools.</b></big></blockquote>
<p>Also let’s note that because we have both read-only reports and tools – we need to have this access information easily retrievable both via “DB Object” (this will be used by tools), and directly from SQL DB without any additional layer (used by reports, it is usually ok as long as we’re checking permissions for a read-only report). The latter means that we do want the retrieval of this mapping (more specifically – answering a question of “whether this user has this Action Verb allowed?”) to be available via an efficient SQL request.</p>
<h3>Take 1: Simple Mapping</h3>
<p>This “efficient SQL” requirement effectively rules out trees of arbitrary depth within SQL (such arbitrary trees are <em>notoriously </em>poorly performing in SQL).</p>
<p>Still, we can easily have the following tables in our SQL DB:</p>
<pre class="brush: sql; title: ; notranslate">CREATE TABLE GROUPS(
  GROUP_ID INT,
  GROUP_NAME VARCHAR(30),
  PRIMARY_KEY(GROUP_ID),
 UNIQUE(GROUP_NAME) --or CONSTRAINT, or whatever-else
);

CREATE TABLE GROUPS_VERBS(
  GROUP_ID INT,
  VERB VARCHAR(30),-- ACTUALLY, IT IS BETTER TO USE VERB_ID,
                   -- BUT FOR OUR EXAMPLE IT WILL DO
  PRIMARY_KEY(GROUP_ID,VERB)
    -- ORDER WITHIN PRIMARY_KEY MAY MATTER: 
    --                   AS WE’LL BE USUALLY LOOKING
    --                   VIA GROUP_ID, HAVING IT
    --                   AS THE FIRST FIELD IN INDEX
    --                   WILL USUALLY HELP
);

CREATE TABLE GROUPS_ACCOUNTS(
  GROUP_ID INT,
  ACCOUNT_ID INT,
  PRIMARY_KEY(ACCOUNT_ID,GROUP_ID)
    -- ORDER WITHIN PRIMARY_KEY MAY MATTER: 
    --                   AS WE’LL BE USUALLY LOOKING
    --                   VIA ACCOUNT_ID, HAVING IT
    --                   AS THE FIRST FIELD IN INDEX
    --                   WILL USUALLY HELP
);
</pre>
<p>Then, the following operations can be easily (and efficiently) supported:</p>
<ul>
<li>All the tables GROUPS, GROUPS_VERBS, and GROUPS_ACCOUNTS should be editable via Admin Tools (NB: the admin tool which allows to do it should have its own “Action Verb” too, as it is one of the most dangerous actions in the system)</li>
<li>Checking whether certain ACCOUNT has certain VERB – is a simple SELECT over a trivial JOIN of GROUPS_ACCOUNTS with GROUPS_VERBS (ON GROUP_ID). On any half-decent SQL DB it is completed instantly.</li>
</ul>
<p>This simplistic model will allow your management to create group CSR, to decide which operations are allowed for all CSRs, and to add/remove CSRs to this group (and then there will be groups SENIOR_CSR, PAYMENT_CSR, MANAGEMENT, and so on).</p>
<h3>Take 2: “Compiled” Mappings</h3>
<p><img width="170" height="170" src="/wp-content/uploads/BB_emotion_0022b.png" />The simple model discussed above, will usually be sufficient for a while. However, at the point when number of active CSRs goes above 50-100 (and/or number of GROUPS goes above 8-10) – this simplistic model will likely start to be too restricting for CSR management folks. In particular – they will want to have hierarchies of the groups (so a group can include other groups – or, in other words, PAYMENT_CSRs should be able to <em>inherit</em> all the permissions/VERBs of CSRs – plus add a few other permissions too); another popular request is to have “negative groups” (so that there is an option to inherit “everything <em>except </em>these few VERBs”).</p>
<p>At this point, you are likely to say “hey! But it means arbitrary trees, which you&#8217;ve already ruled out!”. You’re right, but fortunately for me, I have a good answer ;-).</p>
<p>I still do NOT want to <em>retrieve</em> arbitrary trees from SQL <em>every time</em> we need to make an access control check. However, we can observe that to answer our eternal question “whether the user X has permission Y” – <em>any </em>kind of the permission tree can be represented via even simpler mapping than the one above: we can have one single relation table</p>
<pre class="brush: sql; title: ; notranslate">CREATE TABLE ACCOUNTS_VERBS(
  ACCOUNT_ID INT,
  VERB VARCHAR(30),-- AS ABOVE, IT IS BETTER TO USE VERB_ID,
                   -- BUT FOR OUR EXAMPLE IT WILL DO
  PRIMARY_KEY(ACCOUNT_ID,VERB)
);
</pre>
<p>Alternatively – we could keep the tables discussed in “Take 1” intact.</p>
<p>Then, we can do the following:</p>
<ul>
<li>Store the groups tree in SQL – but to retrieve it <em>only </em>to show it to management-like admins when they want to modify it.</li>
<li>Whenever they decide to modify the access tree, <em>in addition </em>to modifying the tree, we can <em>calculate </em>a new content of the ACCOUNTS_VERBS table<a href="#rabbitfootnote-2"><sup>2</sup></a> which will provide <em>exactly </em>the same access as described in the tree (this is certainly possible and not a rocket science) and re-populate ACCOUNT_VERBS table with the new content (in the same ACID transaction as modifying the tree itself).
<ul>
<li>BTW, this can be implemented very easily within the architecture-I-recommend (discussed in Vol. III and Vol. VI), which <em>requires </em>that <em>all </em>the modifications MUST go via separated “DB Server”, so adding an in-memory calculation of the “compiled” rights is trivial.</li>
<li>Of course, it will lead to a multi-row update, which is a relatively heavy operation for OLTP – but (a) as it is still just <em>hundreds </em>of rows (and not millions), and (b) as <em>changing </em>access rights tends to happen about 100’000x less frequently than <em>checking </em>them – this is still an extremely good deal performance-wise.</li>
</ul>
</li>
</ul>
<p><img width="170" height="170" src="/wp-content/uploads/BB_emotion_0012b.png" />This approach means that we can have our cake (have tree-like structures to express access rights) and eat it too (have very fast SQL for checking access). Moreover, we can start with a simpler Take 1 – and to add “compiling” the tree into flat access relation table(s) more-or-less easy later, when/if it becomes necessary.</p>
<p>That is my story of access rights for Admin Tools.</p>
<hr class="rabbit-footnote-separator" /><a name="rabbitfootnote-2"></a><div class="rabbit-footnote"><sup>2</sup> or, if we keep structure from Take 1- of GROUPS, GROUPS_VERBS, and GROUPS_ACCOUNTS tables</div>
<p>&nbsp;</p>
<h2>[[To Be Continued&#8230;</h2>
<p><img width="170" height="170" src="/wp-content/uploads/BB_emotion_0001b.png" />This concludes beta Chapter 26(c) from the upcoming book &#8220;Development and Deployment of Multiplayer Online Games (from social games to MMOFPS, with social games in between)&#8221;.</p>
<p>Stay tuned for beta Chapter 27(a), where we&#8217;ll start discussing ways of OLTP DB optimization]]</p>
<p>&nbsp;</p>
<hr><h3>Acknowledgement</h3><p>Cartoons by Sergey Gordeev<sup><a style="border:none;" href="/real-people-behind-the-hare#sergey-gordeev"><img width="16" height="16" src="/wp-content/uploads/irl-link.png" alt="IRL" style="position:relative; bottom:3px;"></a></sup> from <a href="http://gagltd.eu/">Gordeev Animation Graphics</a>, Prague.</p><h3>P.S.</h3><p>Don&#39;t like this post?&nbsp;<b><a href="http://ithare.com/access-control-for-admin-tools/#rabbit-comment">Criticize&#8623;</a></b></p><h3>P.P.S.</h3><p>We've tried to optimize our feed for viewing in your RSS viewer. However, our pages are quite complicated, so if you see any glitches when viewing this page in your RSS viewer, please refer to our <a href="http://ithare.com/access-control-for-admin-tools/">original page</a>.</p>
]]></description>
		<wfw:commentRss>http://ithare.com/access-control-for-admin-tools/feed/</wfw:commentRss>
		<slash:comments>0</slash:comments>
		</item>
		<item>
		<title>Help Desk Software for MOGs</title>
		<link>http://ithare.com/help-desk-software-for-mogs/</link>
		<comments>http://ithare.com/help-desk-software-for-mogs/#comments</comments>
		<pubDate>Wed, 19 Jul 2017 04:13:55 +0000</pubDate>
		<dc:creator><![CDATA["No Bugs" Hare]]></dc:creator>
				<category><![CDATA[D&D of MOGs: Vol. VII-IX (1st beta)]]></category>
		<category><![CDATA[Development & Deployment of Multiplayer Online Games]]></category>
		<category><![CDATA[multiplayer]]></category>
		<category><![CDATA[Server]]></category>

		<guid isPermaLink="false">http://ithare.com/?p=9952&#038;rabbit_rss_ver=23</guid>
		<description><![CDATA[
<div class="rabbit-img"><a href="/wp-content/uploads/BB_part159_BookChapter26b_v3.png"><img class="wp-image-9976 size-medium" src="/wp-content/uploads/BB_part159_BookChapter26b_v3-640x427.png" alt="CSRs supporting Game Worlds" width="640" height="427" /></a></div>
<div class="rabbit-img-right"><a href="/contents-of-development-and-deployment-of-massively-multiplayer-games-from-social-games-to-mmofps-with-stock-exchanges-in-between/#vol7"><img src="/wp-content/uploads/bbbook_cover_vol07_-330.png" alt="#DDMoG, Vol. VII" width="220" height="220" /></a></div><p>[[<em>This is Chapter 26(b) from “beta” Volume VII of the upcoming book "Development&Deployment of Multiplayer Online Games", which is currently being beta-tested. Beta-testing is intended to improve the quality of the book, and provides free e-copy of the "release" book to those who help with improving; for further details see "<a href="/book-beta-testing-development-and-deployment-of-massively-multiplayer-games-from-social-games-to-mmofps-with-stock-exchanges-in-between/">Book Beta Testing</a>". All the content published during Beta Testing, is subject to change before the book is published. </em><p><em>To navigate through the "1st beta" of the book, you may want to use <a href="/contents-of-development-and-deployment-of-massively-multiplayer-games-from-social-games-to-mmofps-with-stock-exchanges-in-between/#toc">Development&amp;Deployment of MOG: Table of Contents</a>.</em>]]
<p>One thing which is almost-universally neglected in real-world MOGs – while being of paramount importance – is Help Desk Software.</p>
<h2>On Importance of Support for MOGs</h2>
<p>In a single-player gamedev world, the relative importance of different player-visible aspects is usually seen by management along the following lines (Table 26.1):<a href="#rabbitfootnote-1"><sup>1</sup></a></p>
<table>
<tbody>
<tr>
<td style="text-align: center;">Content (which is King)</td>
</tr>
<tr>
<td style="text-align: center;">More Content</td>
</tr>
<tr>
<td style="text-align: center;">Even More Content</td>
</tr>
<tr>
<td style="text-align: center;">Visual Effects</td>
</tr>
<tr>
<td style="text-align: center;">Rest of 3D Graphics</td>
</tr>
<tr>
<td style="text-align: center;">Gameplay</td>
</tr>
<tr>
<td style="text-align: center;">Sound/Music</td>
</tr>
<tr>
<td style="text-align: center;">That’s it – nothing else matters (=”zero importance level”)</td>
</tr>
<tr>
<td style="text-align: center;">Support (importance is below zero)</td>
</tr>
</tbody>
</table>
<p>As this book is about MOGs, I won’t elaborate on the reasons behind this (IMO pitiful) state of affairs, though will briefly mention that:</p>
<ul>
<li>Prioritizing Content before Gameplay <em>seems</em> to go against players&#8217; wishes even for single-player games (see, for example, discussions on <a href="http://ithare.com/help-desk-software-for-mogs/?rabbit_open_refs=1#rabbitref-GameSpot">[GameSpot]</a> and <a href="http://ithare.com/help-desk-software-for-mogs/?rabbit_open_refs=1#rabbitref-GiantBomb">[GiantBomb]</a> to get a few examples of player&#8217;s opinions)</li>
<li>IMNSHO it largely steams from:
<ul>
<li>most of AAA gamedev companies working along the lines of movie production companies, and</li>
<li>an average game reviewer being unable to judge anything but shiny graphics.</li>
</ul>
</li>
<li>As long as it is about single-player games, it isn&#8217;t much of our concern within the context of this book.</li>
</ul>
<p>For a typical MOGs<a href="#rabbitfootnote-2"><sup>2</sup></a>, however, situation changes <em>drastically </em>(Table 26.2):<a href="#rabbitfootnote-3"><sup>3</sup></a></p>
<table>
<tbody>
<tr>
<td style="text-align: center;" colspan="5">Gameplay</td>
</tr>
<tr>
<td style="text-align: center;" colspan="5">More Gameplay</td>
</tr>
<tr>
<td style="text-align: center;">Content</td>
<td style="text-align: center;">Graphics (can be very rudimentary<a href="#rabbitfootnote-4"><sup>4</sup></a>)</td>
<td style="text-align: center;">Payments</td>
<td style="text-align: center;">Support</td>
<td style="text-align: center;">Connectivity</td>
</tr>
<tr>
<td style="text-align: center;" colspan="5">Sound/Music</td>
</tr>
</tbody>
</table>
<p><a href="#_ftnref4" name="_ftn4"></a></p>
<p>As we can see –</p>
<blockquote><big><b>for MOGs, support becomes one of the very important parts of the picture,<br />
often on par with Content and Graphics.</b></big></blockquote>
<p><img width="170" height="170" src="/wp-content/uploads/BB_emotion_0012b.png" />This, in turn, makes your Support Team one of the substantial overall teams of your multiplayer game. Once upon a time, I’ve seen myself a very successful multiplayer game, where gameplay was mostly on par with a competition (and graphics was admittedly worse) – and the competitive advantage over the competition stemmed from two things: (a) reliable software (including better handling of connectivity issues), and (b) <em>much </em>better quality of support (which included non-trivial stuff such as security complaints etc. etc.). <em>These two things were apparently sufficient to overtake the whole competition and get about 50% market share of the whole niche (making over a billion dollars in revenues per year in the process).</em><em> </em></p>
<p>One last note aimed to CEOs and financial guys:</p>
<blockquote><big><b>DO NOT consider your Support Team an expense.</b></big></blockquote>
<p>Rather, your Support Team should be seen <em>as a way to improve overall customer experience </em>(and this, in turn, is Extremely Important™ for competitive MOG niches)<em>. </em>As noted above, this approach of “Support Team to improve Experience”), in turn, has been observed to provide a <em>big competitive advantage </em>(as noted above – at least in one case it was one of two key points which have proven to be sufficient to grab 50% of the market share, and to make a billion a year).</p>
<hr class="rabbit-footnote-separator" /><a name="rabbitfootnote-1"></a><div class="rabbit-footnote"><sup>1</sup> As we’re speaking about <em>player-visible </em>features – marketing, monetization, and Back-End Tools are intentionally set aside</div><a name="rabbitfootnote-2"></a><div class="rabbit-footnote"><sup>2</sup> whatever it means</div><a name="rabbitfootnote-3"></a><div class="rabbit-footnote"><sup>3</sup> as always, YMMV</div><a name="rabbitfootnote-4"></a><div class="rabbit-footnote"><sup>4</sup> as it was discussed in Vol. II – there are successful MOGs out there with an <em>extremely </em>rudimentary graphics (such as static 2D images).</div>
<p>&nbsp;</p>
<h2>Help Desk Requirements</h2>
<h3>E-mails vs Tickets vs Live Chat vs Phone</h3>
<p>With this in mind, let’s see what we can do to help our Support Team to keep our players happy. First, let’s note that most of the time,</p>
<blockquote><big><b>We do NOT want to provide available-to-everybody live chat, or phone support.</b></big></blockquote>
<p>There are two Big Reasons™ for it:</p>
<ul>
<li><img width="170" height="170" src="/wp-content/uploads/BB_emotion_0027b.png" />the quality of support when using synchronous support methods such as live chat (and even worse – with phone support) tends to be <em>significantly worse</em> compared to asynchronous support such as e-mails/tickets. This happens because of several factors:
<ul>
<li>With emails/tickets – your CSRs are working in a not-too-stressful environment of “hey, I have time to think about it (or to chill out) if I need”. With live chat and phone support – CSRs are in a fundamentally different and extremely stressful mode of “I need to answer <em>right away</em>”, and you’ll see very soon that <em>finding knowledgeable people willing to do it in such a stressful environment, is apparently next-to-impossible. </em>Looking at the very same thing from the opposite side – there is a reason why nobody is willing to work in call centers, and this is exactly related to the <em>stress </em>(which is inherently higher for <em>synchronous </em>communications such as chat/phone, than for <em>asynchronous </em>communications such as e-mails).</li>
<li>Time “on hold” is a biiiiig source of frustration for the customer for both live chat and phones.</li>
<li>Redirects from the 1<sup>st</sup> level support to upper levels – which are inevitable for any non-trivial request – are Really Ugly™ for live chat/phone (while being 100% invisible for e-mails).
<ul>
<li>Moreover – as upper-level support is not always-available – it often causes the customer to make multiple calls to deal with one single issue (ouch!). To make things even worse – it is <em>extremely </em>frustrating to the the customer to wait “on hold”, then to go via identification questions (with lots of spelling involved) – only to learn that the person-who-can-handle-it is not available, so she needs to call again &lt;double-ouch! /&gt;.</li>
</ul>
</li>
<li>Over-the-phone identification is extremely time consuming and error-prone; on the other hand, over e-mail it is rather trivial (those who tried to spell Rumpelstiltskin over the phone at least once, will be 100% on my side).</li>
</ul>
</li>
<li>Compared to e-mails/tickets, live chat happens to be expensive, and phone support is even worse (that’s even taking into account lackluster salaries – and associated drop in support quality). The difference in efficiency between e-mail-handing CSRs (where a single 1<sup>st</sup>-level CSR – given right tools &#8211; can handle up to 200-300 hundred e-mails per shift), and live chat/phone CSRs (at most 100 and 50 interactions per shift respectively) – is just way too large to be ignored.<a href="#rabbitfootnote-5"><sup>5</sup></a></li>
</ul>
<p>Overall,</p>
<blockquote><big><b>It is MUCH better to have a customer’s e-mail answered within 15 minutes with a good advice – than to force the same customer to wait for those 15 minutes on hold, just to get a reply “sorry, the only person who can answer your question, is busy with another customer<a href="#rabbitfootnote-6"><sup>6</sup></a>”</b></big></blockquote>
<hr class="rabbit-footnote-separator" /><a name="rabbitfootnote-5"></a><div class="rabbit-footnote"><sup>5</sup> Note that my numbers are even-more-favorable-for-e-mails the those found in <a href="http://ithare.com/help-desk-software-for-mogs/?rabbit_open_refs=1#rabbitref-Hanke">[Hanke]</a> – but I did observe such numbers first-hand. <em>Plus, </em>as noted above – synchronous methods often cause unnecessary second calls (which will bring overall performance of the live-chat or phone support even further down)</div><a name="rabbitfootnote-6"></a><div class="rabbit-footnote"><sup>6</sup> actually – spending her valuable time on trying to spell the name Rumpelstiltskin over the phone</div>
<p>&nbsp;</p>
<p><a href="#_ftnref6" name="_ftn6"></a></p>
<h4></h4>
<h4>Exceptions – when Live Chat/Phone are ok</h4>
<p>That being said, I’ve seen Live Chat/Phone teams working well and efficiently; however – all of such instances had one very important property:</p>
<blockquote><big><b>To be efficient – Live Chat/Phone should be initiated <em>by your side</em>, not <em>by player</em>.</b></big></blockquote>
<p>Examples of such synchronous-support-initiated-by-your-side include such things as “there is a complicated problem,<a href="#rabbitfootnote-7"><sup>7</sup></a> let’s schedule a phone call to discuss it“ and “hey, you have a problem depositing, let us help you over the phone”. And whenever the call is initiated by <em>your</em> side – most of the negatives of live-chat/phone go away (you can control expenses easily, your CSR is calling well-prepared, there are much less angry customers, etc.).</p>
<hr class="rabbit-footnote-separator" /><a name="rabbitfootnote-7"></a><div class="rabbit-footnote"><sup>7</sup> =“we’re about to ban you if you don’t provide a good explanation”</div>
<p>&nbsp;</p>
<h4>E-mails vs Tickets</h4>
<p>After my broadside against synchronous support methods such as phone and live chat – let’s discuss the differences between asynchronous ones – e-mails and tickets. For these two – I am quite convinced that <em>while tickets are perfectly fine for B2B support </em>(such as your-admins-contacting-your-ISP)<em>, forcing your B2C customers/players into ticket system is not really realistic.</em></p>
<p>Actually, if you try to use tickets for your players – there are only two scenarios (which end essentially the same):</p>
<ul>
<li>You DO provide a support e-mail in addition to ticket submission system. Then – you can be 100% sure, that <em>lots </em>of your players <em>will </em>send you e-mails without any ticket references, so you will still need to have a way to map e-mails into tickets very easily.</li>
<li>You DON’T provide such an e-mail (i.e. you ONLY support tickets). This is likely to cause too much frustration for your players, <em>even more so if you’ll require your players to login into your support ticket app</em>.
<ul>
<li>We should keep in mind that players are coming to your site to <em>play</em>, not to <em>login-then-watch-in-a-separate-browser-window-for-your-helpdesk-replies-etc.</em> Moreover – as players perceive a vast majority of the support requests to be <em>your </em>problems,<a href="#rabbitfootnote-8"><sup>8</sup></a> requiring them to jump through the hoops just to complain about these problems, will pretty much inevitably be seen as “adding insult to injury” by a large portion of your player population. Sure, it will reduce your support load – but doing it at the cost of losing customer satisfaction is very rarely a good deal.</li>
</ul>
</li>
</ul>
<p>As a result –</p>
<blockquote><big><b>While you MAY use “tickets” as an implementation detail – you MUST make sure that your Help Desk software handles incoming e-mails <em>flawlessly </em>and <em>seamlessly</em>.</b></big></blockquote>
<p>Moreover, for B2C style of interactions I tend to prefer e-mail-centric systems to ticket-centric ones. While in fact <em>both </em>ticket-centric and e-mail-centric approaches may work, the ticket-based system implies that the customer restricts all the communications within one single ticket to one single topic; with real-world B2C customers, there is no way to ensure this style of communication, which in turn causes quite a bit of confusion. On the other hand, with e-mail-centric systems, the unit we’re dealing with, is <em>ongoing conversation with one single player</em>; this <em>conversation </em>tends to match player expectations much better than tickets which are rather-artificial-from-his-point-of-view.</p>
<h4>Number of E-mails to Expect</h4>
<blockquote><p>Let me give you some numbers.</p>
<p>1, 2, 3, 4, 5, &#8230;</p>
<p></p>&#8212; undisclosed CEO &#8212;</blockquote>
<p>To get an idea about the numbers of CSRs you’ll need – let’s provide a few numbers. For a game with 100K simultaneous players 24&#215;7 – you can expect of the order of 10K e-mails per day (though YMMV greatly, <em>plus </em>keep in mind that the better your support is – the more e-mails you’ll get;<a href="#rabbitfootnote-9"><sup>9</sup></a> still – spending <em>more </em>time on support usually qualifies as a very good investment, as good support clearly increases customer satisfaction).</p>
<p><img width="170" height="170" src="/wp-content/uploads/BB_emotion_0006b.png" />As a 1<sup>st</sup>-line CSR (given good tools, at least along the lines discussed below) can handle about 25-35 e-mails per hour – very roughly we’re speaking about 10-15 round-the-clock 1<sup>st</sup>-line CSRs per every 100K of your simultaneous players.</p>
<p>1<sup>st</sup>-level CSRs will handle simple well-defined cases such as “I forgot my password” (no matter how prominent your login box shows “Forgot password?” – roughly half of your support e-mails will be about it), and will forward more complicated cases to the upper levels of support. Unfortunately, duties of the upper levels vary <em>way too significantly </em>to provide any estimates; in other words – you’ll need to find it out yourself.</p>
<hr class="rabbit-footnote-separator" /><a name="rabbitfootnote-8"></a><div class="rabbit-footnote"><sup>8</sup> regardless of whether it is actually the case</div><a name="rabbitfootnote-9"></a><div class="rabbit-footnote"><sup>9</sup> or the other way around – the worse support you have, the less people will want to use it for the 2<sup>nd</sup> time (preferring to abandon playing your game instead).</div>
<p>&nbsp;</p>
<h3>E-mail Help Desk: Features</h3>
<p>As mentioned above – right tools are clearly The Key™ to make job of your CSRs (especially 1<sup>st</sup>-line CSRs) efficient.<a href="#rabbitfootnote-10"><sup>10</sup></a> Moreover, the better tools you give them –&gt; the more mundane work you will be able to take off their shoulders –&gt; the more work satisfaction your CSRs will have –&gt; the better people you’ll be able to hire as your CSRs -&gt; the better support you will provide to your players. And this is beyond an obvious observation that the better tools your CSRs have – the better help they will be able to provide from a purely technical point of view.</p>
<p>As a result, you MUST NOT underestimate importance of your Help Desk software. In particular, the following features are IMO The Absolute Must™ for anything which dares to be named Help Desk:</p>
<ul>
<li>From the player’s perspective – your Help Desk system SHOULD operate <em>without</em> the need to login to see the progress. Instead – as discussed above, systems which allow any player to get support using nothing but existing-player’s-e-mail are <em>strongly </em>preferred over those which <em>require</em> player to jump through the hoops of creating a separate HelpDesk account &lt;ouch /&gt;.
<ul>
<li>Having web form as an <em>optional </em>way to get support is a completely different story &#8211; and is actually desirable (see also below on spam filters).</li>
</ul>
</li>
<li><img width="170" height="170" src="/wp-content/uploads/BB_emotion_0010b.png" />From the CSR&#8217;s perspective, serious support needs LOTS of stuff:
<ul>
<li>Anti-spam filter. While these days it is more-or-less standard feature – keep in mind that it should be tunable, and as a rule of thumb – it should be tuned on “it is MUCH better to let a bit of spam in, rather than to throw away legitimate e-mail”. In other words – make sure that your anti-spam filter is on a cautious side.
<ul>
<li>Your anti-spam filter MUST treat <em>all </em>known e-mail addresses (<em>both </em>those from previous conversations – <em>and </em>from your player accounts in your DB) – as white-listed.</li>
<li>Your anti-spam filter MUST store all the e-mails for a long time, <em>and </em>your system MUST automatically retrieve all-the-e-mails-from-spam-folder-which-came-from-email-address-X at the very moment when the CSR associates e-mail X with a player’s account.</li>
<li>Also, as no anti-spam filter can be made 100% free from “false positives”, you also MUST have a way to send you messages <em>bypassing</em> anti-spam filter; in practice – a form on your website with recaptcha, usually does the trick as such a <em>supplementary </em>way to contact you (just in case if your anti-spam filter gets overzealous-for-any-reason on this particular player)</li>
</ul>
</li>
<li><em>Automated</em> identification of incoming e-mails and associating them with the player account. In particular:
<ul>
<li>If a player was using this e-mail address <em>either</em> in a previous conversation, <em>or </em>it is listed in the player’s account itself, his e-mail MUST be automatically associated with the account (with no action by CSR required <em>at all</em>).
<ul>
<li>CSR should have an ability to override automated identification – but you should monitor how often it happens (to make sure that you automated identification algorithms are still in shape – and to fix the problems when they arise).</li>
</ul>
</li>
<li>If there are two or more such players – <em>all </em>such accounts SHOULD be listed, so CSR can merely select one of them.</li>
<li>If the e-mail is coming completely “out of blue” – then it becomes a job of the CSR to associate it with a player’s account (and since this point, according to the rules above – <em>all</em> e-mails from this e-mail address MUST be associated automatically).</li>
<li>With this automated identification – the information about the associated player (AND about all the recent e-mails with this player) MUST be available to your CSR in at most one click. Normally – there should be at least two links easily available from the e-mail:
<ul>
<li>A link into Back-End Tools for all the information about this player</li>
<li>In addition – usually, a separate link should be available, leading to the list of all the e-mail exchanges with this player (regardless of the e-mail account where these e-mails came from, <em>and </em>regardless of the “tickets”)</li>
<li>Moreover – SOME of the information should be shown right there in the e-mail queue; at least – an associated player ID SHOULD be shown, but depending on your game, 2-3 additional parameters from player’s account should be also possible; what exactly to include – depends on typical CSR working patterns.</li>
</ul>
</li>
</ul>
</li>
<li>Based on this automated identification – your Help Desk software MUST allow <em>both </em>to prioritize <em>and </em>to color-code your e-mails when they’re shown in your e-mail queue. A more-or-less typical example of such prioritizing/color-coding:
<ul>
<li>Alerts from your monitoring system (as discussed in [[TODO]] section above, most of the time they SHOULD go into your e-mail queue) – highest priority, often shown in RED. Whenever seeing such an alert – CSR team should stop doing anything else and deal with the alert.</li>
<li>E-mails from those players which have VIP (“pro players”, “known reviewers/opinion leaders”, “troublemakers” etc.) flag set in their accounts (these flags should be settable by your CSRs manually). Usually e-mails from VIP players should have priority right after alerts, usually shown in GREEN.</li>
<li>E-mails from paying players. These are prioritized below VIPs, and are usually shown in default color (white?)</li>
<li>E-mails from not-yet-paying players. Priority-wise, these reside at the very bottom of the food chain, and are often shown in GREY.</li>
</ul>
</li>
<li>Your Help Desk system MUST allow CSRs to “assign” an incoming e-mail to themselves (so that there are no two CSRs working on the same e-mail); this is also known as “Agent Collision Prevention”
<ul>
<li>If this “assigned” status still stays (without upgrading to some other status) when a shift of the corresponding CSR is over – it MUST be automatically dropped (otherwise you’ll get way too many e-mails which are “hanged-for-several-days-for-no-reason” – for example, if your CSR has forgot about a message – and left for vacation with several e-mails still assigned to him).</li>
</ul>
</li>
<li>Your Help Desk system MUST allow to change status of the incoming e-mail. Moreover – some actions MUST allow to change status without unnecessary clicks.
<ul>
<li>For example, when CSR is answering an e-mail – your system SHOULD show “Change Status Of Incoming E-mail To:” field, with “REPLIED, NO FURTHER ACTION REQUIRED” status pre-selected by default. <em>Once again, it is all about saving your CSRs from a bit of mundane work</em>.</li>
</ul>
</li>
<li><img width="170" height="170" src="/wp-content/uploads/BB_emotion_0009b.png" />Your Help Desk system MUST have templates with canned responses well-integrated. For example – instead of writing an individual response to ubiquitous “I lost my password” e-mail, your CSR MUST be able to select “Lost password” template from a drop-down list – and a draft e-mail should be automatically prepared. In this draft – a substitution of the fields from player’s account MUST be performed (for example, “Dear {$FirstName}” should be substituted with “Dear John,”) – and highlighted (so that CSR can easily double-check whether substitutions make sense).
<ul>
<li>If you <em>really </em>care about your CSRs – you can even go even further, and have heuristics which tries to guess what the e-mail is about – and offers the most-likely-guess <em>in addition </em>to the drop-down list of templates, saving your CSRs two clicks or so if automated guess is correct.</li>
</ul>
</li>
<li>Your Help Desk system MAY allow to grab information from other sources such as support forums – and push them into the same Email Queue.
<ul>
<li>IMHO, <em>when applied to public sources such as </em>forums, the value of this feature is <em>greatly </em>exaggerated (in particular – replies in public forums SHOULD NOT be canned, and canned replies is a staple for e-mail processing).</li>
<li>On the other hand, integrating <em>point-to-point </em>conversations into your Email Queue (i.e. private messages sent to your social network account) is generally a good idea.</li>
</ul>
</li>
<li>Last but not least – your Help Desk system MUST provide statistics on performance of your CSRs (as well as an easy ability to retrieve all the replies of a certain CSR over specified time frame).</li>
</ul>
</li>
</ul>
<p>If the features above look much-more-difficult-than-you-expected-from-an-e-mail-handling-system – that’s because the whole support process (replying to many thousands e-mails per day) is very far from being trivial.</p>
<hr class="rabbit-footnote-separator" /><a name="rabbitfootnote-10"></a><div class="rabbit-footnote"><sup>10</sup> Of course, training is also extremely important, but it is clearly outside of the scope of this book.</div>
<p>&nbsp;</p>
<h2>Implementation: SaaS vs In-House 3<sup>rd</sup>-party vs DIY</h2>
<p>With the requirements laid out, we can start thinking about implementing our Help Desk system.</p>
<p>At least in theory, there are three distinct approaches to your Help Desk software:</p>
<ul>
<li> <strong>Option 1.</strong> Using SaaS system (also known as “hosted” solutions) such as Zendesk or desk.com
<ul>
<li>Such systems are certainly the best choice from the point of view of the IT team (there is nothing to do there &lt;wink /&gt;, except for paying money for the system). On the other hand – such systems tend to <em>severely lack </em>on integration options for your Email Queue. In particular:
<ul>
<li>Identification of incoming e-mails (against <em>your </em>DB) is usually lacking; even when it is possible to organize – it is going to be quite an effort involving synchronizing different DBs (yours and SaaS).</li>
<li>Prioritization and color coding is rarely (if ever) possible.</li>
<li>Any other access to your account DB (such as VIP flags, or data to be used in templates) is at worst impossible, and at best is a Big Headache™.</li>
</ul>
</li>
<li>Overall – SaaS Help Desk <em>will </em>work, but unless you provide <em>at least </em>all the integration along the lines discussed above – your SaaS Help Desk will be able to provide <em>neither </em>above-average customer satisfaction, <em>nor </em>reasonable job satisfaction for your CSRs (and both these effects will amplify each other, leading to a downward spiral of overall dissatisfaction for both players and CSRs).</li>
</ul>
</li>
<li><strong>Option 2.</strong> Using 3<sup>rd</sup>-party Help Desk software hosted internally (this is also known as “in-house”, “self-hosted”, or “on-premise” Help Desk); examples include HelpSpot, Jitbit, and Kayako (with all three companies offering <em>both </em>SaaS <em>and </em>self-hosted options).
<ul>
<li>I have to admit that I don’t know much about on-premise-but-3<sup>rd</sup>-party help desks, but my current understanding is that you’ll have <em>somewhat better </em>chances to integrate them with your system properly. Still – make sure to take a closer look <em>and </em>to consider how specific-integrations-scenarios-mentioned-above can be implemented with their system. In this regard, (a) automated identification of incoming e-mails based <em>both </em>on previous e-mails <em>and </em>data in your DB, and (b) ability to integrate information-from-your-DB into their screens, including prefilling-templates from fields in your DB are especially important.</li>
<li>Oh, and it has been reported that on-premise systems are often <em>much </em>less expensive than SaaS ones.</li>
</ul>
</li>
<li><strong>Option 3. </strong> As always, a DIY option provides the best flexibility and – if you spend enough time on it – the best experience for both your CSRs and your players. Moreover, starting from about (very roughly) 100K simultaneous players – the savings on CSR time tend to outweigh IT costs, and as customer satisfaction for a properly-implemented DIY Help Desk tends to be <em>significantly </em>better than alternatives; it means that for larger games DIY Help Desk becomes a pure win.
<ul>
<li>Once, I’ve seen a fully-DIY e-mail handing system with most of the functionality mentioned above (plus LOTS of game-specific bells and whistles too). Not incidentally, their support was commonly regarded as by far the best thing in the industry.</li>
<li>Still, for smaller games (those which do not even try to reach 100K simultaneous players) it is hardly wise to spend time on DIY-ing your own Help Desk software.</li>
</ul>
</li>
</ul>
<h2>TL;DR for Help Desk</h2>
<p>Let’s summarize our observations about Help Desk software:</p>
<ul>
<li>Support is Really Important™ for MOGs</li>
<li>Primary support channel SHOULD be centered around e-mails (or other asynchronous one-to-one communications such as private messages over social media)
<ul>
<li>While replying in public forums should an important part of your efforts – they are too different from one-to-one conversations such as e-mails, so as a rule of thumb they should be handled separately.</li>
</ul>
</li>
<li><img width="170" height="170" src="/wp-content/uploads/BB_emotion_0008b.png" />Your Help Desk software SHOULD be highly optimized for the very specific tasks your CSRs are facing. While these tasks are very game-dependent, there are a few common tasks which SHOULD be automated for a pretty much <em>any </em>game:
<ul>
<li>Identifying incoming e-mails
<ul>
<li>This includes an ability to open a player profile within your main DB in one single click</li>
</ul>
</li>
<li>Prioritizing and color-coding of incoming e-mails</li>
<li>Preparing drafts from custom templates (with fields pre-filled from the players account)</li>
</ul>
</li>
<li>As for the ways to implement your Help Desk – unfortunately, there is no silver bullet:
<ul>
<li>SaaS solutions (which are dime a dozen these days) are the simplest for IT, but their lack of customization leads to: (a) mundane repetitive work for CSRs, which in turn leads to (b) loss of CSR productivity, and (c) loss of satisfaction both for customers and for CSRs.</li>
<li>On-premise (a.k.a. in-house or self-hosted) 3<sup>rd</sup>-party Help Desk systems are a bit better customization-wise – at the cost of higher IT efforts.</li>
<li>The ultimate experience (both for CSRs and your customers) is provided by a completely DIY Help Desk system – but it is hardly worth the trouble for smaller games (very roughly – those below 100K simultaneous players).</li>
</ul>
</li>
</ul>
<h2>[[To Be Continued&#8230;</h2>
<p><img width="170" height="170" src="/wp-content/uploads/BB_emotion_0001b.png" />This concludes beta Chapter 26(b) from the upcoming book &#8220;Development and Deployment of Multiplayer Online Games (from social games to MMOFPS, with social games in between)&#8221;.</p>
<p>Stay tuned for beta Chapter 26(c), where we&#8217;ll discuss access control to our Admin Tools]]</p>
<hr><h3>References</h3><p></p>
<p><a name="rabbitref-GameSpot"></a>[GameSpot] <a href="https://www.gamespot.com/forums/pc-mac-linux-society-1000004/gameplay-graphics-sound-music-and-story-which-one--31257758/">https://www.gamespot.com/forums/pc-mac-linux-society-1000004/gameplay-graphics-sound-music-and-story-which-one--31257758/</a></p>
<p><a name="rabbitref-GiantBomb"></a>[GiantBomb] <a href="https://www.giantbomb.com/forums/general-discussion-30/graphics-vs-gameplay-503246/">https://www.giantbomb.com/forums/general-discussion-30/graphics-vs-gameplay-503246/</a></p>
<p><a name="rabbitref-Hanke"></a>[Hanke] Michael Hanke, &#8220;Airline e-Commerce: Log on. Take off.&#8221;<sup><a href="https://www.amazon.com/Airline-e-Commerce-Take-off-ebook/dp/B01FXZS6ZM" style="border:none;"><img width="16" height="16" style="position:relative; bottom:3px;" src="/wp-content/uploads/amazon-link.png" alt="Amazon"></a></sup></p>
<p></p><h3>Acknowledgement</h3><p>Cartoons by Sergey Gordeev<sup><a style="border:none;" href="/real-people-behind-the-hare#sergey-gordeev"><img width="16" height="16" src="/wp-content/uploads/irl-link.png" alt="IRL" style="position:relative; bottom:3px;"></a></sup> from <a href="http://gagltd.eu/">Gordeev Animation Graphics</a>, Prague.</p><h3>P.S.</h3><p>Don&#39;t like this post?&nbsp;<b><a href="http://ithare.com/help-desk-software-for-mogs/#rabbit-comment">Criticize&#8623;</a></b></p><h3>P.P.S.</h3><p>We've tried to optimize our feed for viewing in your RSS viewer. However, our pages are quite complicated, so if you see any glitches when viewing this page in your RSS viewer, please refer to our <a href="http://ithare.com/help-desk-software-for-mogs/">original page</a>.</p>
]]></description>
		<wfw:commentRss>http://ithare.com/help-desk-software-for-mogs/feed/</wfw:commentRss>
		<slash:comments>4</slash:comments>
		</item>
		<item>
		<title>Back End Tools for MOGs</title>
		<link>http://ithare.com/back-end-tools-for-mogs/</link>
		<comments>http://ithare.com/back-end-tools-for-mogs/#comments</comments>
		<pubDate>Tue, 11 Jul 2017 14:40:53 +0000</pubDate>
		<dc:creator><![CDATA["No Bugs" Hare]]></dc:creator>
				<category><![CDATA[D&D of MOGs: Vol. VII-IX (1st beta)]]></category>
		<category><![CDATA[Development & Deployment of Multiplayer Online Games]]></category>
		<category><![CDATA[multiplayer]]></category>
		<category><![CDATA[Server]]></category>
		<category><![CDATA[web development]]></category>

		<guid isPermaLink="false">http://ithare.com/?p=9927&#038;rabbit_rss_ver=23</guid>
		<description><![CDATA[
<div class="rabbit-img"><a href="/wp-content/uploads/BB_part158_BookChapter26a_v2.png"><img class="wp-image-9934 size-medium" src="/wp-content/uploads/BB_part158_BookChapter26a_v2-640x427.png" alt="Front-End vs Back-End" width="640" height="427" /></a></div>
<div class="rabbit-img-right"><a href="/contents-of-development-and-deployment-of-massively-multiplayer-games-from-social-games-to-mmofps-with-stock-exchanges-in-between/#vol7"><img src="/wp-content/uploads/bbbook_cover_vol07_-330.png" alt="#DDMoG, Vol. VII" width="220" height="220" /></a></div><p>[[<em>This is Chapter 26(a) from “beta” Volume VII of the upcoming book "Development&Deployment of Multiplayer Online Games", which is currently being beta-tested. Beta-testing is intended to improve the quality of the book, and provides free e-copy of the "release" book to those who help with improving; for further details see "<a href="/book-beta-testing-development-and-deployment-of-massively-multiplayer-games-from-social-games-to-mmofps-with-stock-exchanges-in-between/">Book Beta Testing</a>". All the content published during Beta Testing, is subject to change before the book is published. </em><p><em>To navigate through the "1st beta" of the book, you may want to use <a href="/contents-of-development-and-deployment-of-massively-multiplayer-games-from-social-games-to-mmofps-with-stock-exchanges-in-between/#toc">Development&amp;Deployment of MOG: Table of Contents</a>.</em>]]
<p>One all-important thing which is very often neglected in MOGs – is Back End Tools. On the other hand, Back End Tools is one thing which is extremely important for your game. After all – it is Back End which controls (and allows to see &lt;smile /&gt;) all the money flowing into your game; even more importantly – it is the way your CSRs can access the system, and reply to support requests (ranging from “Help! I lost my password” to “I paid you my $1.99, but got nothing”).</p>
<p>Within this book, we will understand Back End as a set of tools, which provides the following capabilities:</p>
<ul>
<li><strong>Control.</strong> Whatever your game is – you’ll probably want to change its operational parameters (or more generally – control your game operation at business level). This includes such things as running scheduled tournaments, changing gameplay parameters, announcing server restart to all the relevant players, etc. etc. etc.</li>
<li><strong>Monitoring.</strong> It is all-important that your support team knows the current health of the system at any given point in time (saying to the player complaining that the game is slow, to reboot his computer – while it is your servers which are lagging – is usually not the best idea).</li>
<li><strong>Reporting.</strong> In addition to controlling your game – you will need to get all the data your non-programmers need, from the databases.<a href="#rabbitfootnote-1"><sup>1</sup></a> This includes all kinds of data, ranging from operational data such as “Last sessions played by player X”, to analytical data such as “Give me per-country stats of all the players filtered according to such-and-such criteria”.</li>
<li><strong>Help Desk.</strong> Most of the time, you will find that your Help Desk is just a fancy name for an elaborated-and-highly-customized Email Queue. While in theory, in addition to e-mails you can have tickets, live chat, and even phone call center – in practice, pushing your players into explicit tickets is unrealistic, and live chat / phone is just too expensive to run (with a few narrow exceptions discussed below).</li>
</ul>
<p>While the spectrum of these tools is rather wide – they have one significant thing in common:</p>
<blockquote><big><b>The vast majority of Back-End Tools are intended for NON-programmers and NON-admins.</b></big></blockquote>
<p><img width="170" height="170" src="/wp-content/uploads/BB_emotion_0022b.png" />Instead, primary users of your Back-End Tools are your CSRs, your Security Team, your Marketing&amp;Monetization Team, and last but certainly not least – the Almighty Management. As a result – most often, Back-End Tools are implemented as an internal web site.</p>
<p>Sure, admins and programmers MAY use Back-End Tools too (though in larger companies there is often an administrative prohibition on doing it in production at least for programmers<a href="#rabbitfootnote-2"><sup>2</sup></a>) – but Back-End Tools should be <em>easily </em>usable by people who have no idea about command line, threads, CIDR addressing notation, and so on.</p>
<p>Now, let’s take a closer look at these capabilities – and see what they <em>might </em>entail; on the other hand – let’s keep in mind that each game has its own unique requirements, and I will be able to mention only a very small subset of things which your specific game will need in the long run.</p>
<hr class="rabbit-footnote-separator" /><a name="rabbitfootnote-1"></a><div class="rabbit-footnote"><sup>1</sup> BTW, for our purposes – we do not consider databases as such as a part of the Back End Tools</div><a name="rabbitfootnote-2"></a><div class="rabbit-footnote"><sup>2</sup> it may also be a regulatory requirement – for example, PCI DSS calls for a clean separation between development and production requirements, <em>and </em>for restricting access to card numbers on <em>need-to-know</em> basis.</div>
<p>&nbsp;</p>
<h2>Control</h2>
<p>Controlling your game is a very game-specific task, and all I can do is to give a few examples to demonstrate the range of Control-related Back-End Tools I’ve seen or heard of:</p>
<ul>
<li>Announcements (ranging from server restarts to saying “hey guys, our Big Tournament is about to start, you can watch it in real-time”).</li>
<li>Preparing for server restart (pretty often – stopping creating new games and waiting until current ones finish, a process somewhat similar to Docker’s DRAIN).</li>
<li>Scheduling tournaments.</li>
<li>Adjusting gameplay parameters for different lobbies (different countries, …).</li>
<li>Managing payment methods (percentages of transactions going via different payment methods, disabling a method, etc.)</li>
<li>Managing player accounts – ranging from player ban (or “ban wave”) to giving players some goodies (for example, extending their subscription as a compensation for server crash during all-important-for-them-tournament).</li>
<li>Approving uploaded avatar images (that is, if avatar images can be uploaded).</li>
<li>etc., etc., etc.</li>
</ul>
<p>A question whether to include admin-level manipulations (such as “let’s add this server/cloud provider/…” to the mix of the servers we’re using”) into Back-End Tools – is an open one. Still, I’d say that <em>if </em>these operations have some impact on gameplay – all the servers (with their parameters) should be at least <em>visible </em>in your back-end; usually – it is also a good idea to allow control of certain gameplay parameters for already-added servers from Back-End Tools. For example, while <em>adding </em>a new cloud provider can be seen as a purely admin task (and can be made without help from Back-End Tools) – pretty often, the same admin will need to add this provider into Back-End Tools, so non-admin Gameplay Team can see it and say via Back-End Tools: “hey, we can see in Monitoring that this provider has frequent connectivity problems, so we won’t run our Important Tournaments there”.</p>
<p><img width="170" height="170" src="/wp-content/uploads/BB_emotion_0010b.png" />Implementation-wise, Back-End Control Tools are usually based on a web server, plus an app server behind it – which app server then communicates with your Game Servers (such as Game World Servers, MatchMaking Servers, Cashier Servers, etc.; more on them in Vol. III’s chapter on Server-Side Architecture).</p>
<p>What to use as your web server – doesn’t matter too much (it is an internal web server, so even IIS will do<a href="#rabbitfootnote-3"><sup>3</sup></a>); however, you better think from the very beginning on “how we’re going to integrate our app server with our Game Servers”. In other words – if you’re going to have your Back-End app server in Java while your Game Servers are C++, you’d better agree from the very beginning to use <em>protobufs </em>(<em>FlatBuffers, Thrift, …, your-own-infrastructure-supporting-both-Java-and-C++) </em>for communications between your Back-End app server and your Game Servers.</p>
<hr class="rabbit-footnote-separator" /><a name="rabbitfootnote-3"></a><div class="rabbit-footnote"><sup>3</sup> Just make 200%-sure it is <em>never </em>exposed to the Internet.</div>
<p>&nbsp;</p>
<h2>Monitoring</h2>
<p>As noted above, monitoring is an important part of the Back-End Tools. In particular, CSRs should:</p>
<ul>
<li>Be aware of the current problems on your side to give reasonable advice to the players. For example, if you know that all the players from a large ISP are currently disconnected (which can be easily caused by the ISP’s router failing, and BGP being misconfigured) – it is better to describe the situation to the customer instead of anemic and unprofessional “please run Windows Update and update your drivers”<a href="#rabbitfootnote-4"><sup>4</sup></a></li>
<li>Raise the hell if something goes wrong – calling admins/developers/whoever-else in case of alerts raised by your monitoring tools. While such notifications can be done automatically – a well-trained 24&#215;7 support team was seen to be more reliable in this regard.<a href="#rabbitfootnote-5"><sup>5</sup></a></li>
</ul>
<p>Technically – most of the time, your CSRs will just use a custom view (“custom device report”, etc.), which you create specifically for them in you monitoring system such as Zenoss or Zabbix. Also – it is a good idea to have your monitoring system to push alerts into your Email Queue;<a href="#rabbitfootnote-6"><sup>6</sup></a> as your CSRs will spend most of their time there – alerting them via Email Queue tends to work extremely well.</p>
<hr class="rabbit-footnote-separator" /><a name="rabbitfootnote-4"></a><div class="rabbit-footnote"><sup>4</sup> Translation: “we have no idea what is going on, but maybe while you’re doing it – the problem will go away by itself”</div><a name="rabbitfootnote-5"></a><div class="rabbit-footnote"><sup>5</sup> And of course, nothing prevents you from <em>both </em>running automated notifications, <em>and </em>have procedures for support who should start calling admins.</div><a name="rabbitfootnote-6"></a><div class="rabbit-footnote"><sup>6</sup> And Email Queue should show such alerts with a topmost priority – more on it below.</div>
<p>&nbsp;</p>
<h2><a href="#_ftnref5" name="_ftn5"></a>Reporting</h2>
<p>Reporting is one thing which starts small, but later takes most of your Back-End Team efforts (though ongoing integration with your Help Desk can be time-consuming too). Once, I’ve seen a game, which started with just a single report showing all the players – and over several years got to over a thousand of different reports.</p>
<p>The key with reporting is to</p>
<blockquote><big><b>Make sure that your reports are CSR-driven<a href="#rabbitfootnote-7"><sup>7</sup></a></b></big></blockquote>
<p>It is pretty much hopeless to try to <em>predict </em>which reports you’ll need in the future; even if we try to guess it – we’ll be hopelessly wrong 99% of the time &lt;sigh /&gt;. As a result – I am a <em>strong </em>proponent of starting to implement any of the reports <em>only </em>when somebody comes and says “hey, we need such and such data presented in such-and-such way”. Not only it will save you efforts – but also it will allow to provide <em>exactly </em>what is necessary for CSRs/Marketing/Management…</p>
<p><img width="170" height="170" src="/wp-content/uploads/BB_emotion_0008b.png" />From what I’ve seen, reports which can be seen in games, vary <em>greatly</em>; still, they can be divided into two very broad categories: operational reports and analytical reports. Operational reports are usually mostly used by CSRs, and analytical ones – by Marketing/Monetization Teams, and by Management.</p>
<p>Examples of operational reports (those which are not too game-specific) include:</p>
<ul>
<li>All the player data for player X.</li>
<li>Detailed play history for player X (usually this report differs from the previous one to avoid cluttering).</li>
<li>Stats and history of two players X and Y playing together (these are often used by Security Team, in case if some kind of collusion between players is suspected).</li>
<li>History of payments for player X.</li>
<li>History of <em>all</em> the payments for payment provider P over time period (this one is necessary for reconciliation with payment providers).</li>
<li>Show all the people who ever shared any credit cards with player X.</li>
<li>Show all the people who ever shared an IP address with player X. <em>(NB: this report is a risky one, and generally you should check whether the number of such players is within reason, before starting to show a million-entry-long list of the people who happen to share the same proxy</em>).</li>
</ul>
<p>Examples of analytical reports include:</p>
<ul>
<li>How many new registrations came in (money was generated, etc.) during specified time frame? <em>NB: this report is actually a borderline between the operational and analytical ones, but let’s list it here.</em></li>
<li>Per-day registrations AND active players in such and such country (city, …).</li>
<li>How much money have those-players-who-registered-during-specified-time-frame brought over their first 60 days after registration? This kind of reports is common to analyze promotion results.</li>
<li>How well are players coming from such-and-such affiliate (or via certain ad source) they are doing (both in terms of time spent on site, and in terms of money generated)?</li>
<li>The same thing – but comparing <em>all</em> the affiliates.</li>
<li>Per-affiliates (per-ad-source) ROI.</li>
<li>etc., etc.</li>
</ul>
<p>Implementation-wise, I would argue against using fancy GUI-based reporting tools such as Crystal Reports (Active Reports, etc.); in fact, once upon a time I’ve seen people trying Crystal exactly as a tool to implement game reporting – just to realize that it is <em>waaay too </em>restrictive, and to move away to ASP-based custom-written reports (which worked like a charm BTW).</p>
<p>In particular –</p>
<blockquote><big><b>I am clearly insisting on writing all your SQL and NoSQL queries by hand</b></big></blockquote>
<p>As soon as this requirement is complied with – I am pretty much agnostic to the specific app server technology you’ll be using; any of {.NET|Java|Python|even-PHP} (with appropriate frameworks if you feel like it) will do.</p>
<p>Further two all-important things to keep in mind are that:</p>
<ul>
<li>From the very beginning, be prepared to run your reports off the replica (more on replicas in Vol. VI’s chapter on Databases)</li>
<li>Keep in mind that while operational reports are usually run from a replica-which-is-structurally-identical to the OLTP DB – the analytical reports are often very different:
<ul>
<li>They are using aggregates, and/or</li>
<li>They’re using OLAP cubes, and/or</li>
<li>They’re using a NoSQL DB</li>
</ul>
</li>
</ul>
<p>As a result of those structurally-different replicas for analytical reporting – such reports often become a joint effort, with parts of the job shared between the Database Team (which should prepare the data in a structure which will be usable by reporting), and Back-End Team (which is responsible for retrieving the data and displaying it to the end-user)<a href="#rabbitfootnote-8"><sup>8</sup></a>.</p>
<hr class="rabbit-footnote-separator" /><a name="rabbitfootnote-7"></a><div class="rabbit-footnote"><sup>7</sup> Marketing Team-driven, Management-driven, etc.</div><a name="rabbitfootnote-8"></a><div class="rabbit-footnote"><sup>8</sup> and actual SQL/NoSQL queries can easily end up on the either side, though usually for big databases, Database Team is better positioned to write non-trivial queries.</div>
<p>&nbsp;</p>
<h3>On Reports with Too Many Rows</h3>
<p>One very important observation about reports is that</p>
<blockquote><big><b>Any report which is longer than a few hundred rows, is not immediately usable by people.</b></big></blockquote>
<p>Looking over a table with thousands of rows rarely makes much sense; it means that <em>if your CSRs/Marketing need these-long-reports – most likely, they’re doing some post-processing with the data. And if it happens often enough – it means that their work can be optimized by providing another report which does this post-processing for them.</em></p>
<p>As a result – it is often a good idea to log number of rows returned on the server-side, then have a script which scans logs to find those reports which are often returning too many rows – and then manually investigate what can be done to simplify the work flow.</p>
<p>Actually, this is one manifestation of a more generic rule of</p>
<blockquote><big><b>Being proactive with optimization of the work flow of your CSRs.</b></big></blockquote>
<p>This rule is <em>very important </em>to ensure that your CSRs are <em>both </em>efficient <em>and </em>happy &#8211; and this, in turn, is extremely important to keep <em>both </em>your management <em>and</em> players happy.</p>
<p>&nbsp;</p>
<h3>On Visualization</h3>
<p><img width="170" height="170" src="/wp-content/uploads/BB_emotion_0019b.png" />When speaking about reports, there are actually two distinct aspects of them: <em>content</em> and <em>visualization</em>. And while, as discussed above, <em>content </em>of the reports should be driven by CSRs/Marketing/Management – <em>presentation </em>of the reports should be as uniform as possible. In particular, ideally:</p>
<ul>
<li>There should be ability to sort by any column
<ul>
<li>Multi-column sorting is even more useful</li>
</ul>
</li>
<li>Ability to export any report to CSV (so it can be imported into Excel for further processing<a href="#rabbitfootnote-9"><sup>9</sup></a>)</li>
<li>For all aggregate reports (such as per-country analytical reports discussed above) – there should be a uniform way to visualize report as a graph.</li>
</ul>
<p>All these features <em>should </em>be done purely on the browser-side by JavaScript, so that no additional SQL queries are ever required when playing with visualization. Implementation-wise – it should be done by using your own “glue” library layer to render your data from your reports (<em>without </em>generating any of JS explicitly(!), and <em>without </em>calling any 3<sup>rd</sup>-party stuff right from your reports); this approach will allow to add more visualization capabilities (and/or change your 3<sup>rd</sup>-party visualization library) later, and without rewriting all those hundreds of existing reports.</p>
<hr class="rabbit-footnote-separator" /><a name="rabbitfootnote-9"></a><div class="rabbit-footnote"><sup>9</sup> NB: due to potential for cheating, <em>some </em>of the reports may need have this capability disabled (and copy-pasting may be disabled too)</div>
<p>&nbsp;</p>
<h2>[[To Be Continued&#8230;</h2>
<p><img width="170" height="170" src="/wp-content/uploads/BB_emotion_0001b.png" />This concludes beta Chapter 26(a) from the upcoming book &#8220;Development and Deployment of Multiplayer Online Games (from social games to MMOFPS, with social games in between)&#8221;.</p>
<p>Stay tuned for beta Chapter 26(b), where we&#8217;ll briefly discuss helpdesk software]]</p>
<hr><h3>Acknowledgement</h3><p>Cartoons by Sergey Gordeev<sup><a style="border:none;" href="/real-people-behind-the-hare#sergey-gordeev"><img width="16" height="16" src="/wp-content/uploads/irl-link.png" alt="IRL" style="position:relative; bottom:3px;"></a></sup> from <a href="http://gagltd.eu/">Gordeev Animation Graphics</a>, Prague.</p><h3>P.S.</h3><p>Don&#39;t like this post?&nbsp;<b><a href="http://ithare.com/back-end-tools-for-mogs/#rabbit-comment">Criticize&#8623;</a></b></p><h3>P.P.S.</h3><p>We've tried to optimize our feed for viewing in your RSS viewer. However, our pages are quite complicated, so if you see any glitches when viewing this page in your RSS viewer, please refer to our <a href="http://ithare.com/back-end-tools-for-mogs/">original page</a>.</p>
]]></description>
		<wfw:commentRss>http://ithare.com/back-end-tools-for-mogs/feed/</wfw:commentRss>
		<slash:comments>4</slash:comments>
		</item>
		<item>
		<title>System Monitoring</title>
		<link>http://ithare.com/system-monitoring/</link>
		<comments>http://ithare.com/system-monitoring/#comments</comments>
		<pubDate>Tue, 04 Jul 2017 14:04:26 +0000</pubDate>
		<dc:creator><![CDATA["No Bugs" Hare]]></dc:creator>
				<category><![CDATA[D&D of MOGs: Vol. VII-IX (1st beta)]]></category>
		<category><![CDATA[Development & Deployment of Multiplayer Online Games]]></category>
		<category><![CDATA[Server]]></category>

		<guid isPermaLink="false">http://ithare.com/?p=9889&#038;rabbit_rss_ver=23</guid>
		<description><![CDATA[
<div class="rabbit-img"><a href="/wp-content/uploads/BB_part157_BookChapter22c_v1.png"><img class="wp-image-9896 size-medium" src="/wp-content/uploads/BB_part157_BookChapter22c_v1-640x427.png" alt="Monitoring Servers" width="640" height="427" /></a></div>
<div class="rabbit-img-right"><a href="/contents-of-development-and-deployment-of-massively-multiplayer-games-from-social-games-to-mmofps-with-stock-exchanges-in-between/#vol7"><img src="/wp-content/uploads/bbbook_cover_vol07_-330.png" alt="#DDMoG, Vol. VII" width="220" height="220" /></a></div><p>[[<em>This is Chapter 25(c) from “beta” Volume VII of the upcoming book "Development&Deployment of Multiplayer Online Games", which is currently being beta-tested. Beta-testing is intended to improve the quality of the book, and provides free e-copy of the "release" book to those who help with improving; for further details see "<a href="/book-beta-testing-development-and-deployment-of-massively-multiplayer-games-from-social-games-to-mmofps-with-stock-exchanges-in-between/">Book Beta Testing</a>". All the content published during Beta Testing, is subject to change before the book is published. </em><p><em>To navigate through the "1st beta" of the book, you may want to use <a href="/contents-of-development-and-deployment-of-massively-multiplayer-games-from-social-games-to-mmofps-with-stock-exchanges-in-between/#toc">Development&amp;Deployment of MOG: Table of Contents</a>.</em>]]
<p>As noted above – to see that your mission-critical system is working, you need to monitor its health 24&#215;7. And – no surprise here – there are tools which help you in this regard. While I myself am guilty of designing my own monitoring tool for a what-have-became-a-billion-dollar-business – I will be the first one to say that these days, it would be quite silly.</p>
<h2>Requirements</h2>
<p>First, let’s take a look on “what we want from system monitoring?”. Without going into unnecessary details, we can safely say that:</p>
<ul>
<li>We will want to monitor at least a hundred parameters per server, with at most 5-second intervals.
<ul>
<li>It means that for a hundred of servers, we’ll need 2000 New Values Per Second (NVPS) written.</li>
<li>On the other hand, we do NOT have a requirement of strict Durability (i.e. even if some monitoring data will get lost once in a long while – it certainly won’t be the end of the world).</li>
</ul>
</li>
<li>We DO need to monitor app-level parameters. As a result, <em>custom monitoring </em>is the must.</li>
<li><img width="170" height="170" src="/wp-content/uploads/BB_emotion_0027b.png" />We DO need an ability to raise hell when something goes wrong. This includes two components:
<ul>
<li>Detecting that something goes wrong (at least simple thresholds)</li>
<li>Ability to notify support/admins/…</li>
</ul>
</li>
<li>We DO want to monitor log files (both those by our apps and by OS/DB/3<sup>rd</sup>-party apps), to parse them – and to raise hell if something goes wrong.</li>
</ul>
<h2>What to Monitor?</h2>
<p>Now, we need to decide “what to monitor?”. This is not that difficult question; actually –</p>
<blockquote><big><b>We need to monitor EVERYTHING we can afford to monitor.</b></big></blockquote>
<p>This includes both very traditional monitoring things such as:</p>
<ul>
<li> <strong>Data from your network devices</strong>, such as number of packets traveling via the switch Ethernet interface, number of corrupted packets over the interface (if it is non-zero – most likely we’re speaking about the partially-broken Ethernet cable), and so on. This kind of data is usually collected via SNMP.</li>
<li><strong>Data from your Server Boxes</strong>. Includes CPU usage, amount of committed RAM, amount of free space on your drives, etc. etc. etc. Maybe collected either via SNMP, or directly via a plugin-provided-by-your-monitoring-system.
<ul>
<li>One very important thing to monitor, is health of your RAID drives (if one drive fails, or indicated as “going to fail soon” – it needs to be replaced ASAP).</li>
</ul>
</li>
<li><strong>Data from your DBMS(s).</strong> As database is one absolutely critical part of your setup – monitoring it is also absolutely critical. This kind of data is usually collected via some kind of plugin-provided-by-your-monitoring-system.</li>
<li><strong>Data from your own apps(!).</strong> This is one part which is very often overlooked by admins. However – to make sure that our software <em>does </em>work as intended – we <em>do </em>need to monitor quite a few parameters of our own (which is BTW very consistent with operating under DevOps model – with <em>both</em> developers <em>and </em>admins having <em>joint </em>responsibility for the system). To do it – you’ll need to write your own agents (fortunately – usually you can write your own <em>script </em>or <em>module </em>for your-system’s-agent). In particular, the following parameters are of extreme importance:
<ul>
<li>For (Re)Actor-based systems:
<ul>
<li>idle (waiting-for-event) time per thread and per-(Re)Actor. As each (Re)Actor can use only one thread – going over 100% means sharp increase in latencies<a href="#rabbitfootnote-1"><sup>1</sup></a> – but it is avoidable if you monitor your system closely enough.</li>
<li>Sizes of incoming queues for (Re)Actors.</li>
</ul>
</li>
<li>For massively-multithreading systems:
<ul>
<li>Number of threads per type of requests.</li>
<li>Time spent under <em>each</em> of your mutexes. As overloading mutex has <em>even worse </em>effects<a href="#rabbitfootnote-2"><sup>2</sup></a> than using-100%-of-the-core-for-(Re)Actor – we need to monitor all of them very closely too.</li>
</ul>
</li>
<li>For <em>all </em>systems: whatever-performance-related-data-your-app-is-able-to-share. Some examples include:
<ul>
<li>Current number of players per game type (region, etc. etc.)</li>
<li>Per-request-type (per-message-type, etc.) processing times.</li>
<li>Per-app memory usage</li>
<li>Current app-level cache sizes.</li>
<li>etc. etc.</li>
</ul>
</li>
<li><img width="170" height="170" src="/wp-content/uploads/BB_emotion_0019b.png" />Business-level real-time data (sic!). This is one field which is even more frequently overlooked than app-level data. Still – it is <em>really </em>important to know that a 10-minute average of your drop-out rate from a certain form raised to 100% (and if you, in the spirit of Continuous Delivery, have just deployed a new version of this form – it may indicate that there is an outright bug there to be fixed ASAP and even sooner). Monitoring business-level data, just as app-level monitoring, requires writing your own agents (scripts, modules, etc.).</li>
</ul>
</li>
</ul>
<hr class="rabbit-footnote-separator" /><a name="rabbitfootnote-1"></a><div class="rabbit-footnote"><sup>1</sup> Though surprisingly, there is a substantial reserve for the (Re)Actor to operate at 100% of load – this happens due to avoiding some of context switches in this mode, which in turn leads to better-than-linear(!) scalability around this point.</div><a name="rabbitfootnote-2"></a><div class="rabbit-footnote"><sup>2</sup> Unlike (Re)Actors which tend to save on context switches under the heavy load, mutex-based systems tend to cause <em>much more </em>context switches under the same scenarios – which often leads to highly-non-linear dependencies.</div>
<p>&nbsp;</p>
<h2>On Storage: to SQL or not to SQL?</h2>
<p>Now, we can discuss the Big Fat Ugly Question™ of the storage system for our monitoring system; after all – we should be able to handle those thousands-of-NVPS we need.</p>
<p>Since time immemorial,<a href="#rabbitfootnote-3"><sup>3</sup></a> I have been a opponent of using SQL databases to store <em>monitoring </em>data (more generally – time series data). There are several reasons for it:</p>
<ul>
<li>As a Very Big Fat Rule of Thumb™, Monitoring data doesn’t really require SQL access (and specialized stuff such as aggregates is much more important for monitoring analysis than ad-hoc SQL queries). For monitoring data, all the views are very simplistic, and show merely some-timeframe-from-the-dataset (nothing else).
<ul>
<li>As a result, SQL benefits pretty much disappear when it comes to monitoring data.</li>
</ul>
</li>
<li><img width="170" height="170" src="/wp-content/uploads/BB_emotion_0006b.png" />Monitoring data doesn’t really require ACID transactions. As noted above – we do NOT need Durability, and if some monitoring data is lost once in a blue moon – so be it. This is a part of a more general observation that we are not going to stop our production just because monitoring is down/not coping with the load/crashed/etc.
<ul>
<li>As a result, another benefit of a proper SQL DBMS doesn’t apply to monitoring data.</li>
</ul>
</li>
<li>On the negative side – overheads of SQL DBMS, when applying them to time series data, are high.
<ul>
<li>In particular, overheads of transactions (which are not necessary for time series – see on Durability above), doing the same work twice (first into DB log, and then into data files), and updating indexes (which are necessary in SQL DB, but aren’t really necessary when using plain files, or in specialized time series DB) do hurt SQL DBs pretty badly.</li>
<li>One real-world example: in <a href="http://ithare.com/system-monitoring/?rabbit_open_refs=1#rabbitref-Shaw">[Shaw]</a>, the author is bragging about achieving 10K NVPS (New Values Per Second),<a href="#rabbitfootnote-4"><sup>4</sup></a> using two twelve-core 2.4GHz boxes with 48G RAM total (that’s not accounting for proxies). Well, I have to say that back 15 years ago, I saw a plain-file-based monitoring system, working off one single box with 2&#215;1.5Ghz cores, 256M RAM<a href="#rabbitfootnote-5"><sup>5</sup></a> and BBWC RAID card – and being able to process 5K NVPS; while this is 2x less than numbers in <a href="http://ithare.com/system-monitoring/?rabbit_open_refs=1#rabbitref-Shaw">[Shaw]</a>, it ran on hardware which is about 20x-50x less powerful, so actually we&#8217;re speaking about 10x-25x performance penalty of using SQL DBs for storing time series.</li>
<li>As a result – given the choice, I <em>strongly</em> prefer non-SQL-DB-based monitoring systems to SQL-DB-based ones.</li>
<li>OTOH – it <em>is </em>possible to scale at least <em>some </em>of the SQL-DB-based systems; in spite of huge overheads (we’re speaking about 10x-25x(!) difference), modern computers can handle even such inefficiencies, while <em>not </em>being prohibitively expensive (and as we need just one such server for a hundred of other boxes – it won’t reflect <em>that </em>bad on your bottom line).</li>
</ul>
</li>
</ul>
<p><img width="170" height="170" src="/wp-content/uploads/BB_emotion_0009b.png" />All that being said – modern monitoring systems are way too often SQL-DB-driven (with only modern exception I know being <em>Zenoss</em>), so you <em>might </em>have to use an SQL back-end. OTOH – I certainly want a monitoring system which has <em>demonstrated </em>scalability, at least along the lines of <a href="http://ithare.com/system-monitoring/?rabbit_open_refs=1#rabbitref-Shaw">[Shaw]</a>. However, without such <em>demonstrated </em>scalability – I’d be <em>extremely </em>suspicious of SQL-DB-based monitoring tools (it is just soooo many ways to do it badly wrong with an SQL DB…).</p>
<p><em>Note that my rants about DBs for monitoring actually apply ONLY to traditional SQL-based DBs, and do NOT apply to specialized time series DBs such as RRDTool or OpenTSDB (which has been reported to scale to about 100K writes/second per server box).</em></p>
<hr class="rabbit-footnote-separator" /><a name="rabbitfootnote-3"></a><div class="rabbit-footnote"><sup>3</sup> At least for 10 years now</div><a name="rabbitfootnote-4"></a><div class="rabbit-footnote"><sup>4</sup> keep in mind that in the spirit of DevOps, you’ll want to monitor of the order of 100 values per server box (including lots of custom app parameters) – and at most at 5-second intervals, so 10K NVPS corresponds to a few hundred of servers</div><a name="rabbitfootnote-5"></a><div class="rabbit-footnote"><sup>5</sup> was a significant amount back there.</div>
<p>&nbsp;</p>
<h2>Which Monitoring System to Use?</h2>
<p>Currently, there is more than one system which can be used for monitoring. In particular, the following systems are particularly popular:</p>
<ul>
<li><strong>Cacti</strong>. A dinosaur (just like me &lt;wink /&gt;) which was the most popular monitoring tool 10 years ago. Cacti is working, but IMO is a bit too data-centric (rather than task-centric); also it is losing popularity to newer monitoring systems. On the positive side, Cacti uses RRDTool (rather than an SQL database) as a back-end – which is IMNSHO a Good Thing™ (as discussed above).
<ul>
<li>My take: I’d rather not use Cacti for new deployments, due to better alternatives such as <em>Zenoss</em>.</li>
</ul>
</li>
<li><strong>Nagios Core</strong> and <strong>Nagios XI</strong>. As of 2017, Nagios is probably the most popular monitoring system out there. Much more task-centric than Cacti (in particular, alerts are much more integral to Nagios than to Cacti). While Nagios Core can work without a database – Nagios XI requires MySQL (which can hurt your scalability easily – so it is not a coincidence that scalability is among top complaints about Nagios out there).
<ul>
<li>My take: I don&#8217;t recommend to use Nagios at least if you’re planning to go to several dozens of servers (and for a hundreds-of-thousands-players game &#8211; you <em>should </em>plan for at least as much).</li>
</ul>
</li>
<li><strong>Zabbix</strong>. While Zabbix, just like Nagios XI, is also SQL-database-driven, it <em>seems </em>that Zabbix guys did their job to optimize performance; while still lacking performance of the SQL-less solutions (see below) – there are believable experiments (such as <a href="http://ithare.com/system-monitoring/?rabbit_open_refs=1#rabbitref-Shaw">[Shaw]</a>) which demonstrate that Zabbix <em>seems </em>to scale, at least to some extent. On the positive side – I’d mention that I <em>like </em>Zabbix APIs for custom monitoring.
<ul>
<li>My take: if starting a new project, Zabbix would be my 2<sup>nd</sup> choice (after Zenoss, see below). Even simpler-than-Zenoss custom monitoring cannot outweigh my very serious dislike to using generic SQL DB for storing monitoring time series data.</li>
</ul>
</li>
<li><strong>PandoraFMS</strong>. PandoraFMS is a very direct competitor to Zabbix, and <em>seems </em>to be very similar feature-wise too. However, I am rather concerned that the line between PandoraFMS Community (which is free), and PandoraFMS Enterprise (which costs $$) is blurred.
<ul>
<li>My take: Overall, I prefer Zenoss; and if looking for an SQL-DB-based monitoring tool – then, due to licensing being blurred for PandoraFMS, and to demonstrated scalability for Zabbix, I’d rather use Zabbix.</li>
</ul>
</li>
<li><strong>Zenoss</strong> provides option to use either RRDTool or OpenTSDB (both being specially optimized for time series, and not suffering from traditional SQL DB performance overheads). On the negative side – to add our own app-level monitoring, we’d need to write a <em>ZenPack </em>– which is substantially more involved than writing a simple script.
<ul>
<li>My take: in spite of more complicated custom app-level monitoring, I still prefer Zenoss (with either RRDTool or OpenTSDB as a back-end), to any other monitoring system.</li>
</ul>
</li>
</ul>
<p>[[TODO: take a look at Prometheus/InfluxDB, TICK; also open-source Graphite, Grafana, Icinga, and libreNMS]]</p>
<p>[[TODO: push vs pull]]</p>
<p>[[TODO: HA for monitoring is a Big Fat Overkill(tm) most of the time]]</p>
<h3>Application Logs</h3>
<p><img width="170" height="170" src="/wp-content/uploads/BB_emotion_0007b.png" />Application logs is just a yet another source of extremely valuable data; for example, if your app writes about assertions into the log and keeps running afterwards<a href="#rabbitfootnote-6"><sup>6</sup></a> – you want to know about it ASAP. As a result – logs do need to be integrated into your monitoring system.</p>
<p>With processing logs, we actually have two distinct tasks. First, we need to <em>store </em>the logs somewhere (not strictly required, but usually we <em>do</em> want centralized storage for logs for several reasons). It can be done either by some kind of script – or by using <em>syslogd</em>.</p>
<p>Second – we need to <em>parse </em>those logs in real-time – <em>and </em>to report certain events from the logs to our monitoring system (raising alert if applicable). This is one of those jobs a good monitoring system is supposed to do for us.</p>
<hr class="rabbit-footnote-separator" /><a name="rabbitfootnote-6"></a><div class="rabbit-footnote"><sup>6</sup> this is pretty common for (Re)Actors, especially in VALIDATE and CALCULATE stages of VALIDATE-CALCULATE-MODIFY-SIMULATE pattern, discussed in Vol. II’s chapter on (Re)Actors.</div>
<p>&nbsp;</p>
<h2>What to Do with All This Data?</h2>
<p>After we got all this data stored – we need to do <em>something</em> with it. Two most common uses for the monitored data, is <em>graphs </em>and <em>alerts</em>.</p>
<p>This is where the whole power of the 3<sup>rd</sup>-party monitoring system comes in. Implementing nicely-looking graphs, as well as alert-definition-language and alert actions (such as “send SMS”) – are quite time-consuming (and are not really necessary, as monitoring tool developers have already done it for us).</p>
<p>What you’ll really need process-wise – is to have two things:</p>
<ul>
<li>Somebody from your team looking at all those graphs on regular basis, looking for unusual patterns, and for potential bottlenecks – and setting rules and alerts for those parameters which may cause trouble.
<ul>
<li>Of course, whenever you run into a bottleneck which brings your system to a crawl – you will add an alert too, but it is always better to be proactive, and at least <em>try </em>to identify likely bottlenecks in advance.</li>
</ul>
</li>
<li>Alert your team that “something went horribly wrong” and to raise hell. How to “raise hell” properly, heavily depends on the way your support team normally operates &#8211; and on the nature of the problem. First of all, there are “issues which can wait until developers are back to the job”, and “the whole damn thing is down”. For the former – a simple internal e-mail will do, but for the latter – you need to be very aggressive with delivering your alerts; here, there are two distinct scenarios:
<ul>
<li><img width="170" height="170" src="/wp-content/uploads/BB_emotion_0029b.png" />If you happen to run serious support team 24&#215;7 anyway – then the only thing you really need to do, is just pushing an e-mail with the highest-priority status into support e-mail queue – and make sure that there is a procedure for support people to follow (essentially – what is the order to call people). We’ll discuss e-mail queues (ticket systems, etc.) in Chapter [[TODO]].</li>
<li>Otherwise – it is better to send the same message using several available channels
<ul>
<li>For <em>root</em>’s sake, don’t bother with detecting-that-notification-service-is-down-and-use-backup-channel routine – just send the same alert over <em>all </em>your channels in parallel – and to several people too (the whole system is down, and there isn’t such thing as an unnecessary notification about it).</li>
<li>For this kind of alerts – I am advocating the use of <em>three </em>different channels for <em>each </em>of your admins-to-be-notified – (a) e-mail, (b) SMS,<a href="#rabbitfootnote-7"><sup>7</sup></a> and (c) app-based notification (usually – using a 3<sup>rd</sup>-party service such as <em>Pushover</em>). Note though that while these channels are somewhat-independent on the receiver’s side – all of them still rely on your datacenter having Internet connection (which is itself is a SPOF – see below).</li>
<li>Keep in mind that your monitoring server itself can be down at the very moment when it should have raised the alarm. OTOH, for most of the games out there – it is not too big deal (for it to happen, we need <em>two </em>faults – first, the monitoring server should crash, and then – the system should experience severe problems, and all this should happen within a few hours – which is quite unlikely<a href="#rabbitfootnote-8"><sup>8</sup></a>). Of course, you still need to check that your monitoring is working, at least once per working day.</li>
<li>Also, keep in mind that the whole connection to the Internet of all your servers in a datacenter can be down. Unlike the above scenario of monitoring server failing at the same time as the system gets down – this can easily be a result of a <em>single </em>fault (Internet-is-down will <em>cause </em>your game to get down). Still, if your ISP is good,<a href="#rabbitfootnote-9"><sup>9</sup></a> they should detect such an outage themselves. On the other hand – you <em>may </em>want to setup an external service (in a different datacenter) pinging your servers and raising the hell completely independently if something goes wrong.</li>
</ul>
</li>
</ul>
</li>
</ul>
<hr class="rabbit-footnote-separator" /><a name="rabbitfootnote-7"></a><div class="rabbit-footnote"><sup>7</sup> You’ll need to use a 3<sup>rd</sup>-party service to send SMS; one example of such service is OVH</div><a name="rabbitfootnote-8"></a><div class="rabbit-footnote"><sup>8</sup> Of course, it is possible that a fault in the system has caused a flood of information, causing your monitoring server to crash. Still, as we’re not speaking about monitoring a nuclear station or something – we <em>might </em>have a luxury to ignore this scenario because it is “quite unlikely”</div><a name="rabbitfootnote-9"></a><div class="rabbit-footnote"><sup>9</sup> and for the sake of your players, it’s better be good</div>
<p>&nbsp;</p>
<h2>Bottom Line</h2>
<p>TL;DR on your monitoring system:</p>
<ul>
<li>While it is not a rocket science – it will take quite a bit of time to set it up.</li>
<li><img width="170" height="170" src="/wp-content/uploads/BB_emotion_0005b.png" />You DO want to monitor <em>everything, </em>including:
<ul>
<li>Network devices</li>
<li>Servers</li>
<li>DBMS</li>
<li>Your own apps</li>
<li>Business-level metrics</li>
<li>Application logs (both from your own apps and from 3<sup>rd</sup>-party apps)</li>
</ul>
</li>
<li>You DO need a centralized system to do monitoring.</li>
<li>Even I (a well-known fan of DIY) don’t think that we should implement monitoring system ourselves.</li>
<li>When choosing an existing monitoring system, I prefer:
<ul>
<li>My 1<sup>st</sup> choice: Zenoss, or</li>
<li>My 2<sup>nd</sup> choice: Zabbix</li>
</ul>
</li>
<li>After you got your new shiny monitoring system with all the data, you should use it proactively. In particular:
<ul>
<li>You MUST set alerts (and update them every time your system managed to slow down)</li>
<li>You MUST spend time studying graphs on regular basis, to identify likely bottlenecks.</li>
</ul>
</li>
</ul>
<h2>[[To Be Continued&#8230;</h2>
<p><img width="170" height="170" src="/wp-content/uploads/BB_emotion_0001b.png" />This concludes beta Chapter 25(c) from the upcoming book &#8220;Development and Deployment of Multiplayer Online Games (from social games to MMOFPS, with social games in between)&#8221;.</p>
<p>Stay tuned for beta Chapter 26(a), where we&#8217;ll start discussing helpdesk and back-end tools]]</p>
<hr><h3>References</h3><p></p>
<p><a name="rabbitref-Shaw"></a>[Shaw] Corey Shaw, <a href="http://blog.zabbix.com/scalable-zabbix-lessons-on-hitting-9400-nvps/2615/">&#8220;Scalable Zabbix – Lessons on hitting 9400 NVPS&#8221;</a></p>
<p></p><h3>Acknowledgement</h3><p>Cartoons by Sergey Gordeev<sup><a style="border:none;" href="/real-people-behind-the-hare#sergey-gordeev"><img width="16" height="16" src="/wp-content/uploads/irl-link.png" alt="IRL" style="position:relative; bottom:3px;"></a></sup> from <a href="http://gagltd.eu/">Gordeev Animation Graphics</a>, Prague.</p><h3>P.S.</h3><p>Don&#39;t like this post?&nbsp;<b><a href="http://ithare.com/system-monitoring/#rabbit-comment">Criticize&#8623;</a></b></p><h3>P.P.S.</h3><p>We've tried to optimize our feed for viewing in your RSS viewer. However, our pages are quite complicated, so if you see any glitches when viewing this page in your RSS viewer, please refer to our <a href="http://ithare.com/system-monitoring/">original page</a>.</p>
]]></description>
		<wfw:commentRss>http://ithare.com/system-monitoring/feed/</wfw:commentRss>
		<slash:comments>6</slash:comments>
		</item>
		<item>
		<title>Scaling Stateful Objects</title>
		<link>http://ithare.com/scaling-stateful-objects/</link>
		<comments>http://ithare.com/scaling-stateful-objects/#comments</comments>
		<pubDate>Tue, 27 Jun 2017 13:40:56 +0000</pubDate>
		<dc:creator><![CDATA["No Bugs" Hare]]></dc:creator>
				<category><![CDATA[D&D of MOGs: Vol. VII-IX (1st beta)]]></category>
		<category><![CDATA[Development & Deployment of Multiplayer Online Games]]></category>
		<category><![CDATA[Distributed Systems]]></category>
		<category><![CDATA[System Architecture]]></category>
		<category><![CDATA[Cache]]></category>
		<category><![CDATA[Database]]></category>
		<category><![CDATA[Scalability]]></category>
		<category><![CDATA[Server]]></category>

		<guid isPermaLink="false">http://ithare.com/?p=9833&#038;rabbit_rss_ver=23</guid>
		<description><![CDATA[
<div class="rabbit-img"><a href="/wp-content/uploads/BB_part155_BookChapter08b_v2.png"><img class="wp-image-9846 size-medium" src="/wp-content/uploads/BB_part155_BookChapter08b_v2-640x427.png" alt="Scalability Fairy" width="640" height="427" /></a></div>
<div class="rabbit-img-right"><a href="/contents-of-development-and-deployment-of-massively-multiplayer-games-from-social-games-to-mmofps-with-stock-exchanges-in-between/#vol3"><img src="/wp-content/uploads/bbbook_cover_vol03_-330.png" alt="#DDMoG, Vol. III" width="220" height="220" /></a></div><p>[[<em>This is Chapter 8(b) from “beta” Volume III of the upcoming book "Development&Deployment of Multiplayer Online Games", which is currently being beta-tested. Beta-testing is intended to improve the quality of the book, and provides free e-copy of the "release" book to those who help with improving; for further details see "<a href="/book-beta-testing-development-and-deployment-of-massively-multiplayer-games-from-social-games-to-mmofps-with-stock-exchanges-in-between/">Book Beta Testing</a>". All the content published during Beta Testing, is subject to change before the book is published. </em><p><em>To navigate through the "1st beta" of the book, you may want to use <a href="/contents-of-development-and-deployment-of-massively-multiplayer-games-from-social-games-to-mmofps-with-stock-exchanges-in-between/#toc">Development&amp;Deployment of MOG: Table of Contents</a>.</em>]]
<h3>The Myth of Stateless-Only Scalability</h3>
<p>For quite a long time (and especially in the webdev world), there exists a perception that to achieve scalability, all our request handlers need to be as stateless as possible (in particular, RESTful web services don’t allow for in-memory states<a href="#rabbitfootnote-1"><sup>1</sup></a>). In the world of the all-popular Docker containers, it means that all the app containers need not only to be <em>immutable</em>, but also should be <em>ephemeral</em> (a.k.a. disposable).<a href="#rabbitfootnote-2"><sup>2</sup></a></p>
<p>From a practical perspective, it translates into the following observation:</p>
<blockquote><big><b>It is widely (MIS)believed that stateless Server-Side Apps are The Only Way™ to scale Server-Side.</b></big></blockquote>
<p>In this statement, it is “The Only” part which I am arguing against. Sure, having perfectly stateless request processing is a Good Thing™ – but only as long as you can afford it &lt;sad-face /&gt;.</p>
<hr class="rabbit-footnote-separator" /><a name="rabbitfootnote-1"></a><div class="rabbit-footnote"><sup>1</sup> or at the very least, stateful apps are very much frowned upon in RESTful world – all in the name of scalability</div><a name="rabbitfootnote-2"></a><div class="rabbit-footnote"><sup>2</sup> for more discussion on Docker, see Vol. VII’s chapter on DevOps</div>
<p>&nbsp;</p>
<h4>Pushing Scalability Problem to the Database</h4>
<blockquote><p>I am innocent of the blood of this just person: see ye to it.</p>&#8212; Pontius Pilate, Matthew 27:24 &#8212;</blockquote>
<p>The problem with stateless processing (such as RESTful-style stateless request handlers) is that</p>
<blockquote><big><b>If our functional specification requires storing the state on Server-Side,<a href="#rabbitfootnote-3"><sup>3</sup></a> <em>and</em> we’re using stateless request handlers – then all the state inevitably ends up in the database.</b></big></blockquote>
<p>This, in turn, means that by going for stateless request processing:</p>
<ul>
<li>There is no scalability problem on the request processing side anymore
<ul>
<li>In other words, we DO have perfect scalability for request processing apps, yay!</li>
</ul>
</li>
<li><img width="170" height="170" src="/wp-content/uploads/BB_emotion_0005b.png" />The whole scalability problem rears its ugly head on the database level.
<ul>
<li>And as we’ll see below – it becomes <em>much </em>worse at that point, up to the point of being <em>completely unmanageable </em>&lt;sad-face /&gt;.</li>
</ul>
</li>
</ul>
<p>In other words –</p>
<blockquote><big><b>keeping our request handlers stateless, does NOT really solve the scalability problem; instead – it merely pushes it to the database.</b></big></blockquote>
<p>Sure, if we’re working in a classical Huge-Company environment, we (as app developers) can say “it is not our problem anymore” (washing our hands of the matter Pilate-style). However, if our aim is not only to cover our ***es to keep our current job while the project goes down, but rather want (in a true DevOps spirit) to make sure that <em>the whole system </em>succeeds – we need to think a bit further. Most importantly, we need to realize that pushing the problem from us to DBAs isn’t the end of the scalability problems; instead – we should ask ourselves:</p>
<blockquote><big><b>with the kind of load we’ll be throwing at the database, will it be feasible to scale the database (that is, without spending millions on hardware/licenses/maintenance)?</b></big></blockquote>
<hr class="rabbit-footnote-separator" /><a name="rabbitfootnote-3"></a><div class="rabbit-footnote"><sup>3</sup> which almost-universally is the case – 100% stateless apps beyond simple web browsing are very rare</div>
<p>&nbsp;</p>
<h4>Databases and Scalability</h4>
<p>As mentioned above – we as app-developers DO need to think how much load we want to throw at the database. In this department, there are some pretty bad news for us. In spite of what your DBA may (and your database salesman <em>will</em>) tell you – in general,<a href="#rabbitfootnote-4"><sup>4</sup></a> databases certainly do NOT scale trivially in a linear manner. Worse than that –</p>
<blockquote><big><b>In a pretty much any serious real-world interactive system, it is database which is The Bottleneck™.</b></big></blockquote>
<p>I remember a discussion with very knowledgeable architect-level guys from a pretty large company as early as in 2000; during the discussion, we had quite a few disagreements, but one thing was very obvious to everybody involved: <em>scaling everything-besides-database is trivial, it is database which is going to cause trouble scalability-wise</em>. Since that point, I’ve seen (and built) quite a few serious systems – and haven’t see anything which might have changed my opinion about it.</p>
<p>When speaking about real-world OLTP databases in 2017,<a href="#rabbitfootnote-5"><sup>5</sup></a> the following very practical observations usually stand (we’ll discuss it in more detail in Vol. VI’s chapter on Databases):<a href="#rabbitfootnote-6"><sup>6</sup></a></p>
<ul>
<li>Pretty much any kind of load up to approximately 10 write-ACID-transactions/second is trivial</li>
<li>When you need loads of the order of 100 write-ACID-transactions/second – it is usually doable to use usual database optimizations (indexes, caches, physical layout, BBWC RAID, etc.).</li>
<li>Getting to 1000 write-ACID-transactions/second becomes <em>severely</em> non-trivial. If the database structure and loads don’t allow for trivial sharding (in particular – if we need to allow players to play with <em>anybody-they-want-to-play-with</em>) – things start to get ugly. We’ll discuss one way to do it, in Vol. VI’s chapter on Databases.</li>
<li><img width="170" height="170" src="/wp-content/uploads/BB_emotion_0030b.png" />for a non-trivially-shardable database, 10’000 write-ACID-transactions/second (BTW, with usual MOG load patterns, it roughly corresponds to about 100 billion transactions/year) inevitably becomes The Ultimate Nightmare™ for DBAs. In practice – such beasts are either huuuuge ultra-expensive systems, or Shared-Nothing systems (which require support from app-level, more on such systems in Vol. VI’s chapter on Databases).</li>
<li>Everything above this is both (a) very rarely really necessary,<a href="#rabbitfootnote-7"><sup>7</sup></a> and (b) in practice, works only without ACID requirement, or for trivially-shardable scenarios.</li>
</ul>
<p>In other words –</p>
<blockquote><big><b>Increasing DB load by a factor of 10x, can easily kill the whole thing.</b></big></blockquote>
<p>This, in turn, means that</p>
<blockquote><big><b>When writing our apps, we MUST care about DB load.</b></big></blockquote>
<p>As we’ll see below – app-level in-memory state can <em>easily </em>reduce number of write-ACID-transactions by factor of 10x to 1000x(!), which will make <em>huge </em>practical difference; as a result – at the very least we <em>should </em>include stateful apps into our consideration.</p>
<hr class="rabbit-footnote-separator" /><a name="rabbitfootnote-4"></a><div class="rabbit-footnote"><sup>4</sup> at least if (a) multiple-object-ACID-transactions are necessary, and (b) there is no obvious sharding of the objects; unfortunately – most of the time both (a) and (b) happen to be the case for MOGs and MOG-like systems.</div><a name="rabbitfootnote-5"></a><div class="rabbit-footnote"><sup>5</sup> And however surprising it might sound – these numbers change very little during last 15 years</div><a name="rabbitfootnote-6"></a><div class="rabbit-footnote"><sup>6</sup> specific numbers below are <em>extremely </em>rough (give or take at least an order of magnitude); also let’s note that we’re speaking about <em>real-world </em>transactions (each writing at least a dozen rows, not trivially shardable, etc. etc.), so any overly-optimistic numbers such as TPC-C or any other artificial tests do <em>not </em>apply.</div><a name="rabbitfootnote-7"></a><div class="rabbit-footnote"><sup>7</sup> TBH, I know of only one real-world system which <em>does </em>need it: it is post-2007-or-so NASDAQ. Note that lots of the companies out there, while spending <em>lots</em> of efforts to achieve this number of transactions, don’t really need them (as one example, see below for a brief discussion of Uber).</div>
<p>&nbsp;</p>
<h5>NoSQL to the rescue? Not really</h5>
<p>When speaking about databases and scalability &#8211; these days we&#8217;re often told &#8220;hey, there are lots of NoSQL databases which can handle Big Data and scale to infinity&#8221;, implying that the whole scalability problem goes away.</p>
<p>Unfortunately, it is not the case. While NoSQL databases indeed shine in certain scenarios when we need to perform read-only queries &#8211; they tend to have very significant problems when dealing with OLTP-like load, with lots of writes and very high coherency requirements. We&#8217;ll discuss these issues in detail in Vol. VI&#8217;s chapter on Databases, but for now let&#8217;s note that vast majority of NoSQL databases does <em>not </em>support multi-object database transactions with ACID guarantees (and proposed equivalents either don&#8217;t scale, or aren&#8217;t usable, or both). Yes &#8211; however sad it might sound, ACID support in most of NoSQL DBs out there is limited to <em>single-object </em>ACID transactions (which is not enough for 99% of OLTP processing tasks); moreover &#8211; extending this support to <em>multiple objects </em>under traditional NoSQL architectures will be at odds with their scalability.</p>
<p>BTW, I don&#8217;t mean that NoSQL is a Bad Thing(tm); it is just that each technology should be used within its own applicability realm. In particular, these days OLTP is still better to be performed over traditional RDBMS; however &#8211; as we&#8217;ll see in Vol. VI&#8217;s chapter on Databases &#8211; it is perfectly possible to have eventually-consistent replica of this OLTP in Big-Data-oriented NoSQL, to process all kinds of historical queries there.</p>
<h3>Scaling: Stateless vs Stateful Server-Side Apps</h3>
<p>Let’s compare two approaches to scaling our MOG (or any other Server-Side-centric interactive distributed system for that matter). One scaling approach will use classical Stateless Server-Side Apps, and another – will use Stateful Server-Side Apps (with an in-memory state).</p>
<p>We’ll be comparing these two approaches to scaling from several different angles; in particular – from the perspective of performance, durability and scalability.</p>
<h4>Performance Perspective</h4>
<p>As noted above, in case of Stateless Server-Side Apps, we’re bound to store <em>everything </em>to the DB. And for a vast majority of game-like systems, this is going to be prohibitively expensive. A few examples from different genres:</p>
<ul>
<li>For a virtual world simulation, writing <em>everything</em> to the database is going to be a non-starter; as the state of each player usually changes 20 times per second, making this much transactions per player is going to kill the whole thing even for a very modest number of players.</li>
<li>For a casino-like game such as poker, we’ll need to write <em>every single player action</em> to DB. This means making on average about 20 DB transactions per hand.</li>
<li>Even for a social farming game, we could easily end up with several dozens of clicks per player-currently-using-farm, per minute.</li>
</ul>
<p>Let’s compare it to the app with an in-memory state, the one which writes changes to Game World State to DB only at the end of the Game Event (as it was discussed in detail in the [[TODO]] section above):</p>
<ul>
<li>For a virtual world simulation, we can write changes to player state, only at the end of Game Events such as fights (conversations having consequences, etc.). It will often allow us to write things to DB once-per-minute or so (which is a 1200x(!) improvement compared to the stateless approach above).</li>
<li>For a poker game, we’ll need to write only the outcome of <em>each hand</em> to DB, corresponding to approximately 20x savings compared to naïve stateless approach.</li>
<li>For a farming game, most of the time we can make an artificial Game Event (which ends either on a Really Important Achievement™, or after a certain timeout). In practice – we can easily save up to 10x DB-activity-wise (compared to the stateless app).</li>
</ul>
<p>As we can see –</p>
<blockquote><big><b>Server-Side Apps with an In-Memory State can easily save us 10x-1000x of database load.</b></big></blockquote>
<p><img width="170" height="170" src="/wp-content/uploads/BB_emotion_0012b.png" />Moreover, as it is DB which is usually The Bottleneck™ – it means that we’re saving this enormous amount of load, <em>exactly where it really matters</em>.</p>
<p>BTW, this observation goes far beyond traditional games. Some of us remember that epic migration of Uber first from MySQL to PostgreSQL in 2013, only to migrate back to MySQL (with a custom extension) 3 years later.</p>
<p>However, I heard an opinion that Uber would fare <em>much </em>better if they’d avoided the supposedly perfectly-scalable stateless-app architecture, and kept the most common update (the same source has reported it as storing “current position of the car”) as mostly-in-memory only (writing to DB at large intervals, like “write the whole history of the car positions once per hour per car”<a href="#rabbitfootnote-8"><sup>8</sup></a>) – pretty much along the lines discussed above. Sure, all the <em>trips </em>still need to be saved immediately (they have direct financial implications, and <em>do </em>need to be durable even if the Server-Side App crashes), but with mere 1 million trips per day which Uber has (that’s just 30 transactions/second even accounting for intra-day load variations) – writing it down is trivial even for a single-writing-DB-connection OLTP system (in fact – the single-writing-DB-connection was seen handling 50M+ real-world transactions/day<a href="#rabbitfootnote-9"><sup>9</sup></a>); for details – see Vol. VI’s chapter on Databases.</p>
<p>Sure, as I didn’t make this analysis for myself – I cannot really vouch for it, but I have to say that given the numbers above – it looks quite plausible. Moreover, I <em>did </em>see real-world systems (which I unfortunately cannot name here), which experienced <em>exactly </em>this kind of problems (and <em>exactly </em>due to making everything stateless, effectively increasing database load 10x+-fold, and causing <em>lots </em>of trouble for the database, DBAs, and ultimately – for end-users).</p>
<hr class="rabbit-footnote-separator" /><a name="rabbitfootnote-8"></a><div class="rabbit-footnote"><sup>8</sup> using our terminology – it would mean creating an artificial Game Event</div><a name="rabbitfootnote-9"></a><div class="rabbit-footnote"><sup>9</sup> and BTW, transactions were significantly more complicated than writing the <em>trip </em>down</div>
<p>&nbsp;</p>
<h4>Durability Perspective</h4>
<p>Of course, these performance benefits of Stateful Server-Side Apps don’t come for free (nothing does). The currency we’ll be paying with for this drastically improved performance, is Lack of Durability. In other words – if our Stateful Server-Side App crashes, we’ll lose all the state which haven’t been saved yet to the DB.</p>
<p><img width="170" height="170" src="/wp-content/uploads/BB_emotion_0025b.png" />On the first glance this may look Really Bad™, but on the other hand, for most of MOGs – it is <em>exactly </em>the behavior we want (see the [[TODO]] section above for discussion). Moreover, even for a non-gaming interactive systems such as Uber, going along these lines is perfectly acceptable at least for <em>some </em>of the data. Using Uber data as an example – if in case of App crash we lose <em>trips </em>– it would be a significant problem, but losing half an hour of historical data about historical positions of the cars won’t be noticeable (as these historical data is used <em>only</em> for statistical purposes – losing a very minor random portion of it won’t change the stats).</p>
<p>Alternatively – there is a possibility to make our Stateful Apps Fault-Tolerant (for a relevant discussion &#8211; see Chapter 10). Still, to be honest, as Fault Tolerance doesn’t prevent from software-bug-induced crashes – for fast-changing business- and game-like apps I’d rather not risk to rely on it (in other words – in business world,<a href="#rabbitfootnote-10"><sup>10</sup></a> crash costs and crash prevention costs are balanced in a way that implies that sooner or later, crashes <em>will </em>happen).</p>
<hr class="rabbit-footnote-separator" /><a name="rabbitfootnote-10"></a><div class="rabbit-footnote"><sup>10</sup> I am <em>not </em>speaking about nuclear reactors or medical devices</div>
<p>&nbsp;</p>
<h4>Scaling Perspective</h4>
<blockquote><p>[Bart] &#8211; Well, you&#8217;re damned if you do,<br />
[Chorus] &#8211; Deep, deep trouble.<br />
[Bart] &#8211; Well, you&#8217;re damned if you do,<br />
And you&#8217;re damned if you don&#8217;t.</p>&#8212; The Simpsons &#8212;</blockquote>
<p>As already noted above, <em>performance != scaling</em>, so let’s take a look at our Stateful-vs-Stateless Server-Side Apps from scaling perspective too.</p>
<h5>Scaling Stateless-App-Based System</h5>
<p>As discussed above, when speaking about a system based on Stateless Apps, scalability is trivially achievable: we just need to create new (or use an existing) instance of our Stateless App – and bingo! – we got our scalability.</p>
<p>A very high-level diagram of this approach is shown on Fig 8.1:</p>
<div class="rabbit-img"><a href="/wp-content/uploads/Fig-8.1-1.png"><img class="wp-image-9836 size-medium" src="/wp-content/uploads/Fig-8.1-1.png" alt="Fig 8.1"style="width:803px; max-width:100%;" width="640" height="232" /></a></div>
<p>It all looks very simple: after Clients come to our Load Balancer, asking for a service from App 1 – they’re randomly directed to one of the instances of App 1 (these instances may run on one Server Box or can be spread over several different ones); the same happens for App 2 (or any other type of App).</p>
<p>In this model, all the Apps are perfectly stateless (i.e. they carry no meaningful state between requests), and therefore they can be created/destroyed as necessary. From the point of view of scaling <em>Apps </em>– it is a perfect scenario.</p>
<p><img width="170" height="170" src="/wp-content/uploads/BB_emotion_0008b.png" />On the other hand, as discussed above, the real-world task is <em>never </em>formulated in terms of scaling <em>only </em>apps; instead – we need to scale <em>the whole system</em>; and in this regard Stateless-App-based systems exhibit significant problems.</p>
<p>In particular, as discussed above, for Stateless-App-based architectures, all the scalability work is pushed down to the database. Of course, for some of Server-Side developers it means merely pushing the responsibility to somebody-else with relief, but we’re currently wearing our architectural hat, so assuming that “somebody will do it for us” (without an understanding how it will be done) is not really an option.</p>
<p>Moreover, in practice, this DB (which needs to handle <em>all</em> the state updates merely because there is no other place to store them) becomes a <em>very bad </em>white-hot bottleneck. Once, a DBA of such a system told me about a nightmare he had – it was about the servers which got so hot that they started melting. Fortunately, I never found myself in such position – but I can understand him perfectly:</p>
<blockquote><big><b>Pushing unnecessary stuff to DB-which-is-already-The-Bottleneck, is a Pretty Bad Idea™.</b></big></blockquote>
<p>As discussed above – scaling DBs is a very well-known huuuuge headache (a.k.a. Deep Trouble™); achieving even 1000 real-world transactions<a href="#rabbitfootnote-11"><sup>11</sup></a> per second (which – taking into account usual MOG-like load patterns – corresponds to about 30M transactions/day, or 10 billion transactions/year) is already pretty difficult; going above this number has several very unpleasant consequences:</p>
<ul>
<li>Non-trivial solutions are required.</li>
<li>Costs go through the roof, but as the dependency between load and costs is highly non-linear, spending more doesn’t help much.<a href="#rabbitfootnote-12"><sup>12</sup></a></li>
<li>job of DBAs becomes <em>extremely </em>difficult.</li>
<li>overall reliability suffers, starting from a very simple observation: the more DB Server Boxes you need to run – the higher chances are that at least <em>one </em>of them crashes.
<ul>
<li>This, in turn, leads to convoluted fault tolerant systems (with fault tolerance further taking its toll both in terms of bugs and in terms of reduced performance)
<ul>
<li>Just to illustrate my point: to handle a million writes per second, in Uber uses at least a few dozen boxes (using Cassandra on top of Mesos) <a href="http://ithare.com/scaling-stateful-objects/?rabbit_open_refs=1#rabbitref-Verma">[Verma]</a><a href="#rabbitfootnote-13"><sup>13</sup></a>; to achieve desirable reliability of 99.99%; this, in turn, required them to build a full-scale fault-tolerant system with transparent handling of box failures etc. etc. In an alternative architecture (the one using some kind of in-memory caching<a href="#rabbitfootnote-14"><sup>14</sup></a>) – a similar task of writing one million rows per second in a highly parallelizable environment can be achieved on one single server box running a decent RDBMS, which tends to have comparable reliability<a href="#rabbitfootnote-15"><sup>15</sup></a> at at least 10x less cost.</li>
</ul>
</li>
</ul>
</li>
</ul>
<p><a href="#_ftnref16" name="_ftn16"></a></p>
<p><img width="170" height="170" src="/wp-content/uploads/BB_emotion_0006b.png" />Of course, in <em>some </em>cases simple sharding will do the trick; in particular – for most of the single-player games sharding is trivial (each player sits in her own shard, with no interactions between the shards). However, as we’re speaking about <em>multiplayer </em>games (where it is usually impossible to restrict “which players are allowed to interact with each other” – see also discussion on it in Vol. I’s chapter on GDD) – sharding will rarely work (at least not without significant help from the app level).</p>
<p>Still, as we’ll discuss it in the Vol. VI’s chapter on Databases – it <em>is </em>usually possible to scale an MOG OLTP DB to 100M DB transactions/day and probably beyond; however – it is a very significant effort, which requires lots of complicated work (and while it <em>seems </em>having no apparent scalability problems – I didn’t see it scaling beyond 100M DB transactions/day, so I cannot really vouch for it).</p>
<p>Based on all the discussion above, we can make one very important conclusion:</p>
<blockquote><big><b>if we can avoid (or at least significantly postpone) this effort by reducing DB load by a factor of 10x-100x – we <em>should </em>do it.</b></big></blockquote>
<p>Note that I am <em>not </em>arguing for pursuing optimizations which save mere 20% at architectural stage; these are usually too small<a href="#rabbitfootnote-16"><sup>16</sup></a> to shift the balance from one architecture to another one; however, a 10x performance improvement due to better architecture, most of the time qualifies as a game changer (pun intended).</p>
<hr class="rabbit-footnote-separator" /><a name="rabbitfootnote-11"></a><div class="rabbit-footnote"><sup>11</sup> NB: we’re not speaking of highly artificial tests such as TPC-C, but about real stuff</div><a name="rabbitfootnote-12"></a><div class="rabbit-footnote"><sup>12</sup> BTW, make sure not to trust benchmarks-by-DB-vendors which tell you enormous numbers such as millions transactions/second; in short – all such benchmarks I’ve seen, were having at least one Really Big Issue™ which made them completely inapplicable to real-world cases (at least those cases which are somehow related to MOGs and OLTP DBs in general).</div><a name="rabbitfootnote-13"></a><div class="rabbit-footnote"><sup>13</sup> strictly speaking, <a href="http://ithare.com/scaling-stateful-objects/?rabbit_open_refs=1#rabbitref-Verma">[Verma]</a> says only that they have 300 boxes to run 20 clusters, and that the largest of these clusters handles 1m writes/second. Still, I am quite confident that it implies using at least a few dozens of server boxes to run their largest cluster.</div><a name="rabbitfootnote-14"></a><div class="rabbit-footnote"><sup>14</sup> Either using Stateful-App-Based system, or Stateless-App-Based one with In-Memory Caching – both are described below.</div><a name="rabbitfootnote-15"></a><div class="rabbit-footnote"><sup>15</sup> from my experience – at least 99.995% as long as we’re speaking only about DB server + RDBMS</div><a name="rabbitfootnote-16"></a><div class="rabbit-footnote"><sup>16</sup> well, unless you find 15 of <em>independent </em>optimizations, each providing 20% gain – but it rarely happens</div>
<p>&nbsp;</p>
<h5>Scaling Stateful-App-Based System</h5>
<p>With a system which is based on Stateful Apps (and assuming that our business logic/GDD is ok with relaxed Durability guarantees for the data which we decide to keep in-memory only) – we’re often able to reduce DB load by a factor of 10x-100x (and as observed above, for DB load, this kind of difference usually means a Damn Lot™).</p>
<p>A corresponding diagram is shown in Fig 8.2:</p>
<div class="rabbit-img"><a href="/wp-content/uploads/Fig-8.2-3.png"><img class="wp-image-9837 size-medium" src="/wp-content/uploads/Fig-8.2-3.png" alt="Fig 8.2"style="width:803px; max-width:100%;" width="640" height="248" /></a></div>
<p>Compared to Stateless-Based approach shown on Fig 8.1, we can see the following differences:</p>
<ul>
<li>Our Apps got In-Memory state. In turn, it means that:
<ul>
<li>This In-Memory State is not durable, and can be lost (as discussed above, this is <em>exactly </em>the behavior we want while Game Event is in progress)</li>
<li>Achieving balance between different Apps is not that trivial (in practice, I&#8217;ve never seen imbalance to be a significant problem, but I do know scenarios when it <em>may </em>happen<a href="#rabbitfootnote-17"><sup>17</sup></a>).</li>
</ul>
</li>
<li>As our Apps are now Stateful, it means that (unlike with stateless web apps), there are potentially two separate aspects for our Load Balancing:
<ul>
<li>First, we need to make sure that server-box-which-carries-our-state, has enough CPU power; in other words – we need to Load-Balance our Stateful Apps between different Server Boxes.
<ul>
<li>OTOH, for slower-paced games, this can be bypassed by moving state around as necessary; see Chapter 9 for discussion on Web-Based Architectures as an example.</li>
<li>Most of the time, this balancing will be <em>less </em>perfect than Load Balancing of Stateless Apps; from what I’ve seen – it <em>is </em>possible to keep these discrepancies in check, but in certain cases it <em>may </em>become a rather significant headache.</li>
<li>For games, usually, this flavor of Load Balancing (of the objects among Server Boxes) is performed by Matchmaking Server (not shown on Fig 8.2). The idea is that it is Matchmaking Server which decides to run a game (and where) – so it decides where to create the next instance.</li>
<li>A completely separate Load Balancer (which may include moving Game World instances around) – is also possible. Interesting variations of such Load Balancing include balancing of “seamless” MMO worlds as discussed in [Beardsley] and [Baryshnikov].</li>
</ul>
</li>
<li>Second – we <em>may </em>need to balance incoming <em>players </em>(or <em>requests</em>) among the Servers. While <em>usually </em>it is not a problem (as each of the Apps tends to serve about the same number of players) – in cases when we’re broadcasting some Very Important Game™ (like some Big Final) to everybody-who-wants-it, this MAY become a problem. For an example of a solution – see discussion about Front-End Servers in Chapter 9.</li>
</ul>
</li>
<li><img width="170" height="170" src="/wp-content/uploads/BB_emotion_0041b.png" />The main advantage of this approach is about reduced DB load. This, in turn, is achieved by writing to DB only at the end of Game Events.
<ul>
<li>In turn, it means that we need to identify those Game Events which allow/require writing to DB<a href="#rabbitfootnote-18"><sup>18</sup></a>, and to understand implications of rolling back to the beginning of the Game Event in case of crash.</li>
</ul>
</li>
</ul>
<p>Overall, from what I’ve seen in the wild, Stateful-App-Based systems tend to <em>both </em>perform <em>and </em>scale much <em>much</em> better than Stateless-App-Based ones. Of course, if Durability is a firm requirement, these architectures won’t fly (at least without ensuring fault tolerance for the Apps, preserving their In-Memory State).</p>
<hr class="rabbit-footnote-separator" /><a name="rabbitfootnote-17"></a><div class="rabbit-footnote"><sup>17</sup> in practice, if the number of App instances running on a single server, is high, <em>and</em> the load is restricted by number-of-players (opposed to number-of-observers) – achieving reasonable balance is going to be pretty simple.</div><a name="rabbitfootnote-18"></a><div class="rabbit-footnote"><sup>18</sup> or create them artificially, as mentioned above for social farming games, and for Uber</div>
<p>&nbsp;</p>
<h5>Scaling System Based on Stateless-App plus In-Memory Write-Back Cache</h5>
<p>At this point, we have to note that strictly speaking, having an In-Memory State <em>somewhere in the system </em>does NOT <em>necessarily</em> imply that it is our Apps which need to be Stateful.</p>
<p>Instead of using Stateful Apps, to save on the DB load while keeping our Apps stateless, we <em>can </em>have a centralized In-Memory write-back(!) cache sitting between our apps and DB, as shown on Fig 8.3:</p>
<div class="rabbit-img"><a href="/wp-content/uploads/Fig-8.3-3.png"><img class="wp-image-9838 size-medium" src="/wp-content/uploads/Fig-8.3-3.png" alt="Fig 8.3"style="width:806px; max-width:100%;" width="640" height="247" /></a></div>
<p>From the point of view of scaling, this model is a kind of “hybrid” between the Stateless-App and Stateful-App models. In particular, with such a Stateless-App-plus-In-Memory-Write-Back-Cache model:</p>
<ul>
<li>Like with Stateful-Apps, we <em>do</em> reduce DB load a lot.
<ul>
<li>As discussed above, this simplifies scaling DB <em>greatly</em></li>
</ul>
</li>
<li>Like with Stateful-Apps, we <em>do</em> need to identify our Game Events, and to ensure DB writes at the end of Game Events (though with In-Memory Cache, it will be done by write-back cache on instructions of our App)</li>
<li>Like with Stateful-Apps, we do sacrifice Durability between Game Events (i.e. crash of Write-Back Cache kills all the stuff which wasn’t written to DB yet)</li>
<li>Like with Stateless-Apps, we can Load-Balance only the incoming requests (or players) – and there is no need to Load-Balance the Stateful-Apps.
<ul>
<li>Scaling In-Memory Cache is rarely a problem.</li>
</ul>
</li>
</ul>
<p><img width="170" height="170" src="/wp-content/uploads/BB_emotion_0017b.png" />This approach tends to work pretty well at least for social games in Web-Based Deployment Architecture (which we’ll discuss in Chapter 9) – and <em>may </em>work for medium-paced games such as casino games too. On the other hand, for really fast-paced games (especially simulations) this model won’t really work problems because of (a) latencies to retrieve the state, and (b) because of enormous traffic between Stateless Apps and In-Memory Cache.</p>
<h5>Scaling System Based on Disposable-Stateful-Apps</h5>
<p>In some cases (in particular, for stock exchanges) there is a firm requirement to have <em>all</em> the modifications to the state of our system Durable (which means that they should go to DB, there is no way around it).</p>
<p>In such cases, and if the latencies are important – a kind of “Disposable-Stateful-Apps” can be used. The point here is to have a more-or-less usual Stateful App, but in this case our Stateful App will be merely serving as a read-only cache for DB information; as a result – in a case of crash it becomes trivial to restore the data from DB (which in turn makes such Stateful Apps disposable (in Docker-speak – <em>ephemeral</em>)).</p>
<p>An example of such a system is shown in Fig 8.4:</p>
<div class="rabbit-img"><a href="/wp-content/uploads/Fig-8.4-1.png"><img class="wp-image-9839 size-medium" src="/wp-content/uploads/Fig-8.4-1.png" alt="Fig 8.4"style="width:803px; max-width:100%;" width="640" height="248" /></a></div>
<p>This approach is very similar to the one shown in Fig 8.1 (the one for Stateless Apps) – except that Apps are no longer stateless &lt;wink /&gt;. However, while Apps in Fig 8.4 are Stateful – their state is merely a read-only app-level cache, so in case of App crash (or App  relocation/creation) the state can be easily reconstructed from the Database. While this approach does not reduce DB load compared to purely Stateless Apps &lt;sad-face /&gt;, it <em>does </em>improve latencies significantly (which can be a Big Plus for stock exchanges etc.).</p>
<p>BTW, in a certain sense this approach shares some ideas with Front-End Servers as discussed in Chapter 9 (in a sense, Front-End Servers can be seen as read-only caches of “master” state published by the source, too).</p>
<p>From scaling point of view, this model is an another “hybrid” between the Stateless-App and Stateful-App models. In particular, with such a Stateless-App-plus-In-Memory-Cache model:</p>
<ul>
<li>Like with Stateless-Apps, we cannot reduce DB load &lt;sad-face /&gt;</li>
<li>Like with Stateful-Apps, we do reduce latencies</li>
<li>Like with Stateless-Apps, we do NOT sacrifice Durability.</li>
<li>Like with Stateless-Apps, we can Load-Balance only the incoming requests (or players) – and there is no need to Load-Balance the Stateful-Apps (they’re both disposable and interchangeable).</li>
</ul>
<h4>Stateful vs Stateless</h4>
<p>With all the different scalability models discussed above (BTW, each of them has its own niche when it is The Right Thing To Do™), it would be nice to have a simple guideline to know where to start. Not pretending that I have a definite answer which will work in all the scenarios, from my experience, I’d say that the following qualifies as a reasonably good starting point for your analysis:</p>
<ul>
<li><img width="170" height="170" src="/wp-content/uploads/BB_emotion_0007b.png" />If limitations to Durability are not a concern, <em>and </em>we can save at least 3-5x of DB load by using In-Memory State – we should go for it! For anywhere sizeable project, headaches related to scaling DB under unnecessary load, are the worst ones you will have, so reducing them by factor of 3-5x (and as we’ve seen above – it can easily go all the way to 10x-1000x) is an Extremely Good Thing™.
<ul>
<li>One obvious solution in this direction is to use Stateful Apps. This approach does work – but has quite a few complications
<ul>
<li>In a sense – when moving from Stateless Apps to Stateful Apps, we’re trading DB scaling complications (which are typical for Stateless Apps) for App scaling complications (typical for Stateful Apps). From my experience, such a trade-off is well-worth it.</li>
</ul>
</li>
<li>On the other hand, as discussed above, in some cases (in particular, if the game is not too fast) we can <em>both </em>reduce DB load, <em>and </em>avoid Stateful Apps (via using an In-Memory Write-Back Cache). Still, it is not a silver bullet (and won’t really work for most of fast-paced games such as simulations)</li>
</ul>
</li>
<li>If 100% Durability is a requirement (such as for stock exchanges) – then the choice becomes less obvious.
<ul>
<li>If optimizing latency is a requirement – some kind of Disposable-Stateful-Apps is likely to be necessary. Personally, I’ve architected a stock exchange on top of such Disposable-Stateful-Apps (which can be seen as being along the lines of a usual game, but with DB commits on each trader action) – and with a very significant success too</li>
<li>If optimizing latencies is not really needed (which includes pretty much all polling architectures) – then a classical Client-Server web architecture will do.</li>
</ul>
</li>
</ul>
<p><a href="#_ftnref1" name="_ftn1"></a><a href="#_ftnref4" name="_ftn4"></a></p>
<h2>[[To Be Continued&#8230;</h2>
<p><img width="170" height="170" src="/wp-content/uploads/BB_emotion_0001b.png" />This concludes beta Chapter 8(a) from the upcoming book &#8220;Development and Deployment of Multiplayer Online Games (from social games to MMOFPS, with social games in between)&#8221;.</p>
<p>Stay tuned for beta Chapter 25(c), where we&#8217;ll discuss System Monitoring]]</p>
<hr><h3>References</h3><p></p>
<p><a name="rabbitref-Verma"></a>[Verma] Abhishek Verma, <a href="https://www.slideshare.net/DataStax/cassandra-on-mesos-across-multiple-datacenters-at-uber-abhishek-verma-c-summit-2016">&#8220;Cassandra on Mesos Across Multiple Datacenters at Uber&#8221;</a></p>
<p></p><h3>Acknowledgement</h3><p>Cartoons by Sergey Gordeev<sup><a style="border:none;" href="/real-people-behind-the-hare#sergey-gordeev"><img width="16" height="16" src="/wp-content/uploads/irl-link.png" alt="IRL" style="position:relative; bottom:3px;"></a></sup> from <a href="http://gagltd.eu/">Gordeev Animation Graphics</a>, Prague.</p><h3>P.S.</h3><p>Don&#39;t like this post?&nbsp;<b><a href="http://ithare.com/scaling-stateful-objects/#rabbit-comment">Criticize&#8623;</a></b></p><h3>P.P.S.</h3><p>We've tried to optimize our feed for viewing in your RSS viewer. However, our pages are quite complicated, so if you see any glitches when viewing this page in your RSS viewer, please refer to our <a href="http://ithare.com/scaling-stateful-objects/">original page</a>.</p>
]]></description>
		<wfw:commentRss>http://ithare.com/scaling-stateful-objects/feed/</wfw:commentRss>
		<slash:comments>4</slash:comments>
		</item>
		<item>
		<title>Scalability for MOGs</title>
		<link>http://ithare.com/scalability-for-mogs/</link>
		<comments>http://ithare.com/scalability-for-mogs/#respond</comments>
		<pubDate>Tue, 20 Jun 2017 23:43:01 +0000</pubDate>
		<dc:creator><![CDATA["No Bugs" Hare]]></dc:creator>
				<category><![CDATA[D&D of MOGs: Vol I-III (1st beta)]]></category>
		<category><![CDATA[Development & Deployment of Multiplayer Online Games]]></category>
		<category><![CDATA[multiplayer]]></category>
		<category><![CDATA[Scalability]]></category>
		<category><![CDATA[Server]]></category>

		<guid isPermaLink="false">http://ithare.com/?p=9804&#038;rabbit_rss_ver=23</guid>
		<description><![CDATA[
<div class="rabbit-img"><a href="/wp-content/uploads/BB_part154_BookChapter08_v1.png"><img class="wp-image-9811 size-medium" src="/wp-content/uploads/BB_part154_BookChapter08_v1-640x427.png" alt="Scalability Fairy" width="640" height="427" /></a></div>
<div class="rabbit-img-right"><a href="/contents-of-development-and-deployment-of-massively-multiplayer-games-from-social-games-to-mmofps-with-stock-exchanges-in-between/#vol3"><img src="/wp-content/uploads/bbbook_cover_vol03_-330.png" alt="#DDMoG, Vol. III" width="220" height="220" /></a></div><p>[[<em>This is Chapter 8(a) from “beta” Volume III of the upcoming book "Development&Deployment of Multiplayer Online Games", which is currently being beta-tested. Beta-testing is intended to improve the quality of the book, and provides free e-copy of the "release" book to those who help with improving; for further details see "<a href="/book-beta-testing-development-and-deployment-of-massively-multiplayer-games-from-social-games-to-mmofps-with-stock-exchanges-in-between/">Book Beta Testing</a>". All the content published during Beta Testing, is subject to change before the book is published. </em><p><em>To navigate through the "1st beta" of the book, you may want to use <a href="/contents-of-development-and-deployment-of-massively-multiplayer-games-from-social-games-to-mmofps-with-stock-exchanges-in-between/#toc">Development&amp;Deployment of MOG: Table of Contents</a>.</em>]]
<p>In Vol. II, we finished our first round of discussions about Client-Side (with more to follow in Vol. V), so now we can start considering Server-Side.</p>
<p>On the Server-Side, one of the very first things we need to take into account, is Scalability.</p>
<p>In general, poor Scalability isn’t usually observed until post-deployment; on the other hand –</p>
<blockquote><big><b>we DO need to take Scalability into account while architecting and developing our system.</b></big></blockquote>
<p>Otherwise – it can <em>easily </em>happen that at our finest hour – say, when we have a million players <em>willing </em>to play – we won’t be able to handle even half of them (or our Servers will be slowed down to the point of being completely unplayable). In this case, instead of being the finest hour – it can easily become a disaster, with our game beginning a downward spiral towards oblivion.<a href="#rabbitfootnote-1"><sup>1</sup></a></p>
<p>Let’s note that Scalability is a big topic, and that this Chapter is not the whole discussion on Scalability within this book. In particular, we were already discussing the mechanics of scaling for seamless Game World Servers in Vol. I’s chapter on Communications, and we’ll also discuss DB Scalability in detail in Vol. VI’s chapter on Databases; in addition, there will be another round of discussion on Scalability (as it applies to mature highly loaded systems), in Vol. IX.</p>
<p>In this Chapter, we’ll merely try to define a few terms – and to describe some very high-level approaches to Scalability (which, as we’ll see a bit later, will affect our architecture greatly).</p>
<hr class="rabbit-footnote-separator" /><a name="rabbitfootnote-1"></a><div class="rabbit-footnote"><sup>1</sup> no relation to <em>Elder Scrolls</em></div>
<p>&nbsp;</p>
<h2>Performance != Scalability, but… Performance Still Matters</h2>
<h3>What to Scale?</h3>
<p><img width="170" height="170" src="/wp-content/uploads/BB_emotion_0008b.png" />In the context of multiplayer games, there are traditionally two main points which need to be scaled. The first one – is scaling Game Worlds; the second such point is scaling our Database.<a href="#rabbitfootnote-2"><sup>2</sup></a></p>
<p>In addition, at some point you may need to scale your Matchmaking (and if you ever need to scale your Cashier and Payments – you’re certainly in luck &lt;wink /&gt;) – but from our current abstract perspective, they will be scaled in a manner similar to scaling your Game Worlds.</p>
<p>As a result, at least for the time being, we will concentrate on scaling of (a) Game Worlds, and (b) Database.</p>
<hr class="rabbit-footnote-separator" /><a name="rabbitfootnote-2"></a><div class="rabbit-footnote"><sup>2</sup> more generally – persistent storage, but for the purposes of this book we’ll name it Database anyway</div>
<p>&nbsp;</p>
<h3>Scaling Up – Doesn’t Help Much</h3>
<p>To start discussing Scalability – we need to define some terms. In theory, there are two types of Scalability: “scaling up” and “scaling out”. “Scaling up” refers to just buying a better hardware Server; it is a purely hardware solution which doesn’t require anything from software side.</p>
<p>Scaling up sounds as a really nice idea. Hey, we don’t need to think about scaling of our software – just tell admins to buy a new Server, and we’re done!</p>
<p>It all sounds very nice and easy for us developers. Unfortunately, there is one teensy problem with scaling up; the problem is that</p>
<blockquote><big><b>as of 2017, scaling up doesn’t help much.</b></big></blockquote>
<p>The reason for it is two-fold. First, we need to mention that</p>
<blockquote><big><b>for scaling up, it is per-core performance which matters.</b></big></blockquote>
<p>As we don’t want/need to make our software scalable when scaling up – then if our program run on N cores, buying new Server won’t give it any performance boost other than N*performance-of-new-cores/N*performance-of-old-cores; this pretty much translates into the statement above.</p>
<p>The second observation leading to scaling up not working, is the following:</p>
<p>These days, the best per-core performance we can hope for – is an around-4GHz CPU core.<a href="#rabbitfootnote-3"><sup>3</sup></a></p>
<p>Moreover, this didn’t change much over last 15 years or so.<a href="#rabbitfootnote-4"><sup>4</sup></a></p>
<p>Based on these two observations, we can see that if you’re already running a 3GHz CPU (either server one or a desktop one) – possibilities of scaling it up are extremely limited; all we’re speaking about – is 1.5x difference GHz-wise; in addition – it might be possible to get an additional 2x per-core advantage or so due to better caches etc. etc. – but well, at least for scalability of Game Worlds even 1.5x*2x=3x is not really much.</p>
<hr class="rabbit-footnote-separator" /><a name="rabbitfootnote-3"></a><div class="rabbit-footnote"><sup>3</sup> over the past 10 years, IBM Power was the CPU having the highest clock rate – and the fastest Power goes around 4.7-5GHz. Recently, AMD has reached 4.7GHz too, and Intel was <em>rumored</em> to release 5.1GHz CPU soon – though as of early 2017 it seems that these expectations didn’t materialize.</div><a name="rabbitfootnote-4"></a><div class="rabbit-footnote"><sup>4</sup> granted, per-MHz performance did increase over the last 15 years, but gains of the order of 3-4x or so do not help much with scalability</div>
<p>&nbsp;</p>
<h3>Improving Performance to Avoid the Need to Scale</h3>
<p>In addition to Scaling Up – at least in theory, there is one more thing which we might be able to do to deal with the load; it is improving performance of our app, so that we can run our load on the same hardware.<a href="#rabbitfootnote-5"><sup>5</sup></a></p>
<p><img width="170" height="170" src="/wp-content/uploads/BB_emotion_0010b.png" />Just like Scaling Up, improving performance doesn’t provide infinite scalability. However, it happens that it is all about numbers. Let’s take a closer look at them.</p>
<p>Let’s consider a game which needs to handle 100’000 of simultaneous players. As noted above – we have two major points to scale (Game Worlds and Database).</p>
<p>When scaling Game Worlds, and assuming a typical industry number of being able to support 100 players/core – we’ll need around 1000 cores to support desired 100’000 players. Honestly – improving this performance by 1000x so we can run it on a single core, is not really realistic. It means that improving the performance of Game World Servers (while still being important to reduce Server costs(!)) won’t save us from the task of ensuring Scalability for Game Worlds.</p>
<p>On the other hand, if trying to scale our Database for the same game with 100’000 players – we’ll usually be speaking about the numbers of 0.1-1 DB transaction/player/minute (see also the TODO section below). It translates into 10’000-100’000 DB transactions/minute ~= 150-1500 DB transactions/second. And these numbers, as we’ll see in Vol. VI, can be quite achievable even over one single DB connection (that is, <em>if </em>we do a really good job optimizing our performance).</p>
<p>In practice, it means that for scaling Databases, at least in certain cases, we can try to avoid dealing with Scalability until our game becomes really large (and usually, unless we’re an AAA company, it doesn’t happen overnight).</p>
<hr class="rabbit-footnote-separator" /><a name="rabbitfootnote-5"></a><div class="rabbit-footnote"><sup>5</sup> I don’t want to engage in discussion whether “improving performance” is actually one of the forms of “Scaling Up” or not; for the purposes of this book – let’s use “Scaling Up” in a narrow sense of “purely hardware upgrade”, so “improving performance” is a separate concept.</div>
<p>&nbsp;</p>
<h3>Scaling Out</h3>
<p>Even for Databases, and even when trying to avoid dealing with Scalability by improving performance really hard, we’re likely to hit a wall somewhere between 10’000 and 1’000’000 simultaneous players. And as discussed above – for Game Worlds neither Scaling Up nor improving performance will allow to achieve the required performance.</p>
<p>To deal with it –</p>
<blockquote><big><b>we’ll need to Scale Out.</b></big></blockquote>
<p>Unlike Scaling Up which relies on performance of one single core/Server-box – Scaling Out is all about spreading the load across different CPU cores (Server boxes etc.). As noted above, this is the only feasible way to scale your programs these days (when you DO need to scale, that is). As a result – whenever I’m speaking about “Scalability” or “scaling” within this book – I will mean “Scaling Out”.</p>
<p>&nbsp;</p>
<h2>On In-Memory States and Multi-Player Games</h2>
<blockquote><p>The show must go on</p>
<p>The show must go on, yeah yeah</p>
<p>Ooh, inside my heart is breaking</p>
<p>My make-up may be flaking</p>
<p>But my smile still stays on</p>&#8212; Queen &#8212;</blockquote>
<p>&nbsp;</p>
<p>After discussing the very basics of Scalability as such – let’s come back to our topic of multiplayer games.</p>
<p>Let’s observe that most multi-player games out there can be seen as a sequence of “game events”. Let’s define (very loosely) a multiplayer Game Event as “some dynamic interaction which involves more than one player, is limited in time and has an obviously observable outcome”. Examples of Game Events include such seemingly different things as:</p>
<ul>
<li>Arena match</li>
<li>Poker hand</li>
<li>RPG fight (or talk)</li>
</ul>
<p><img width="170" height="170" src="/wp-content/uploads/BB_emotion_0017b.png" />Actually, <em>all </em>the multi-player games I know look to the player as a sequence of Game Events – with, maybe, some interspersed interactions which involve only one single player (for example, interactions with game environment and NPCs but not with other PCs).</p>
<p>Now, as we realize that from multi-player point of view, our game is just a sequence of Game Events, we can make a few further observations.</p>
<p><strong>Observation 8.1.</strong> If Game Event is interrupted for more than a few dozen of seconds,<a href="#rabbitfootnote-6"><sup>6</sup></a> it is next-to-impossible to get all the players who participated in the Game Event, back to it.</p>
<p>For example, if you are running a bingo game with a hundred of players, and you disrupt it for 10 minutes for technical reasons, you won’t be able to continue it in a manner which is fair to all the players, at the very least because you won’t be able to get all that 100 players back into playing at the same time. The problem is all about numbers: for a two-player Game Event getting these two players back might work, but for 10+ – succeeding in <em>all</em> the players returning back to play at the same time is very unlikely.<a href="#rabbitfootnote-7"><sup>7</sup></a></p>
<p>Of course, if your game is a final of a big tournament with a big cash prize, you’ll probably be able to reschedule it for the next day or something, but gathering the same people back after 15 minutes or so of a game being irresponsive, won’t be possible for the vast majority of Game Events out there.</p>
<p><strong>Observation 8.2.</strong> If Game Event is interrupted for more than a few dozens of seconds, then even if we are able to reconstruct the same Game World State technically, it won’t be the same from the player&#8217;s point of view. Moreover, any substantial interrupt of the Game Event can easily provide an unfair advantage to some of the players.</p>
<p><img width="170" height="170" src="/wp-content/uploads/BB_emotion_0019b.png" />Being interrupted in the middle of a sword fight and being asked to resume just from the middle of it (which was “who-knows-how-many-milliseconds-before-you-need-to-press-the-button”) – is not likely to be satisfying for the players. In addition, if the interrupt is rather long – then from the players’ perspective they will stay in a nervous state of “what exactly is my position within this fight” (which is quite unusual and therefore rather uncomfortable compared to usual “I am preparing for this fight”); this is usually worse than knowing that the whole thing will be rolled back and you can start anew (of course, if one of them was winning – it will be unfair, but well – there is no ideally fair solution here).</p>
<p>As for unfair advantages – quite often, it is possible for a player to obtain some important game-changing information during the game event being interrupted. This information can be pretty much anything – from noticing the start of opponent’s move and preparing to counter it during the pause, to being able to run a sophisticated analysis tool in the middle of interrupted chess blitz match.</p>
<p>These effects are known in the game industry – though way too often they’re taken into account only during deployment as an after-thought, and this can easily lead to ugly solutions and even uglier resulting problems. In “In-Memory Game World States: a Natural Fit for ‘No Bugs’ Rule of Thumb” section below, we’ll see an example of rather crazy crash recovery logic of a large multi-million-dollar game: after the crash they first restored a perfectly correct current Game World State (with this restore itself causing lots of trouble) – just to follow it with rolling back this perfectly-correct-current-Game-World-State back to the start of Game Event – exactly because they weren’t able to resume the game due to lack of players.</p>
<hr class="rabbit-footnote-separator" /><a name="rabbitfootnote-6"></a><div class="rabbit-footnote"><sup>6</sup> unless we’re speaking about big tournaments or large prizes, I’d put more or less typical time at about 1-2 minutes (with all the necessary disclaimers about it depending on your game etc. etc.).</div><a name="rabbitfootnote-7"></a><div class="rabbit-footnote"><sup>7</sup> As always, there are some exceptions here and there, but they’re few and far between</div>
<p>&nbsp;</p>
<h3>‘No Bugs’ Rule of Thumb for Multiplayer Games</h3>
<blockquote><p>The weight of evidence for an extraordinary claim</p>
<p>must be proportioned to its strangeness</p>&#8212; Pierre-Simon Laplace &#8212;</blockquote>
<p>Now, armed with these two observations, we can try to figure out what needs to be done if our Server app crashes in the middle of the Game Event (which inevitably causes a large interrupt in game play – that is, unless we’re going for full-scale fault tolerance for <em>all</em> our Servers<em>, and </em>the crash was a hardware one<a href="#rabbitfootnote-8"><sup>8</sup></a>). Personally, I prefer to state it as the following</p>
<blockquote><big><b>“’No Bugs’ Rule of Thumb for Multiplayer Games”:</p>
<p>Whenever Game Event is interrupted for significant time, as a rule of thumb it is better to roll back the interrupted Game Event rather than trying to restore the exact Game World State in the middle of the Game Event.</b></big></blockquote>
<p>This statement is very bold – and as such, requires quite a bit of explanation. Let’s consider two options: the first one is to restore the exact Game World State at the moment of crash, and the second one is to roll back our interrupted Game Event (i.e. we restore the exact Game World State <em>as of the beginning of current Game Event)</em>; moreover, let’s assume that the both options are feasible to implement (which is not often the case for the Option 1, but for our current analysis we can afford a bit of daydreaming).</p>
<p>In both cases, the player’s experience will be hurt. Of course, roll back in Option 2 obviously changes the game landscape. However, as it follows from Observation 8.2, restoring exact Game World State in Option 1 is also far from the ideal. I’d say that from the point of view of “providing the least possible disruption to the players”, for quite a few games out there both approaches are roughly equal (=”having bad impact on the game of the same order of magnitude”). In other words – whatever we’re doing after the crash, gameplay will be hurt, and players will be inevitably unhappy (and some players will be inevitably more unhappy than the others).</p>
<p>With this in mind, we should take into account considerations which have led us to Observation 8.1 – those about getting players back. If going the route of Option 1 (taking “restoring Game Event in the middle” route), we’re basically saying that “everybody who participated in that Game Event, needs to stay online for some unspecified time, just polling to see when we’re able to relaunch our Game Servers; anybody who doesn’t do it – will be punished by losing the Game Event by default”. Essentially, we’ll be punishing players for our own problems – which is certainly not good (and players tend to hate it too). On the other hand, if dealing with the crash via Option 2 – we can say “sorry, Bad Thing™ did happen – but at least we rolled back all the current Game Events, so you can come whenever-you-want and continue playing at your convenience”.</p>
<p>Overall, from what I’ve seen (both as a developer <em>and </em>as a player) – I like the second option (the “roll back to start of Game Event” one) much <em>much </em>better than the first one, at the very least – for <em>most</em> of the games out there. Which is exactly what is summarized in the “’No Bugs’ Rule of Thumb” boldly stated in bold<a href="#rabbitfootnote-9"><sup>9</sup></a> above.</p>
<p><img width="170" height="170" src="/wp-content/uploads/BB_emotion_0007b.png" />BTW, it is <em>exactly</em> the same strategy which is traditionally applied for at least one brick-and-mortar game for centuries. As one poker pro has explained it: if a fire breaks out in a brick-and-mortar poker room while the hand is being played, then the whole hand gets cancelled, and all the chips are returned to their owners “as of the beginning of the hand” – regardless of the cards they were dealt and regardless of the state of the hand in general. Then, when the fire is extinguished, players can start a new hand – or some of them can leave; it is their choice, and certainly not the choice of the casino owner.</p>
<hr class="rabbit-footnote-separator" /><a name="rabbitfootnote-8"></a><div class="rabbit-footnote"><sup>8</sup> a software crash will be faithfully repeated on a reserve node (just as it happened with Ariane 5 rocket, see <a href="http://ithare.com/scalability-for-mogs/?rabbit_open_refs=1#rabbitref-Wikipedia.Cluster.LaunchFailure">[Wikipedia.Cluster.LaunchFailure]</a> for details), so no kind of Fault Tolerance will help against it.</div><a name="rabbitfootnote-9"></a><div class="rabbit-footnote"><sup>9</sup> pun intended</div>
<p>&nbsp;</p>
<h4>Good for Us (as developers)</h4>
<p>Now, let’s note that all this analysis above stands even <em>before </em>we take into account the complexities of implementing perfectly-durable-intra-Game-Event-Game-World-States. In practice – these complexities are so big (essentially leading to pushing each-and-every-player-action into some-kind-of-durable-database – which in turn leads to increasing DB load anywhere from 10x to 1000x, and scaling DBs with <em>that </em>much transactions <em>is</em> going to be next-to-impossible) – that we’d likely to choose Option 2 just to avoid these complexities. However, my point here is different; what I am trying to say is that</p>
<p>In case of crash, rolling back Game Event is usually a Good Thing™ from the <em>player’s</em> point of view</p>
<p>And the fact it also simplifies development – well, it just means that we as developers got lucky: if the simplest-for-developers solution (the one with in-memory Game World States – see “In-Memory Game World States: a Natural Fit for ‘No Bugs’ Rule of Thumb” section below) happens to be the best one for players too, it is certainly a Good Thing™ for everybody involved.</p>
<h4>Exception: Stock Exchanges</h4>
<p>A word of caution for stock exchanges. If your game is a stock exchange, you generally <em>do</em> need to save every-player’s-action persistently (to ensure strict correctness even in case of Game Server loss), so rolling back is not usually an option. Of course, technically we can say that with stock exchanges each single bid constitutes a Game Event, but well – it won’t really simplify our jobs down the road.</p>
<p>That being said, it should be noted that even for stock exchanges at least Classical Game Architecture described in Chapter 9, has been observed to work very well despite DB transaction numbers being rather large. At least in part, it can be attributed to two further observations: first, that for stock exchanges number of user interactions are usually not that high as for MMORPG,<a href="#rabbitfootnote-10"><sup>10</sup></a> and second, that price of the hardware is generally <em>much</em> less of a problem for stock exchanges than for other types of games.</p>
<hr class="rabbit-footnote-separator" /><a name="rabbitfootnote-10"></a><div class="rabbit-footnote"><sup>10</sup> if we exclude post-2007-or-so NASDAQ with lots of bots playing</div>
<p>&nbsp;</p>
<h4>NOT applicable to Single-Player Games</h4>
<p>It should also be noted that the logic above (and especially Observation 8.1) does <em>not</em> apply to single-player games (this includes over-the-Internet single-player games such as Internet slot machines etc.). For a single-player game (whether Internet-based or not), the whole thing tends to work exactly the other way around: there is only one player, and she expects to resume the game <em>exactly</em> at the point when the whole thing was interrupted; moreover, the interrupted gameplay is usually already supported for single-player games, so handling it differently for the crash of our Servers will feel pretty bad. Even worse, with single-player games where the player is playing against the game (such as casinos), rolling the game back for any reason will have pretty bad implications and will raise pretty bad suspicions too.</p>
<p><img width="170" height="170" src="/wp-content/uploads/BB_emotion_0009b.png" />In short – single-player games and multi-player games are two <em>extremely</em> different beasts in this regard, so observations about multi-player games SHOULD NOT be blindly extended to the single-player ones, and vice versa.</p>
<h4>In-Memory Game World States: a Natural Fit for ‘No Bugs’ Rule of Thumb</h4>
<p>From the discussion above it follows that if we had a Server crash with a subsequent reboot, then (as long as crash-reboot cycle took more than 2 minutes or so) – we’ll need to roll back the interrupted Game Event, even if we have perfect data as of the exact moment of crash.</p>
<p>Now comes an all-important</p>
<p><strong>Observation 8.3.</strong> Hey, but if we keep current Game Event in-memory only, we’ll get exactly the behavior we need without any “rollback” efforts (and will lower the DB load by orders of magnitude too)</p>
<p>It means that for most of the multi-player games out there, we can use the following paradigm:</p>
<ul>
<li>we divide the game into Game Events, which need to be rolled back in case of Server crash or something</li>
<li>while Game Event is in progress, this progress is maintained as a part of in-memory Game World State</li>
<li><strong>Game World States</strong><a href="#rabbitfootnote-11"><sup>11</sup></a><strong> SHOULD be written to DB only at the end of each Game Event, and <em>not </em>while the Game Event is in progress.</strong>
<ul>
<li>As a side benefit – this allows for the result of the Game Event to be written to DB atomically, so if there was one artifact for two players before they fight – we can be 100% sure that in DB there will be exactly one artifact after the fight regardless of whatever-has-happened.</li>
</ul>
</li>
</ul>
<p>Bingo! We can have our cake and eat it too! We’ve just got a very high-performance system (in-memory states without syncing to DB are about as fast as they go) – <em>and</em> it also provides very good player experience (well, as good as possible after something went horribly wrong).</p>
<p>BTW, if you choose to ignore this observation – you still can create a workable system, but the things can easily get rather ugly. Once, I’ve seen an architecture which wrote all the user actions to in-memory DB right away – effectively storing perfectly current Game World State in that in-memory DB. It took them quite an effort to implement this DB, but it did work. However – whenever their Server crashed – they needed to roll-forward the whole thing, which in turn, in quite a few cases has led to the need to fix a bug-which-caused-the-crash “right on the fly” before roll-forward can be completed(!); as a result – the roll-forward implementation of the in-memory DB has been observed to cause quite a few long downtimes.</p>
<p>To add insult to the injury – in fact, all these efforts and complexities of roll-forward were completely pointless – because, whenever their Server crashed, the recovery procedure went as follows:</p>
<ul>
<li>first, they roll-forwarded all the DB logs to get a consistent DB state with all the user actions accounted for (including those actions within unfinished Game Events);<a href="#rabbitfootnote-12"><sup>12</sup></a></li>
<li>and right after the roll-forward was completed – they ran an application-level rollback to remove all those unfinished Game Events from DB; the latter was necessary exactly because of the problems with getting the players back to the same Game Event (see Observation 8.1).</li>
</ul>
<p><img width="170" height="170" src="/wp-content/uploads/BB_emotion_0037b.png" />In short &#8211; they made a complicated custom DB-level rollforward, only to follow it up with a complicated custom application-level rollback.</p>
<p>A competing system (couldn’t help myself from bragging it was mine&lt;wink /&gt;), simply didn’t write all those unfinished Game Events into the DB while Game Events were in progress (and wrote the whole Game Event <em>after</em> it is completed, instead). In case of crash (BTW, crashes were <em>extremely </em>rare) – it simply started from DB state (which, given the logic above, corresponded to the end of last-Game-Event), without any additional rollbacks.<a href="#rabbitfootnote-13"><sup>13</sup></a> The whole thing was <em>much</em> simpler, scaled <em>much</em> better, and was observed to be <em>much</em> more reliable than competing in-memory-DB-based one described above.</p>
<hr class="rabbit-footnote-separator" /><a name="rabbitfootnote-11"></a><div class="rabbit-footnote"><sup>11</sup> or a part of the Game World State, which corresponds to the specific Game Event</div><a name="rabbitfootnote-12"></a><div class="rabbit-footnote"><sup>12</sup> and, as noted above, the completing roll-forward could take fixing a bug, ouch!</div><a name="rabbitfootnote-13"></a><div class="rabbit-footnote"><sup>13</sup> In case of DB crash (though not in case of app crash), a DB-level roll-forward to get consistent DB state was still necessary, but – as DB was a standard log-based RDBMS (and RDBMSs are doing log rollforwards for 50+ years now), it worked like a charm</div>
<p>&nbsp;</p>
<h3>On Data Consistency</h3>
<p>One thing which comes to mind when considering such in-memory state-based processing models, is a question about data consistency: “hey, how losing information and data consistency can possibly be a good thing?”. Here I need to mention that I am all <em>for </em>consistency; there is still a question, however, <em>how to define</em> this consistency.</p>
<p>As follows from the discussion above, from the player&#8217;s point of view (GDD, business requirements, etc.) it is necessary to include “interrupts” into our definition of consistency; and as soon as we’ve done it along the lines above – we will need to say something along the lines of “if the game was interrupted for significant time in the middle of Game Event, then the consistent state is defined as the state at the beginning of the interrupted Game Event”.</p>
<p>And as soon as we say it – our in-memory Game World State (synced to DB at the end of each Game Event) becomes a perfectly valid implementation (and a damn convenient one too &lt;wink /&gt;) of the data consistency under the definition above. While another implementation discussed above – the one based on in-memory DB with a subsequent app-level rollback – is also valid under the same definition, it happens to be <em>much</em> less convenient in the real-world.</p>
<p>&nbsp;</p>
<h3>In-Memory State Summary</h3>
<p>TL;DR:</p>
<ul>
<li><img width="170" height="170" src="/wp-content/uploads/BB_emotion_0029b.png" />for multi-player games, if you disrupt a Game Event (such as match, hand, or fight) for more than a few dozens of seconds – you won&#8217;t be able to continue it anyway because you won&#8217;t be able to get all the players-within-this-Game-Event back.</li>
<li>as a result, you&#8217;ll most likely need to roll your whole Game Event back.</li>
<li>and to implement this rolling-back-to-the-beginning-of-the-Game-Event, in-memory states (with syncing to DB at the end of each Game Event) are very natural and convenient.</li>
</ul>
<p>As a result, the following processing model tends to work very well for multi-player games, so you SHOULD consider it very seriously:</p>
<ul>
<li>Your gameflow needs to be separated into Game Events.
<ul>
<li>These Game Events SHOULD be more-or-less natural from player’s point of view</li>
</ul>
</li>
<li>You store intra-Game-Event Game World State in-memory only.</li>
<li>You synchronize your in-memory Game World State with DB around the end of each of Game Events.</li>
<li>If your Server crashes in the middle of the Game Event – you lose your in-memory Game World State.
<ul>
<li>On restart – your system will restore itself from the DB, which corresponds to rolling the state back to the beginning of the interrupted Game Event.
<ul>
<li>It is a Good Thing™, as this is exactly what is required in vast majority of cases.<a href="#rabbitfootnote-14"><sup>14</sup></a></li>
</ul>
</li>
</ul>
</li>
</ul>
<hr class="rabbit-footnote-separator" /><a name="rabbitfootnote-14"></a><div class="rabbit-footnote"><sup>14</sup> YMMV, void where prohibited</div>
<p>&nbsp;</p>
<h2>[[To Be Continued&#8230;</h2>
<p><img width="170" height="170" src="/wp-content/uploads/BB_emotion_0001b.png" />This concludes beta Chapter 8(a) from the upcoming book &#8220;Development and Deployment of Multiplayer Online Games (from social games to MMOFPS, with social games in between)&#8221;.</p>
<p>Stay tuned for beta Chapter 8(b), where we&#8217;ll discuss different scalability schemas]]</p>
<hr><h3>References</h3><p></p>
<p><a name="rabbitref-Wikipedia.Cluster.LaunchFailure"></a>[Wikipedia.Cluster.LaunchFailure] <a href="https://en.wikipedia.org/wiki/Cluster_(spacecraft)#Launch_failure">https://en.wikipedia.org/wiki/Cluster_(spacecraft)#Launch_failure</a></p>
<p></p><h3>Acknowledgement</h3><p>Cartoons by Sergey Gordeev<sup><a style="border:none;" href="/real-people-behind-the-hare#sergey-gordeev"><img width="16" height="16" src="/wp-content/uploads/irl-link.png" alt="IRL" style="position:relative; bottom:3px;"></a></sup> from <a href="http://gagltd.eu/">Gordeev Animation Graphics</a>, Prague.</p><h3>P.S.</h3><p>Don&#39;t like this post?&nbsp;<b><a href="http://ithare.com/scalability-for-mogs/#rabbit-comment">Criticize&#8623;</a></b></p><h3>P.P.S.</h3><p>We've tried to optimize our feed for viewing in your RSS viewer. However, our pages are quite complicated, so if you see any glitches when viewing this page in your RSS viewer, please refer to our <a href="http://ithare.com/scalability-for-mogs/">original page</a>.</p>
]]></description>
		<wfw:commentRss>http://ithare.com/scalability-for-mogs/feed/</wfw:commentRss>
		<slash:comments>0</slash:comments>
		</item>
		<item>
		<title>Docker and MOGs</title>
		<link>http://ithare.com/docker-and-mogs/</link>
		<comments>http://ithare.com/docker-and-mogs/#respond</comments>
		<pubDate>Tue, 13 Jun 2017 23:35:07 +0000</pubDate>
		<dc:creator><![CDATA["No Bugs" Hare]]></dc:creator>
				<category><![CDATA[D&D of MOGs: Vol. VII-IX (1st beta)]]></category>
		<category><![CDATA[Development & Deployment of Multiplayer Online Games]]></category>
		<category><![CDATA[multiplayer]]></category>
		<category><![CDATA[Server]]></category>

		<guid isPermaLink="false">http://ithare.com/?p=9633&#038;rabbit_rss_ver=23</guid>
		<description><![CDATA[
<div class="rabbit-img"><a href="/wp-content/uploads/BB_part153_BookChapter22b_v4.png"><img class="wp-image-9637 size-medium" src="/wp-content/uploads/BB_part153_BookChapter22b_v4-640x427.png" alt="Docker loads Software Container onto Server" width="640" height="427" /></a></div>
<div class="rabbit-img-right"><a href="/contents-of-development-and-deployment-of-massively-multiplayer-games-from-social-games-to-mmofps-with-stock-exchanges-in-between/#vol7"><img src="/wp-content/uploads/bbbook_cover_vol07_-330.png" alt="#DDMoG, Vol. VII" width="220" height="220" /></a></div><p>[[<em>This is Chapter 25(b) from “beta” Volume VII of the upcoming book "Development&Deployment of Multiplayer Online Games", which is currently being beta-tested. Beta-testing is intended to improve the quality of the book, and provides free e-copy of the "release" book to those who help with improving; for further details see "<a href="/book-beta-testing-development-and-deployment-of-massively-multiplayer-games-from-social-games-to-mmofps-with-stock-exchanges-in-between/">Book Beta Testing</a>". All the content published during Beta Testing, is subject to change before the book is published. </em><p><em>To navigate through the "1st beta" of the book, you may want to use <a href="/contents-of-development-and-deployment-of-massively-multiplayer-games-from-social-games-to-mmofps-with-stock-exchanges-in-between/#toc">Development&amp;Deployment of MOG: Table of Contents</a>.</em>]]
<p>When speaking about DevOps in 2017, we cannot avoid discussing Docker (it is a darling of way too many DevOps practitioners out there). These days, everyone and their dog goes crazy about Docker, but what exactly Docker is?</p>
<p>Strictly speaking, Docker is an application container, but then we run into a problem defining “application container”. At this point, while <a href="http://ithare.com/docker-and-mogs/?rabbit_open_refs=1#rabbitref-Coleman">[Coleman]</a> argues that “Containers are not VMs” – the first approximation to describe Docker is still as a “lightweight VM”.<a href="#rabbitfootnote-1"><sup>1</sup></a> Sure, there are significant differences between VMs and containers, but still – from a high-enough-viewpoint we <em>can</em> think of Docker containers as of “lightweight VMs”; continuing analogy from [Coleman], while indeed VMs are analogous to houses, and containers are analogous to apartments, when I (as an application) sleep in a <em>room</em>, I don’t care much whether the room is within an apartment or within a house.</p>
<hr class="rabbit-footnote-separator" /><a name="rabbitfootnote-1"></a><div class="rabbit-footnote"><sup>1</sup> Approaching app containers from the other side, we can think of Docker as of “improved <em>chroot</em>”, though I am afraid that for developers, <em>chroot</em> is less familiar than VMs.</div>
<p>&nbsp;</p>
<h2>Encapsulated Environment – A Real Saver (for Really Poorly Written Programs, That Is)</h2>
<p>Theorizing aside, let’s see what Docker can do for us (as MOG DevOps).</p>
<p>Probably the most touted advantage of Docker is an ability to run our program in <em>exactly </em>the same environment with <em>exactly </em>the same components-our-program-depends-on – which in turn can save us lots of trouble on potential incompatibilities of different components.</p>
<p>For quite a few programs out there this is indeed The Big Thing™. I’ve seen programs (by Very Big Vendors™ BTW) which required several dozens of dependencies, with quite of the dependencies required as “<em>exactly </em>version X” (opposed to usual “<em>at least </em>version X”). Anybody who tried to deploy this kind of things, is quite sure to remember the pain.</p>
<p>In another example (and repeating myself from Vol. [[TODO]]): once upon a time, I have worked with a very nice developer (his name was Andrew), who was responsible for developing an installer for some commercial software (which was a total dependency mess). While usually he was very polite, but when speaking about his job, he described the process in terms of “Our software is a pile of **it, and I need to take this **it into my hands, and carry it to the end-user’s server, without spilling it on the way”.</p>
<p><img width="170" height="170" src="/wp-content/uploads/BB_emotion_0037b.png" />When facing such monstrosities as those pieces of&#8230; software discussed above, I perfectly understand admins who admire Docker; and Andrew would obviously be delighted to prepare a Docker container and say “hey, please install this container instead, and it will just work because we have carried all our dependencies with us”.<a href="#rabbitfootnote-2"><sup>2</sup></a></p>
<p>On the other hand, as a developer, I would be <em>extremely </em>ashamed of releasing such a program myself. As it was noted above – I am sure that we (as developers) are responsible not only for making a program which passes tests, but also for making sure that our program is <em>usable in the real world</em>. This includes avoiding producing abominations such as the ones described above; moreover – as it was discussed at length in Vol. I’s chapter on DIY-vs-Reuse –</p>
<blockquote><big><b>Not all reuse is a Good Thing™</b></big></blockquote>
<p>In particular, from my experience, 99% of dependencies which require an <em>exact </em>version of some software (directly or indirectly), 95% of dependencies which demand a dozen of other dependencies, and 80% of <em>all</em> the dependencies I’ve seen in the software – are better to be avoided (the reasons to avoid specific dependencies vary, see discussion in Vol. II).</p>
<p>While I certainly don’t want to say that <em>all </em>dependencies are bad (in particular, writing your own database, your own TCP stack, or your own JPEG library are rarely good ideas), IMNSHO, these days re-use is badly overused &lt;sad-face /&gt;. As one example: if you’re about to use a component which merely performs a very basic e-mail address format validation, and requires a very specific version-of-.NET to do it – chances are that you’ll be <em>much</em> better in the long run writing these 50 LOCs yourself.</p>
<p>Sure, there will be quite a bit of resistance to the approach of dependency fighting (coming from the camp of the developers thinking along the lines of “I’ve got this task; what is the library I can use which does <em>exactly </em>what I need?”), but if we want our sizeable project to live a long and successful life – this is the only way.</p>
<p>And coming back to our current discussion on Docker:</p>
<blockquote><big><b>if we as developers do our job well and write a program which doesn’t cause “dependency pile of rubbish” syndrome described above – there will be no need for encapsulating dependencies.</b></big></blockquote>
<p>If you’re still in doubt of “hey, what will happen if the next version of the software breaks our app?” – I have to say that in theory, it can happen with or without Docker (with Docker or without, you DO need to apply security patches to the dependencies). However, in practice, as I wrote and maintained quite a few real-world systems designed along the lines discussed in this book (in particular, fighting those sneaky dependencies vigilantly) – I have to say that I don’t remember of one single case of a program failing in production due to dependency version mismatch; those very few cases when such a mismatch would be a problem – were detected during routine testing.</p>
<p>A word of caution: as your Server-Side grows to, say, a million lines of code, it is almost inevitable that <em>some</em> part of it will become a “dependency hell” and <em>will</em> require Docker to run. Still – make sure that such occurrences are very occasional, are obviously frowned upon, and most importantly – do not allow them to become a common practice (allowing it will become the beginning of the end for your system).</p>
<hr class="rabbit-footnote-separator" /><a name="rabbitfootnote-2"></a><div class="rabbit-footnote"><sup>2</sup> TBH, in that specific case most likely it wouldn’t be possible due to licensing issues for dependencies, but technically it would certainly be a breeze</div>
<p>&nbsp;</p>
<h2>Other Benefits of Docker</h2>
<p>As discussed above, I <em>strongly </em>prefer to write programs without going into “dependency hell” – and for such programs, benefits of encapsulating components do not apply.</p>
<p><img width="170" height="170" src="/wp-content/uploads/BB_emotion_0006b.png" />Still, contrary to popular belief, there <em>are</em> benefits of Docker containers which go beyond providing poorly written programs with exact versions of their dependencies. These benefits<a href="#rabbitfootnote-3"><sup>3</sup></a> include:</p>
<ul>
<li>Isolated Configuration.
<ul>
<li>While a well-written software doesn’t really need Docker to deal with &#8220;dependency hell&#8221; – Docker <em>may </em>help to ensure consistent configuration between QA and production (and production misconfigurations are known to cause quite a bit of trouble). As with anything else – it is <em>not </em>a silver bullet, but it <em>may</em> prevent a problem or two.</li>
</ul>
</li>
<li>Resource Quotas.
<ul>
<li>They can easily save your bacon from one runaway process eating up the whole RAM of your server (which in turn can bring down the whole game if you’re unlucky enough).</li>
</ul>
</li>
<li>Docker containers do provide a bit of additional security (protecting your host OS from an attacker who managed to take over your app and/or container).
<ul>
<li>Details are beyond the scope of this book; a good place to <em>start </em>researching this vast topic is <a href="http://ithare.com/docker-and-mogs/?rabbit_open_refs=1#rabbitref-Docker.Security">[Docker.Security]</a>.</li>
</ul>
</li>
<li>Binary Version Control. To be perfectly clear: I am not speaking about using Docker <em>instead</em> of your usual source control system. Rather, I mean keeping previous (binary) versions of your containers within Docker’s layered file system.
<ul>
<li>On the other hand – with multiple similar and/or identical servers running (and this is exactly what we expect from an MOG, at least for Game World servers); using layered file system for binary version control purposes is not really convenient.<a href="#rabbitfootnote-4"><sup>4</sup></a></li>
</ul>
</li>
<li>Automated Scaling and Load Balancing. Now we’re speaking.
<ul>
<li>To achieve it, you need to use another layer over usual Docker containers, such as <em>Docker Swarm</em> or <em>Kubernetes</em>.</li>
<li>Make sure to understand what exactly <em>Swarm</em> is doing, and make sure to avoid terminating your stateful instances (IIRC, Swarm terminates your containers on “redeployment”, so this is one thing you want to avoid while your Game Servers are running). We’ll discuss in-memory state in a bit more detail below, but for now let’s note that <em>whatever you’re doing – make sure that your stateful instances are not terminated forcefully by your scaler/balancer.</em></li>
</ul>
</li>
</ul>
<hr class="rabbit-footnote-separator" /><a name="rabbitfootnote-3"></a><div class="rabbit-footnote"><sup>3</sup> compared to “using neither containers nor VMs”, so advantages over VMs aren’t listed here</div><a name="rabbitfootnote-4"></a><div class="rabbit-footnote"><sup>4</sup> at least from what I’ve heard</div>
<p>&nbsp;</p>
<h2>Docker Costs</h2>
<p>From what I’ve seen and heard, Docker costs are pretty much negligible. TBH, even VM costs are pretty much negligible (that is, <em>if</em> you control the whole physical host and avoid noisy neighbors<a href="#rabbitfootnote-5"><sup>5</sup></a>) – but with Docker the costs are down to pretty much zero.</p>
<p>On the other hand – make sure not to use crazy-to-start-with configurations using things such as remote-disk-shared-over-NFS; they don’t work without Docker, and while adding Docker won’t make things observably worse – it won’t improve things either.</p>
<hr class="rabbit-footnote-separator" /><a name="rabbitfootnote-5"></a><div class="rabbit-footnote"><sup>5</sup> which is impossible in the cloud</div>
<p>&nbsp;</p>
<h2>Docker with an In-Memory State (Immutable but non-Ephemeral)</h2>
<p><img width="170" height="170" src="/wp-content/uploads/BB_emotion_0009b.png" />As we discussed in Vol. III’s chapter on Scalability, I do not buy a rather popular argument that “to achieve scalability, apps and middleware should be stateless” (it is the only one way to skin the scalability cat – and, depending on circumstances, it is often not the best one).</p>
<p>A brief recap. In fact – as business requirements very rarely allow for purely stateless implementations of the whole system – going after stateful middleware means that by declaring our apps and middleware stateless, we’re merely pushing the state (as well as all the scalability issues) down to the database (and for most of the environments out there, databases are NOT trivially scalable, in spite of what-your-DB-sales-person-may-tell-you). Moreover, in certain use cases (including, but not limited to, MOGs) blindly making middleware-and-apps stateless often causes increasing DB load by a factor of 10x-100x(!) – which in turn often makes the task of DB scaling pretty much hopeless.<a href="#rabbitfootnote-6"><sup>6</sup></a></p>
<p>In other words – for our MOG purposes much more often than not, we <em>do </em>want our Game World Apps to have an in-memory state (and yes, this state goes beyond simple caching).</p>
<p>Now back to Docker. While Docker containers are indeed better to be kept <em>immutable</em>, it doesn’t necessarily mean that they cannot hold an <em>in-memory state </em>(i.e. they don’t necessarily need to be <em>ephemeral</em>).</p>
<p>The difference here is that when we’re speaking about Docker images being <em>immutable</em> – we’re actually speaking about a prohibition on <em>persistent </em>state, and in-memory states are perfectly fine. From a practical perspective, even if our app/container has <em>in-memory </em>state, after graceful shutdown of the app/container, we still can avoid storing all those images, and can still upgrade seamlessly.<a href="#rabbitfootnote-7"><sup>7</sup></a></p>
<p>On the other hand – having substantial in-memory state means that we <em>cannot </em>arbitrarily restart / move our apps and containers (i.e. our containers, while being <em>immutable</em>, will go against Docker’s advice in <a href="http://ithare.com/docker-and-mogs/?rabbit_open_refs=1#rabbitref-Docker.Guidelines">[Docker.Guidelines]</a>, and won’t be <em>ephemeral</em>) &lt;sad-face /&gt;. Still, while an ability to dispose of any container just because we don’t like it, looks interesting (and useful too), it is not strictly required; moreover, it <em>seems </em>that <em>Docker Swarm</em> can also be used in a manner which does allow for stateful apps with an in-memory state.</p>
<p>Let’s summarize this in the following table:</p>
<table>
<tbody>
<tr>
<td></td>
<td><strong>Mutable Containers</strong></td>
<td><strong>Immutable Containers (We Are Here)</strong></td>
<td><strong>Ephemeral (Disposable) Containers</strong></td>
</tr>
<tr>
<td><strong>In-Memory State</strong></td>
<td>Yes</td>
<td>Yes</td>
<td>No</td>
</tr>
<tr>
<td><strong>Persistent State</strong></td>
<td>Yes</td>
<td>No</td>
<td>No</td>
</tr>
<tr>
<td><strong>DB Load (compared to architectures based on ephemeral containers)</strong></td>
<td>Potential reduction of 10x-100x</td>
<td>Potential reduction of 10x-100x</td>
<td>Baseline</td>
</tr>
<tr>
<td><strong>Inter-process communication load and latencies (compared to architectures based on ephemeral containers)</strong></td>
<td>Potentially improved by Orders of Magnitude</td>
<td>Potentially improved by Orders of Magnitude</td>
<td>Baseline</td>
</tr>
<tr>
<td><strong>Need to Keep / Backup Container Images</strong></td>
<td>Yes</td>
<td>No</td>
<td>No</td>
</tr>
<tr>
<td><strong>Trivial Upgrade When Container is Not Running</strong></td>
<td>No</td>
<td>Yes</td>
<td>Yes</td>
</tr>
<tr>
<td><strong>Restart Container at Will</strong></td>
<td>No</td>
<td>No</td>
<td>Yes</td>
</tr>
<tr>
<td><strong>Trivial Upgrade when Container IS running</strong></td>
<td>No</td>
<td>No</td>
<td>Yes</td>
</tr>
<tr>
<td><strong>Docker Swarm Compatible</strong></td>
<td>Barely</td>
<td>Yes, as long as we don’t force-terminate containers</td>
<td>Yes</td>
</tr>
</tbody>
</table>
<p>&nbsp;</p>
<h3>Docker Swarm and In-Memory State</h3>
<p>BTW, if considering the usage our immutable-but-not-ephemeral containers in <em>Docker Swarm</em>, we need to keep in mind a few peculiarities which aren’t really too common for mostly-web-oriented ephemeral Docker deployments:</p>
<ul>
<li>If we’re using rented-per-hour hosts (such as cloud servers) to run our containers, we won’t be able to retire the whole host until all the containers there are terminated. And as we cannot force-terminate our non-ephemeral containers – it leaves us with two choices:
<ul>
<li>Use <em>Swarm</em>&#8216;s DRAIN on the host-to-be-retired (preventing new containers to be created there) – and wait until all the containers on the host terminate naturally. If all our containers have lifetime limited by a small upper bound such as 30 minutes – it <em>might </em>fly<em>.</em></li>
<li>Otherwise – we’ll need to do it in a (semi-)manual manner, identifying those containers which prevent us from retiring host, and implementing our own app-level app migration between containers.<a href="#rabbitfootnote-8"><sup>8</sup></a> BTW, as it was mentioned in Vol. II’s chapter on (Re)Actors, deterministic containers can be migrated without incurring the latency penalty of full_serialization-transfer-full_deserializiation.</li>
</ul>
</li>
<li><img width="170" height="170" src="/wp-content/uploads/BB_emotion_0008b.png" />Keep in mind that Swarm-provided DNS-based load balancing as such doesn’t apply to game-like loads (as a rule of thumb, with our containers being stateful, we need to balance containers, not incoming requests; not to mention big inherent problems with DNS-based balancing due to DNS caching). For more discussion on Load Balancing in general – see Vol. III’s chapter on Server-Side Architecture.</li>
</ul>
<hr class="rabbit-footnote-separator" /><a name="rabbitfootnote-6"></a><div class="rabbit-footnote"><sup>6</sup> at least without spending a fortune on DB+associated services</div><a name="rabbitfootnote-7"></a><div class="rabbit-footnote"><sup>7</sup> well, as long as we’re ready to handle DB structure changes, so it is not exactly a free ride either</div><a name="rabbitfootnote-8"></a><div class="rabbit-footnote"><sup>8</sup> Alternatively – we can migrate whole containers using Docker itself, but see below about latencies.</div>
<p>&nbsp;</p>
<h2>Summary</h2>
<p>To summarize the discussion above:</p>
<ul>
<li>Docker MAY be useful for MOG Server-Side deployments.
<ul>
<li>OTOH, most-touted Docker feature of Isolated Components is not really useful provided that we as developers do our job properly</li>
<li>Still, other Docker features – such as Security, Resource Quotas, and Isolated Configuration, MAY be useful</li>
<li>One especially potentially interesting for us Docker feature is Docker Swarm</li>
<li>Keep in mind that primarily Docker is aimed for stateless web apps, so while it <em>can </em>be used for MOGs – take all 3<sup>rd</sup>-party advice on Docker with a big pinch of salt (asking yourself – <em>does it really apply to apps with in-memory state?</em>)</li>
</ul>
</li>
<li>If using Docker, we’ll be aiming for:
<ul>
<li>At least as a first step – we’ll be using Docker for Game World Servers</li>
<li>Our Game World Containers will be immutable (i.e. without persistent state) – but will have an in-memory state (i.e. they won&#8217;t be ephemeral)
<ul>
<li>As a result – we’ll need to make sure that Docker (including Swarm if we&#8217;re using it) doesn’t terminate containers just because it feels like it.</li>
<li>Retiring the whole host may be difficult – DRAIN doesn’t always help, and semi-manual migration mechanisms <em>might </em>be necessary.</li>
</ul>
</li>
<li>Keep in mind that most of the Docker-related advice available out there, is intended for web-like services without an in-memory state (and with ephemeral containers), so take all 3<sup>rd</sup>-party advice with a big pinch of salt.
<ul>
<li>In particular – I do insist that at least for games and game-like services, we <em>should</em> have quite a few our Docker containers non-<em>ephemeral</em> (non-disposable) – otherwise we’ll get very serious performance penalties (see Vol. III’s chapter on Server-Side Architectures for discussion). OTOH – our Docker containers can and <em>should </em>be kept <em>immutable </em>(i.e. each new instance of the container of the same type, <em>can </em>be re-created from the same original image).</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2>[[To Be Continued&#8230;</h2>
<p><img width="170" height="170" src="/wp-content/uploads/BB_emotion_0001b.png" />This concludes beta Chapter 25(b) from the upcoming book &#8220;Development and Deployment of Multiplayer Online Games (from social games to MMOFPS, with social games in between)&#8221;.</p>
<p>Stay tuned for beta Chapter 25(c), where we&#8217;ll discuss basics of system monitoring]]</p>
<hr><h3>References</h3><p></p>
<p><a name="rabbitref-Coleman"></a>[Coleman] Mike Coleman, <a href="https://blog.docker.com/2016/03/containers-are-not-vms/">&#8220;Containers are not VMs&#8221;</a></p>
<p><a name="rabbitref-Docker.Security"></a>[Docker.Security] <a href="https://docs.docker.com/engine/security/security/">&#8220;Docker security&#8221;</a></p>
<p><a name="rabbitref-Docker.Guidelines"></a>[Docker.Guidelines] <a href="https://docs.docker.com/engine/userguide/eng-image/dockerfile_best-practices/#general-guidelines-and-recommendations">&#8220;General guidelines and recommendations&#8221;</a></p>
<p></p><h3>Acknowledgement</h3><p>Cartoons by Sergey Gordeev<sup><a style="border:none;" href="/real-people-behind-the-hare#sergey-gordeev"><img width="16" height="16" src="/wp-content/uploads/irl-link.png" alt="IRL" style="position:relative; bottom:3px;"></a></sup> from <a href="http://gagltd.eu/">Gordeev Animation Graphics</a>, Prague.</p><h3>P.S.</h3><p>Don&#39;t like this post?&nbsp;<b><a href="http://ithare.com/docker-and-mogs/#rabbit-comment">Criticize&#8623;</a></b></p><h3>P.P.S.</h3><p>We've tried to optimize our feed for viewing in your RSS viewer. However, our pages are quite complicated, so if you see any glitches when viewing this page in your RSS viewer, please refer to our <a href="http://ithare.com/docker-and-mogs/">original page</a>.</p>
]]></description>
		<wfw:commentRss>http://ithare.com/docker-and-mogs/feed/</wfw:commentRss>
		<slash:comments>0</slash:comments>
		</item>
		<item>
		<title>DevOps for MOGs</title>
		<link>http://ithare.com/devops-for-mogs/</link>
		<comments>http://ithare.com/devops-for-mogs/#comments</comments>
		<pubDate>Tue, 06 Jun 2017 12:12:43 +0000</pubDate>
		<dc:creator><![CDATA["No Bugs" Hare]]></dc:creator>
				<category><![CDATA[D&D of MOGs: Vol. VII-IX (1st beta)]]></category>
		<category><![CDATA[Development]]></category>
		<category><![CDATA[Development & Deployment of Multiplayer Online Games]]></category>
		<category><![CDATA[Development Processes]]></category>
		<category><![CDATA[multiplayer]]></category>
		<category><![CDATA[Server]]></category>

		<guid isPermaLink="false">http://ithare.com/?p=9613&#038;rabbit_rss_ver=23</guid>
		<description><![CDATA[
<div class="rabbit-img"><a href="/wp-content/uploads/BB_part152_BookChapter22a_v1.png"><img class="wp-image-9619 size-medium" src="/wp-content/uploads/BB_part152_BookChapter22a_v1-640x427.png" alt="Continuous Delivery vs Classical Development" width="640" height="427" /></a></div>
<div class="rabbit-img-right"><a href="/contents-of-development-and-deployment-of-massively-multiplayer-games-from-social-games-to-mmofps-with-stock-exchanges-in-between/#vol7"><img src="/wp-content/uploads/bbbook_cover_vol07_-330.png" alt="#DDMoG, Vol. VII" width="220" height="220" /></a></div><p>[[<em>This is Chapter 25(a) from “beta” Volume VII of the upcoming book "Development&Deployment of Multiplayer Online Games", which is currently being beta-tested. Beta-testing is intended to improve the quality of the book, and provides free e-copy of the "release" book to those who help with improving; for further details see "<a href="/book-beta-testing-development-and-deployment-of-massively-multiplayer-games-from-social-games-to-mmofps-with-stock-exchanges-in-between/">Book Beta Testing</a>". All the content published during Beta Testing, is subject to change before the book is published. </em><p><em>To navigate through the "1st beta" of the book, you may want to use <a href="/contents-of-development-and-deployment-of-massively-multiplayer-games-from-social-games-to-mmofps-with-stock-exchanges-in-between/#toc">Development&amp;Deployment of MOG: Table of Contents</a>.</em>]]
<p>Very very roughly – DevOps (a portmanteau of “DEVelopment” and “OPerationS”) is an understanding that there should be no firewall between development team and operations (deployment) team – and as long as it is understood as such, I am all for DevOps in the context of the multiplayer games.<a href="#rabbitfootnote-1"><sup>1</sup></a></p>
<p>When looking at DevOps from a developer’s-plane-flying-at-30’000-feet, we can translate it into the following very important statement:</p>
<blockquote><big><b>our responsibility as developers does NOT end with producing a program which passes the tests. We are also responsible for the program working after deployment.</b></big></blockquote>
<p>In particular:</p>
<ul>
<li>All-favorite excuse of all times<a href="#rabbitfootnote-2"><sup>2</sup></a> “it works on my box” is not allowed. If there is a reproducible bug <em>in production environment </em>– we <em>must </em>fix it.
<ul>
<li>Consequence: If there is an <em>irreproducible </em>bug in production environment – we <em>must </em>fix it too &lt;sad-smile /&gt;</li>
<li>We <em>should </em>think about “what we’ll do if there is a bug in production”, well, in advance
<ul>
<li>That’s where techniques such as “production post-factum debugging” come <em>really </em>handy (for more details – see Vol. II’s chapter on (Re)Actors).</li>
</ul>
</li>
<li>While developing, we <em>should </em>think about minimizing dependencies.
<ul>
<li>We <em>must not </em>use system-dependent stuff which is not strictly required for us to work
<ul>
<li>As one example, for 99.99% of Server-Side game apps, exact Linux distro where our app is running, should be <em>completely </em>irrelevant.</li>
</ul>
</li>
<li>Explosive mixtures of conflicting dependencies (such as “we’re using lib C which wants lib A version &gt;= 3, and lib B which wants lib A version &lt;= 2” <em>should </em>be completely out of the question</li>
</ul>
</li>
<li><img width="170" height="170" src="/wp-content/uploads/BB_emotion_0009b.png" />We <em>should</em> enable production monitoring in our apps.
<ul>
<li>We’ll discuss more on it in [[TODO]] section below, but for now – let’s note that for our app (<em>especially </em>stateful apps), monitoring their health becomes of paramount importance for the Operations. And nobody but us can really say that the app is really healthy (both logically-consistent and not-about-to-blow-performance-wise). I cannot count the number of times when app-level performance reporting (translated into alerts by the monitoring system) saved my bacon, allowing to look at a problem several weeks/months before it started to cause player-observable trouble</li>
</ul>
</li>
</ul>
</li>
</ul>
<p>On the other hand, DevOps<a href="#rabbitfootnote-3"><sup>3</sup></a> do <em>not </em>necessarily imply that developers are <em>doing </em>all the Operations; from what I’ve seen – successful DevOps <em>do </em>include both Development Team and Operations/Deployment Team; the difference between classical Development+Operations, and DevOps is all about communications between these teams. Within a pre-DevOps world, developers used to think that their responsibility is to produce the program, and after that they can forget about it. With DevOps, there is an ongoing communication channel coming from Operations Team back to Development Team. As a result – we as developers should be ready to deal with requests coming from Operations such as:</p>
<ul>
<li>“What do you think is the <em>optimal </em>way to configure our program<a href="#rabbitfootnote-4"><sup>4</sup></a> in such-and-such environment?”</li>
<li>“Could you guys provide an option to use <em>syslog </em>for logging (it would be simpler for us as Operations to manage all the logs this way, and running a separate daemon which gets your text log files and feeds them to <em>syslog</em>, is ugly and inefficient)?”</li>
<li>“How can we monitor the load on that-mutex-or-thread-which-caused-Big-Slowdown-yesterday?”</li>
<li>And of course, The Ultimate Nightmare™ of both Development and Operations: “our program has crashed in production and we cannot relaunch it; let’s take a look at it Right Now™.”</li>
</ul>
<p><img width="170" height="170" src="/wp-content/uploads/BB_emotion_0017b.png" />This communication channel (coming from Operations back to Development) is <em>extremely </em>important to have a game which is able to work anywhere-reliably in the real world. In a certain sense – without this communication, we’re working within the (IMO badly obsolete at least for vast-majority-of-the-projects) waterfall model; and adding this channel makes the whole process much more agile, which in turn means <em>much</em> better ability to withstand ever-changing real-world requirements.</p>
<hr class="rabbit-footnote-separator" /><a name="rabbitfootnote-1"></a><div class="rabbit-footnote"><sup>1</sup> Moreover, this is what really happens in <em>all </em>the successful MOG teams I know</div><a name="rabbitfootnote-2"></a><div class="rabbit-footnote"><sup>2</sup> second only to “the dog ate my homework”</div><a name="rabbitfootnote-3"></a><div class="rabbit-footnote"><sup>3</sup> At least as I prefer to interpret it</div><a name="rabbitfootnote-4"></a><div class="rabbit-footnote"><sup>4</sup> BTW, it is important NOT to say “your program”; the program is a <em>joint </em>responsibility, and both sides should realize it</div>
<p>&nbsp;</p>
<h2>Continuous Delivery/Continuous Deployment</h2>
<p>In most of the literature out there, DevOps are very tightly associated with “CD” abbreviation. Unfortunately, there is absolutely no agreement over what this “CD” really means. First, let’s note that “CD” can stand either for “Continuous Delivery”, or for “Continuous Deployment”, and they (depending on the point of view) can mean quite different things (see, for example, <a href="http://ithare.com/devops-for-mogs/?rabbit_open_refs=1#rabbitref-Fowler">[Fowler]</a>). As usual, I won’t spend time on arguing which interpretation of the terms is “right”; instead, I’ll try to present different interpretations and their consequences in the context of MOGs (and how to name them – is not that important).</p>
<p>Oh, and one last thing before going onto terminological minefield around “CD”. Before we can even start to speak about any CD – we <em>should</em> implement CI; as discussed in Vol. III’s chapter on Pre-Coding, CI stands for “Continuous Integration”, and is a pretty-much-universally Good Thing™ to have. Very briefly – CI is about making sure that parts of your system are still working together after any change (at least they compile, and they successfully pass certain automated tests); more importantly for us now – CI is a prerequisite for any type of CD.<a href="#rabbitfootnote-5"><sup>5</sup></a></p>
<p>Back to CD. One rather extreme school of thought interprets “CD” as being an ability for <em>any</em> of the developers to push anything-which-passes-automated-tests, to production.<a href="#rabbitfootnote-6"><sup>6</sup></a> And while it might even work in certain environments and for certain sub-projects – when trying to apply it to the <em>whole </em>MOG, this approach won’t fly at all. The problem with Continuous-Delivery-in-this-sense is that <em>certain </em>changes of most systems are just way too risky to allow <em>one single person </em>to make a decision to push the change in production.</p>
<blockquote><big><b>If a change carries a chance to kill the whole project instantly – it <em>must </em>be signed off by several people, including both architects <em>and </em>stakeholders</b></big></blockquote>
<p>It is just a question of risk control and common sense: if we’re speaking about a change which has a potential not just to crash the whole thing, but to bring the whole project down for good – it <em>must not </em>be taken lightly.</p>
<p>And in a MOG world, there are <em>lots </em>of things which qualify as having such deadly such: in particular, pretty much any change to <em>game rules </em>can have such an effect.</p>
<p>On the other hand,</p>
<blockquote><big><b>if we’re speaking about some peripheral change (which can be still very important for your bottom line, but which is not likely to kill your project) – then for <em>that specific class of changes </em>an ability to deploy things ASAP can be much more important than jumping through the hoops of multiple approvals.</b></big></blockquote>
<p>One classical example of such a not-too-immediately-risky-change-which-needs-to-have-fast-turnaround-times is layout of your “create account” form. It <em>is </em>very important for your game,<a href="#rabbitfootnote-7"><sup>7</sup></a> but on the other hand – it is rather difficult for a layout of such a form (provided that it is <em>somehow </em>working), to kill your game. In addition – this layout is an extremely good candidate for all kinds of experimentation, including A/B testing.</p>
<p>As a result – for such features-which-are-important-but-which-have-no-risk-to-kill-your-game-instantly – I’d argue that we could (and actually <em>should</em>) have a very very shortened list of approvals,<a href="#rabbitfootnote-8"><sup>8</sup></a> and a very very shortened life cycle too.</p>
<p>As we can see – approaches to (a) deployment of immediately-critical features which can kill the whole thing with a press of one button, and (b) deployment of not-so-immediately-critical stuff which requires lots of experimentation – can and should be different. In other words,</p>
<blockquote><big><b>I am arguing for each of the teams being able to move with its own development <em>and </em>deployment speed (at least as long as the changes do not involve cross-team interactions).</b></big></blockquote>
<p>For the game team which deals with game balance – changes will require lots of discussions (including discussions with players), careful planning, and often even well-defined “beta” servers where players can playtest results of a change. As a result – such changes are likely to take <em>many weeks</em>.</p>
<p>In contrast, for a change of layout of the “create account” form – a quick look at the A/B testing candidate is often all we need (and pretty often, a simplistic A/B experiment can and should be done in a matter of <em>hours</em>).</p>
<p>To summarize my feelings about CI and CD:</p>
<ul>
<li>CI (=”Continuous Integration”) is a pretty much universally a Good Thing™. I don’t know of any environment where it wasn’t beneficial. Let’s do it.</li>
<li>As for CD (=”Continuous Delivery/Deployment”) it is less obvious (and even terminology is not well-established). However, the following is clear:
<ul>
<li>Different teams (and different pieces of code) tend to have different requirements in this regard – which in turn leads to different practices being optimal for them. In particular:
<ul>
<li>For those teams where a change can lead to the instant death of the project – much longer deployment cycles are typical (for MOGs – can be up to several <em>months</em>, but <em>weeks </em>is more typical)
<ul>
<li>While technically, it might be possible to stretch a definition to name this process “CD”, probably it won’t go with a spirit of CD.</li>
</ul>
</li>
<li>For those teams/fields where changes are not instantly critical – an ability to experiment can easily be much more important than risks (and typical deployment times can be on the order of <em>hours</em>). Related processes (with some reservations) <em>might </em>qualify as “CD”.</li>
</ul>
</li>
<li><img width="170" height="170" src="/wp-content/uploads/BB_emotion_0007b.png" />Most importantly, our processes should allow these different production cycles to co-exist. In particular,
<ul>
<li>We MUST NOT say that those-not-so-instantly-critical-but-requiring-lots-of-experimentation things should be tied to our “core” release schedule (which will probably go at <em>some-weeks </em>release intervals).</li>
<li>OTOH, for “heavy” changes (such as game rule change) – it is typical to have regular deployment cycles (with giving-players-time-to-leave before booting them, with stopping servers, etc. etc.).</li>
</ul>
</li>
<li>How to name this process-with-different-speeds-for-each-team – is not really important; much more important is for this multi-speed process to exist.</li>
</ul>
</li>
</ul>
<hr class="rabbit-footnote-separator" /><a name="rabbitfootnote-5"></a><div class="rabbit-footnote"><sup>5</sup> Well, technically you can try to do CD without CI, but nothing good will come out of it pretty much for sure.</div><a name="rabbitfootnote-6"></a><div class="rabbit-footnote"><sup>6</sup> NB: I am scared with this thought as much as you are, but I heard it from developers myself</div><a name="rabbitfootnote-7"></a><div class="rabbit-footnote"><sup>7</sup> if you have any doubts – ask your marketing/monetization folks; very briefly – this form affects a number of potential players who drop off at this point, and depending on the sequence of forms necessary to create account – drop off rate can be anywhere from 10% to 50% (I am not kidding) – with subtle changes like just adding a word “optional” for phone field, potentially decreasing drop-off 2x(!)</div><a name="rabbitfootnote-8"></a><div class="rabbit-footnote"><sup>8</sup> TBH, I would still ask for a sign-off by team lead of the marketing/monetization team, but well – it is not <em>that </em>critical and actually depends a lot on other processes you&#8217;re using.</div>
<p>&nbsp;</p>
<h2>[[To Be Continued&#8230;</h2>
<p><img width="170" height="170" src="/wp-content/uploads/BB_emotion_0001b.png" />This concludes beta Chapter 25(a) from the upcoming book &#8220;Development and Deployment of Multiplayer Online Games (from social games to MMOFPS, with social games in between)&#8221;.</p>
<p>Stay tuned for beta Chapter 25(b), where we&#8217;ll proceed to discussing potential uses for containers (Docker) for game deployments]]</p>
<hr><h3>References</h3><p></p>
<p><a name="rabbitref-Fowler"></a>[Fowler] Martin Fowler, <a href="https://martinfowler.com/bliki/ContinuousDelivery.html">&#8220;ContinuousDelivery&#8221;</a></p>
<p></p><h3>Acknowledgement</h3><p>Cartoons by Sergey Gordeev<sup><a style="border:none;" href="/real-people-behind-the-hare#sergey-gordeev"><img width="16" height="16" src="/wp-content/uploads/irl-link.png" alt="IRL" style="position:relative; bottom:3px;"></a></sup> from <a href="http://gagltd.eu/">Gordeev Animation Graphics</a>, Prague.</p><h3>P.S.</h3><p>Don&#39;t like this post?&nbsp;<b><a href="http://ithare.com/devops-for-mogs/#rabbit-comment">Criticize&#8623;</a></b></p><h3>P.P.S.</h3><p>We've tried to optimize our feed for viewing in your RSS viewer. However, our pages are quite complicated, so if you see any glitches when viewing this page in your RSS viewer, please refer to our <a href="http://ithare.com/devops-for-mogs/">original page</a>.</p>
<p><a href="#_ftnref5" name="_ftn5"></a></p>
]]></description>
		<wfw:commentRss>http://ithare.com/devops-for-mogs/feed/</wfw:commentRss>
		<slash:comments>4</slash:comments>
		</item>
	</channel>
</rss>

<!-- Dynamic page generated in 0.534 seconds. -->
<!-- Cached page generated by WP-Super-Cache on 2017-08-11 09:01:06 -->
